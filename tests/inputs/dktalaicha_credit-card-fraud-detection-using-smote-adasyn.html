<script>
    let highlighted = [];
    function highlight_lines(lines) {
        for (let line of highlighted) {
            let ele = document.getElementById(String(line));
            ele.style.backgroundColor = '';
        }
        highlighted = lines;
        for (let line of highlighted) {
            let ele = document.getElementById(String(line));
            ele.style.backgroundColor = 'yellow';
        }
    }
    let marked = [];
    function mark_leak_lines(lines) {
        for (let line of marked) {
            let ele = document.getElementById(String(line));
            ele.style.backgroundColor = '';
        }
        marked = lines;
        for (let line of marked) {
            let ele = document.getElementById(String(line));
            ele.style.backgroundColor = ele.style.backgroundColor = 'lightgreen';
        }
    }
    function show_infos(lines) {
        for (let line of lines) {
            let ele = document.getElementById(String(line) + "-info");
            if (ele) {
                ele.style.display = ele.style.display == 'none'? '': 'none'
            }
        }
    }
</script>
    <style type="text/css">
    .sum table {
    font-family: arial, sans-serif;
    border-collapse: collapse;
    width: 100%;
    }

    .sum td, .sum th {
    border: 1px solid #dddddd;
    text-align: left;
    padding: 8px;
    }

    .sum tr:hover {background-color: #D6EEEE;}
</style>
<center>
<table class="sum">
  <tbody><tr>
    <th>Leakage</th>
    <th>#Detected</th>
    <th>Locations</th>
  </tr>
  <tr>
    <td>Pre-processing leakage</td>
    <td>0</td>
    <td></td>
  </tr>
  <tr>
    <td>Overlap leakage</td>
    <td>4</td>
    <td><a href="#1257"><button type="button" style="line-height: 85%; None" onclick="None">1257</button></a> <a href="#1341"><button type="button" style="line-height: 85%; None" onclick="None">1341</button></a> <a href="#1419"><button type="button" style="line-height: 85%; None" onclick="None">1419</button></a> <a href="#1786"><button type="button" style="line-height: 85%; None" onclick="None">1786</button></a></td>
  </tr>
  <tr>
    <td>No independence test data</td>
    <td>1</td>
    <td><a href="#860"><button type="button" style="line-height: 85%; None" onclick="None">860</button></a> <a href="#1071"><button type="button" style="line-height: 85%; None" onclick="None">1071</button></a> <a href="#1174"><button type="button" style="line-height: 85%; None" onclick="None">1174</button></a> <a href="#1259"><button type="button" style="line-height: 85%; None" onclick="None">1259</button></a> <a href="#1343"><button type="button" style="line-height: 85%; None" onclick="None">1343</button></a> <a href="#1421"><button type="button" style="line-height: 85%; None" onclick="None">1421</button></a> <a href="#1789"><button type="button" style="line-height: 85%; None" onclick="None">1789</button></a> <a href="#1790"><button type="button" style="line-height: 85%; None" onclick="None">1790</button></a> <a href="#2053"><button type="button" style="line-height: 85%; None" onclick="None">2053</button></a> <a href="#2076"><button type="button" style="line-height: 85%; None" onclick="None">2076</button></a> <a href="#2098"><button type="button" style="line-height: 85%; None" onclick="None">2098</button></a> <a href="#2128"><button type="button" style="line-height: 85%; None" onclick="None">2128</button></a></td>
  </tr>
</tbody></table></center>

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"
   "http://www.w3.org/TR/html4/strict.dtd">
<!--
generated by Pygments <https://pygments.org/>
Copyright 2006-2021 by the Pygments team.
Licensed under the BSD license, see LICENSE for details.
-->
<html>
<head>
  <title></title>
  <meta http-equiv="content-type" content="text/html; charset=None">
  <style type="text/css">
/*
generated by Pygments <https://pygments.org/>
Copyright 2006-2021 by the Pygments team.
Licensed under the BSD license, see LICENSE for details.
*/
pre { line-height: 145%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
body .hll { background-color: #ffffcc }
body { background: #f8f8f8; }
body .c { color: #408080; font-style: italic } /* Comment */
body .err { border: 1px solid #FF0000 } /* Error */
body .k { color: #008000; font-weight: bold } /* Keyword */
body .o { color: #666666 } /* Operator */
body .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
body .cm { color: #408080; font-style: italic } /* Comment.Multiline */
body .cp { color: #BC7A00 } /* Comment.Preproc */
body .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
body .c1 { color: #408080; font-style: italic } /* Comment.Single */
body .cs { color: #408080; font-style: italic } /* Comment.Special */
body .gd { color: #A00000 } /* Generic.Deleted */
body .ge { font-style: italic } /* Generic.Emph */
body .gr { color: #FF0000 } /* Generic.Error */
body .gh { color: #000080; font-weight: bold } /* Generic.Heading */
body .gi { color: #00A000 } /* Generic.Inserted */
body .go { color: #888888 } /* Generic.Output */
body .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
body .gs { font-weight: bold } /* Generic.Strong */
body .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
body .gt { color: #0044DD } /* Generic.Traceback */
body .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
body .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
body .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
body .kp { color: #008000 } /* Keyword.Pseudo */
body .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
body .kt { color: #B00040 } /* Keyword.Type */
body .m { color: #666666 } /* Literal.Number */
body .s { color: #BA2121 } /* Literal.String */
body .na { color: #7D9029 } /* Name.Attribute */
body .nb { color: #008000 } /* Name.Builtin */
body .nc { color: #0000FF; font-weight: bold } /* Name.Class */
body .no { color: #880000 } /* Name.Constant */
body .nd { color: #AA22FF } /* Name.Decorator */
body .ni { color: #999999; font-weight: bold } /* Name.Entity */
body .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
body .nf { color: #0000FF } /* Name.Function */
body .nl { color: #A0A000 } /* Name.Label */
body .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
body .nt { color: #008000; font-weight: bold } /* Name.Tag */
body .nv { color: #19177C } /* Name.Variable */
body .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
body .w { color: #bbbbbb } /* Text.Whitespace */
body .mb { color: #666666 } /* Literal.Number.Bin */
body .mf { color: #666666 } /* Literal.Number.Float */
body .mh { color: #666666 } /* Literal.Number.Hex */
body .mi { color: #666666 } /* Literal.Number.Integer */
body .mo { color: #666666 } /* Literal.Number.Oct */
body .sa { color: #BA2121 } /* Literal.String.Affix */
body .sb { color: #BA2121 } /* Literal.String.Backtick */
body .sc { color: #BA2121 } /* Literal.String.Char */
body .dl { color: #BA2121 } /* Literal.String.Delimiter */
body .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
body .s2 { color: #BA2121 } /* Literal.String.Double */
body .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
body .sh { color: #BA2121 } /* Literal.String.Heredoc */
body .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
body .sx { color: #008000 } /* Literal.String.Other */
body .sr { color: #BB6688 } /* Literal.String.Regex */
body .s1 { color: #BA2121 } /* Literal.String.Single */
body .ss { color: #19177C } /* Literal.String.Symbol */
body .bp { color: #008000 } /* Name.Builtin.Pseudo */
body .fm { color: #0000FF } /* Name.Function.Magic */
body .vc { color: #19177C } /* Name.Variable.Class */
body .vg { color: #19177C } /* Name.Variable.Global */
body .vi { color: #19177C } /* Name.Variable.Instance */
body .vm { color: #19177C } /* Name.Variable.Magic */
body .il { color: #666666 } /* Literal.Number.Integer.Long */

  </style>
</head>
<body>
<h2></h2>

<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">   1</span>
<span class="normal">   2</span>
<span class="normal">   3</span>
<span class="normal">   4</span>
<span class="normal">   5</span>
<span class="normal">   6</span>
<span class="normal">   7</span>
<span class="normal">   8</span>
<span class="normal">   9</span>
<span class="normal">  10</span>
<span class="normal">  11</span>
<span class="normal">  12</span>
<span class="normal">  13</span>
<span class="normal">  14</span>
<span class="normal">  15</span>
<span class="normal">  16</span>
<span class="normal">  17</span>
<span class="normal">  18</span>
<span class="normal">  19</span>
<span class="normal">  20</span>
<span class="normal">  21</span>
<span class="normal">  22</span>
<span class="normal">  23</span>
<span class="normal">  24</span>
<span class="normal">  25</span>
<span class="normal">  26</span>
<span class="normal">  27</span>
<span class="normal">  28</span>
<span class="normal">  29</span>
<span class="normal">  30</span>
<span class="normal">  31</span>
<span class="normal">  32</span>
<span class="normal">  33</span>
<span class="normal">  34</span>
<span class="normal">  35</span>
<span class="normal">  36</span>
<span class="normal">  37</span>
<span class="normal">  38</span>
<span class="normal">  39</span>
<span class="normal">  40</span>
<span class="normal">  41</span>
<span class="normal">  42</span>
<span class="normal">  43</span>
<span class="normal">  44</span>
<span class="normal">  45</span>
<span class="normal">  46</span>
<span class="normal">  47</span>
<span class="normal">  48</span>
<span class="normal">  49</span>
<span class="normal">  50</span>
<span class="normal">  51</span>
<span class="normal">  52</span>
<span class="normal">  53</span>
<span class="normal">  54</span>
<span class="normal">  55</span>
<span class="normal">  56</span>
<span class="normal">  57</span>
<span class="normal">  58</span>
<span class="normal">  59</span>
<span class="normal">  60</span>
<span class="normal">  61</span>
<span class="normal">  62</span>
<span class="normal">  63</span>
<span class="normal">  64</span>
<span class="normal">  65</span>
<span class="normal">  66</span>
<span class="normal">  67</span>
<span class="normal">  68</span>
<span class="normal">  69</span>
<span class="normal">  70</span>
<span class="normal">  71</span>
<span class="normal">  72</span>
<span class="normal">  73</span>
<span class="normal">  74</span>
<span class="normal">  75</span>
<span class="normal">  76</span>
<span class="normal">  77</span>
<span class="normal">  78</span>
<span class="normal">  79</span>
<span class="normal">  80</span>
<span class="normal">  81</span>
<span class="normal">  82</span>
<span class="normal">  83</span>
<span class="normal">  84</span>
<span class="normal">  85</span>
<span class="normal">  86</span>
<span class="normal">  87</span>
<span class="normal">  88</span>
<span class="normal">  89</span>
<span class="normal">  90</span>
<span class="normal">  91</span>
<span class="normal">  92</span>
<span class="normal">  93</span>
<span class="normal">  94</span>
<span class="normal">  95</span>
<span class="normal">  96</span>
<span class="normal">  97</span>
<span class="normal">  98</span>
<span class="normal">  99</span>
<span class="normal"> 100</span>
<span class="normal"> 101</span>
<span class="normal"> 102</span>
<span class="normal"> 103</span>
<span class="normal"> 104</span>
<span class="normal"> 105</span>
<span class="normal"> 106</span>
<span class="normal"> 107</span>
<span class="normal"> 108</span>
<span class="normal"> 109</span>
<span class="normal"> 110</span>
<span class="normal"> 111</span>
<span class="normal"> 112</span>
<span class="normal"> 113</span>
<span class="normal"> 114</span>
<span class="normal"> 115</span>
<span class="normal"> 116</span>
<span class="normal"> 117</span>
<span class="normal"> 118</span>
<span class="normal"> 119</span>
<span class="normal"> 120</span>
<span class="normal"> 121</span>
<span class="normal"> 122</span>
<span class="normal"> 123</span>
<span class="normal"> 124</span>
<span class="normal"> 125</span>
<span class="normal"> 126</span>
<span class="normal"> 127</span>
<span class="normal"> 128</span>
<span class="normal"> 129</span>
<span class="normal"> 130</span>
<span class="normal"> 131</span>
<span class="normal"> 132</span>
<span class="normal"> 133</span>
<span class="normal"> 134</span>
<span class="normal"> 135</span>
<span class="normal"> 136</span>
<span class="normal"> 137</span>
<span class="normal"> 138</span>
<span class="normal"> 139</span>
<span class="normal"> 140</span>
<span class="normal"> 141</span>
<span class="normal"> 142</span>
<span class="normal"> 143</span>
<span class="normal"> 144</span>
<span class="normal"> 145</span>
<span class="normal"> 146</span>
<span class="normal"> 147</span>
<span class="normal"> 148</span>
<span class="normal"> 149</span>
<span class="normal"> 150</span>
<span class="normal"> 151</span>
<span class="normal"> 152</span>
<span class="normal"> 153</span>
<span class="normal"> 154</span>
<span class="normal"> 155</span>
<span class="normal"> 156</span>
<span class="normal"> 157</span>
<span class="normal"> 158</span>
<span class="normal"> 159</span>
<span class="normal"> 160</span>
<span class="normal"> 161</span>
<span class="normal"> 162</span>
<span class="normal"> 163</span>
<span class="normal"> 164</span>
<span class="normal"> 165</span>
<span class="normal"> 166</span>
<span class="normal"> 167</span>
<span class="normal"> 168</span>
<span class="normal"> 169</span>
<span class="normal"> 170</span>
<span class="normal"> 171</span>
<span class="normal"> 172</span>
<span class="normal"> 173</span>
<span class="normal"> 174</span>
<span class="normal"> 175</span>
<span class="normal"> 176</span>
<span class="normal"> 177</span>
<span class="normal"> 178</span>
<span class="normal"> 179</span>
<span class="normal"> 180</span>
<span class="normal"> 181</span>
<span class="normal"> 182</span>
<span class="normal"> 183</span>
<span class="normal"> 184</span>
<span class="normal"> 185</span>
<span class="normal"> 186</span>
<span class="normal"> 187</span>
<span class="normal"> 188</span>
<span class="normal"> 189</span>
<span class="normal"> 190</span>
<span class="normal"> 191</span>
<span class="normal"> 192</span>
<span class="normal"> 193</span>
<span class="normal"> 194</span>
<span class="normal"> 195</span>
<span class="normal"> 196</span>
<span class="normal"> 197</span>
<span class="normal"> 198</span>
<span class="normal"> 199</span>
<span class="normal"> 200</span>
<span class="normal"> 201</span>
<span class="normal"> 202</span>
<span class="normal"> 203</span>
<span class="normal"> 204</span>
<span class="normal"> 205</span>
<span class="normal"> 206</span>
<span class="normal"> 207</span>
<span class="normal"> 208</span>
<span class="normal"> 209</span>
<span class="normal"> 210</span>
<span class="normal"> 211</span>
<span class="normal"> 212</span>
<span class="normal"> 213</span>
<span class="normal"> 214</span>
<span class="normal"> 215</span>
<span class="normal"> 216</span>
<span class="normal"> 217</span>
<span class="normal"> 218</span>
<span class="normal"> 219</span>
<span class="normal"> 220</span>
<span class="normal"> 221</span>
<span class="normal"> 222</span>
<span class="normal"> 223</span>
<span class="normal"> 224</span>
<span class="normal"> 225</span>
<span class="normal"> 226</span>
<span class="normal"> 227</span>
<span class="normal"> 228</span>
<span class="normal"> 229</span>
<span class="normal"> 230</span>
<span class="normal"> 231</span>
<span class="normal"> 232</span>
<span class="normal"> 233</span>
<span class="normal"> 234</span>
<span class="normal"> 235</span>
<span class="normal"> 236</span>
<span class="normal"> 237</span>
<span class="normal"> 238</span>
<span class="normal"> 239</span>
<span class="normal"> 240</span>
<span class="normal"> 241</span>
<span class="normal"> 242</span>
<span class="normal"> 243</span>
<span class="normal"> 244</span>
<span class="normal"> 245</span>
<span class="normal"> 246</span>
<span class="normal"> 247</span>
<span class="normal"> 248</span>
<span class="normal"> 249</span>
<span class="normal"> 250</span>
<span class="normal"> 251</span>
<span class="normal"> 252</span>
<span class="normal"> 253</span>
<span class="normal"> 254</span>
<span class="normal"> 255</span>
<span class="normal"> 256</span>
<span class="normal"> 257</span>
<span class="normal"> 258</span>
<span class="normal"> 259</span>
<span class="normal"> 260</span>
<span class="normal"> 261</span>
<span class="normal"> 262</span>
<span class="normal"> 263</span>
<span class="normal"> 264</span>
<span class="normal"> 265</span>
<span class="normal"> 266</span>
<span class="normal"> 267</span>
<span class="normal"> 268</span>
<span class="normal"> 269</span>
<span class="normal"> 270</span>
<span class="normal"> 271</span>
<span class="normal"> 272</span>
<span class="normal"> 273</span>
<span class="normal"> 274</span>
<span class="normal"> 275</span>
<span class="normal"> 276</span>
<span class="normal"> 277</span>
<span class="normal"> 278</span>
<span class="normal"> 279</span>
<span class="normal"> 280</span>
<span class="normal"> 281</span>
<span class="normal"> 282</span>
<span class="normal"> 283</span>
<span class="normal"> 284</span>
<span class="normal"> 285</span>
<span class="normal"> 286</span>
<span class="normal"> 287</span>
<span class="normal"> 288</span>
<span class="normal"> 289</span>
<span class="normal"> 290</span>
<span class="normal"> 291</span>
<span class="normal"> 292</span>
<span class="normal"> 293</span>
<span class="normal"> 294</span>
<span class="normal"> 295</span>
<span class="normal"> 296</span>
<span class="normal"> 297</span>
<span class="normal"> 298</span>
<span class="normal"> 299</span>
<span class="normal"> 300</span>
<span class="normal"> 301</span>
<span class="normal"> 302</span>
<span class="normal"> 303</span>
<span class="normal"> 304</span>
<span class="normal"> 305</span>
<span class="normal"> 306</span>
<span class="normal"> 307</span>
<span class="normal"> 308</span>
<span class="normal"> 309</span>
<span class="normal"> 310</span>
<span class="normal"> 311</span>
<span class="normal"> 312</span>
<span class="normal"> 313</span>
<span class="normal"> 314</span>
<span class="normal"> 315</span>
<span class="normal"> 316</span>
<span class="normal"> 317</span>
<span class="normal"> 318</span>
<span class="normal"> 319</span>
<span class="normal"> 320</span>
<span class="normal"> 321</span>
<span class="normal"> 322</span>
<span class="normal"> 323</span>
<span class="normal"> 324</span>
<span class="normal"> 325</span>
<span class="normal"> 326</span>
<span class="normal"> 327</span>
<span class="normal"> 328</span>
<span class="normal"> 329</span>
<span class="normal"> 330</span>
<span class="normal"> 331</span>
<span class="normal"> 332</span>
<span class="normal"> 333</span>
<span class="normal"> 334</span>
<span class="normal"> 335</span>
<span class="normal"> 336</span>
<span class="normal"> 337</span>
<span class="normal"> 338</span>
<span class="normal"> 339</span>
<span class="normal"> 340</span>
<span class="normal"> 341</span>
<span class="normal"> 342</span>
<span class="normal"> 343</span>
<span class="normal"> 344</span>
<span class="normal"> 345</span>
<span class="normal"> 346</span>
<span class="normal"> 347</span>
<span class="normal"> 348</span>
<span class="normal"> 349</span>
<span class="normal"> 350</span>
<span class="normal"> 351</span>
<span class="normal"> 352</span>
<span class="normal"> 353</span>
<span class="normal"> 354</span>
<span class="normal"> 355</span>
<span class="normal"> 356</span>
<span class="normal"> 357</span>
<span class="normal"> 358</span>
<span class="normal"> 359</span>
<span class="normal"> 360</span>
<span class="normal"> 361</span>
<span class="normal"> 362</span>
<span class="normal"> 363</span>
<span class="normal"> 364</span>
<span class="normal"> 365</span>
<span class="normal"> 366</span>
<span class="normal"> 367</span>
<span class="normal"> 368</span>
<span class="normal"> 369</span>
<span class="normal"> 370</span>
<span class="normal"> 371</span>
<span class="normal"> 372</span>
<span class="normal"> 373</span>
<span class="normal"> 374</span>
<span class="normal"> 375</span>
<span class="normal"> 376</span>
<span class="normal"> 377</span>
<span class="normal"> 378</span>
<span class="normal"> 379</span>
<span class="normal"> 380</span>
<span class="normal"> 381</span>
<span class="normal"> 382</span>
<span class="normal"> 383</span>
<span class="normal"> 384</span>
<span class="normal"> 385</span>
<span class="normal"> 386</span>
<span class="normal"> 387</span>
<span class="normal"> 388</span>
<span class="normal"> 389</span>
<span class="normal"> 390</span>
<span class="normal"> 391</span>
<span class="normal"> 392</span>
<span class="normal"> 393</span>
<span class="normal"> 394</span>
<span class="normal"> 395</span>
<span class="normal"> 396</span>
<span class="normal"> 397</span>
<span class="normal"> 398</span>
<span class="normal"> 399</span>
<span class="normal"> 400</span>
<span class="normal"> 401</span>
<span class="normal"> 402</span>
<span class="normal"> 403</span>
<span class="normal"> 404</span>
<span class="normal"> 405</span>
<span class="normal"> 406</span>
<span class="normal"> 407</span>
<span class="normal"> 408</span>
<span class="normal"> 409</span>
<span class="normal"> 410</span>
<span class="normal"> 411</span>
<span class="normal"> 412</span>
<span class="normal"> 413</span>
<span class="normal"> 414</span>
<span class="normal"> 415</span>
<span class="normal"> 416</span>
<span class="normal"> 417</span>
<span class="normal"> 418</span>
<span class="normal"> 419</span>
<span class="normal"> 420</span>
<span class="normal"> 421</span>
<span class="normal"> 422</span>
<span class="normal"> 423</span>
<span class="normal"> 424</span>
<span class="normal"> 425</span>
<span class="normal"> 426</span>
<span class="normal"> 427</span>
<span class="normal"> 428</span>
<span class="normal"> 429</span>
<span class="normal"> 430</span>
<span class="normal"> 431</span>
<span class="normal"> 432</span>
<span class="normal"> 433</span>
<span class="normal"> 434</span>
<span class="normal"> 435</span>
<span class="normal"> 436</span>
<span class="normal"> 437</span>
<span class="normal"> 438</span>
<span class="normal"> 439</span>
<span class="normal"> 440</span>
<span class="normal"> 441</span>
<span class="normal"> 442</span>
<span class="normal"> 443</span>
<span class="normal"> 444</span>
<span class="normal"> 445</span>
<span class="normal"> 446</span>
<span class="normal"> 447</span>
<span class="normal"> 448</span>
<span class="normal"> 449</span>
<span class="normal"> 450</span>
<span class="normal"> 451</span>
<span class="normal"> 452</span>
<span class="normal"> 453</span>
<span class="normal"> 454</span>
<span class="normal"> 455</span>
<span class="normal"> 456</span>
<span class="normal"> 457</span>
<span class="normal"> 458</span>
<span class="normal"> 459</span>
<span class="normal"> 460</span>
<span class="normal"> 461</span>
<span class="normal"> 462</span>
<span class="normal"> 463</span>
<span class="normal"> 464</span>
<span class="normal"> 465</span>
<span class="normal"> 466</span>
<span class="normal"> 467</span>
<span class="normal"> 468</span>
<span class="normal"> 469</span>
<span class="normal"> 470</span>
<span class="normal"> 471</span>
<span class="normal"> 472</span>
<span class="normal"> 473</span>
<span class="normal"> 474</span>
<span class="normal"> 475</span>
<span class="normal"> 476</span>
<span class="normal"> 477</span>
<span class="normal"> 478</span>
<span class="normal"> 479</span>
<span class="normal"> 480</span>
<span class="normal"> 481</span>
<span class="normal"> 482</span>
<span class="normal"> 483</span>
<span class="normal"> 484</span>
<span class="normal"> 485</span>
<span class="normal"> 486</span>
<span class="normal"> 487</span>
<span class="normal"> 488</span>
<span class="normal"> 489</span>
<span class="normal"> 490</span>
<span class="normal"> 491</span>
<span class="normal"> 492</span>
<span class="normal"> 493</span>
<span class="normal"> 494</span>
<span class="normal"> 495</span>
<span class="normal"> 496</span>
<span class="normal"> 497</span>
<span class="normal"> 498</span>
<span class="normal"> 499</span>
<span class="normal"> 500</span>
<span class="normal"> 501</span>
<span class="normal"> 502</span>
<span class="normal"> 503</span>
<span class="normal"> 504</span>
<span class="normal"> 505</span>
<span class="normal"> 506</span>
<span class="normal"> 507</span>
<span class="normal"> 508</span>
<span class="normal"> 509</span>
<span class="normal"> 510</span>
<span class="normal"> 511</span>
<span class="normal"> 512</span>
<span class="normal"> 513</span>
<span class="normal"> 514</span>
<span class="normal"> 515</span>
<span class="normal"> 516</span>
<span class="normal"> 517</span>
<span class="normal"> 518</span>
<span class="normal"> 519</span>
<span class="normal"> 520</span>
<span class="normal"> 521</span>
<span class="normal"> 522</span>
<span class="normal"> 523</span>
<span class="normal"> 524</span>
<span class="normal"> 525</span>
<span class="normal"> 526</span>
<span class="normal"> 527</span>
<span class="normal"> 528</span>
<span class="normal"> 529</span>
<span class="normal"> 530</span>
<span class="normal"> 531</span>
<span class="normal"> 532</span>
<span class="normal"> 533</span>
<span class="normal"> 534</span>
<span class="normal"> 535</span>
<span class="normal"> 536</span>
<span class="normal"> 537</span>
<span class="normal"> 538</span>
<span class="normal"> 539</span>
<span class="normal"> 540</span>
<span class="normal"> 541</span>
<span class="normal"> 542</span>
<span class="normal"> 543</span>
<span class="normal"> 544</span>
<span class="normal"> 545</span>
<span class="normal"> 546</span>
<span class="normal"> 547</span>
<span class="normal"> 548</span>
<span class="normal"> 549</span>
<span class="normal"> 550</span>
<span class="normal"> 551</span>
<span class="normal"> 552</span>
<span class="normal"> 553</span>
<span class="normal"> 554</span>
<span class="normal"> 555</span>
<span class="normal"> 556</span>
<span class="normal"> 557</span>
<span class="normal"> 558</span>
<span class="normal"> 559</span>
<span class="normal"> 560</span>
<span class="normal"> 561</span>
<span class="normal"> 562</span>
<span class="normal"> 563</span>
<span class="normal"> 564</span>
<span class="normal"> 565</span>
<span class="normal"> 566</span>
<span class="normal"> 567</span>
<span class="normal"> 568</span>
<span class="normal"> 569</span>
<span class="normal"> 570</span>
<span class="normal"> 571</span>
<span class="normal"> 572</span>
<span class="normal"> 573</span>
<span class="normal"> 574</span>
<span class="normal"> 575</span>
<span class="normal"> 576</span>
<span class="normal"> 577</span>
<span class="normal"> 578</span>
<span class="normal"> 579</span>
<span class="normal"> 580</span>
<span class="normal"> 581</span>
<span class="normal"> 582</span>
<span class="normal"> 583</span>
<span class="normal"> 584</span>
<span class="normal"> 585</span>
<span class="normal"> 586</span>
<span class="normal"> 587</span>
<span class="normal"> 588</span>
<span class="normal"> 589</span>
<span class="normal"> 590</span>
<span class="normal"> 591</span>
<span class="normal"> 592</span>
<span class="normal"> 593</span>
<span class="normal"> 594</span>
<span class="normal"> 595</span>
<span class="normal"> 596</span>
<span class="normal"> 597</span>
<span class="normal"> 598</span>
<span class="normal"> 599</span>
<span class="normal"> 600</span>
<span class="normal"> 601</span>
<span class="normal"> 602</span>
<span class="normal"> 603</span>
<span class="normal"> 604</span>
<span class="normal"> 605</span>
<span class="normal"> 606</span>
<span class="normal"> 607</span>
<span class="normal"> 608</span>
<span class="normal"> 609</span>
<span class="normal"> 610</span>
<span class="normal"> 611</span>
<span class="normal"> 612</span>
<span class="normal"> 613</span>
<span class="normal"> 614</span>
<span class="normal"> 615</span>
<span class="normal"> 616</span>
<span class="normal"> 617</span>
<span class="normal"> 618</span>
<span class="normal"> 619</span>
<span class="normal"> 620</span>
<span class="normal"> 621</span>
<span class="normal"> 622</span>
<span class="normal"> 623</span>
<span class="normal"> 624</span>
<span class="normal"> 625</span>
<span class="normal"> 626</span>
<span class="normal"> 627</span>
<span class="normal"> 628</span>
<span class="normal"> 629</span>
<span class="normal"> 630</span>
<span class="normal"> 631</span>
<span class="normal"> 632</span>
<span class="normal"> 633</span>
<span class="normal"> 634</span>
<span class="normal"> 635</span>
<span class="normal"> 636</span>
<span class="normal"> 637</span>
<span class="normal"> 638</span>
<span class="normal"> 639</span>
<span class="normal"> 640</span>
<span class="normal"> 641</span>
<span class="normal"> 642</span>
<span class="normal"> 643</span>
<span class="normal"> 644</span>
<span class="normal"> 645</span>
<span class="normal"> 646</span>
<span class="normal"> 647</span>
<span class="normal"> 648</span>
<span class="normal"> 649</span>
<span class="normal"> 650</span>
<span class="normal"> 651</span>
<span class="normal"> 652</span>
<span class="normal"> 653</span>
<span class="normal"> 654</span>
<span class="normal"> 655</span>
<span class="normal"> 656</span>
<span class="normal"> 657</span>
<span class="normal"> 658</span>
<span class="normal"> 659</span>
<span class="normal"> 660</span>
<span class="normal"> 661</span>
<span class="normal"> 662</span>
<span class="normal"> 663</span>
<span class="normal"> 664</span>
<span class="normal"> 665</span>
<span class="normal"> 666</span>
<span class="normal"> 667</span>
<span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span>
<span class="normal">1328</span>
<span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span>
<span class="normal">1337</span>
<span class="normal">1338</span>
<span class="normal">1339</span>
<span class="normal">1340</span>
<span class="normal">1341</span>
<span class="normal">1342</span>
<span class="normal">1343</span>
<span class="normal">1344</span>
<span class="normal">1345</span>
<span class="normal">1346</span>
<span class="normal">1347</span>
<span class="normal">1348</span>
<span class="normal">1349</span>
<span class="normal">1350</span>
<span class="normal">1351</span>
<span class="normal">1352</span>
<span class="normal">1353</span>
<span class="normal">1354</span>
<span class="normal">1355</span>
<span class="normal">1356</span>
<span class="normal">1357</span>
<span class="normal">1358</span>
<span class="normal">1359</span>
<span class="normal">1360</span>
<span class="normal">1361</span>
<span class="normal">1362</span>
<span class="normal">1363</span>
<span class="normal">1364</span>
<span class="normal">1365</span>
<span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span>
<span class="normal">1373</span>
<span class="normal">1374</span>
<span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span>
<span class="normal">1379</span>
<span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span>
<span class="normal">1395</span>
<span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span>
<span class="normal">1407</span>
<span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span>
<span class="normal">1595</span>
<span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span>
<span class="normal">1599</span>
<span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span>
<span class="normal">1614</span>
<span class="normal">1615</span>
<span class="normal">1616</span>
<span class="normal">1617</span>
<span class="normal">1618</span>
<span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span>
<span class="normal">1650</span>
<span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span>
<span class="normal">1659</span>
<span class="normal">1660</span>
<span class="normal">1661</span>
<span class="normal">1662</span>
<span class="normal">1663</span>
<span class="normal">1664</span>
<span class="normal">1665</span>
<span class="normal">1666</span>
<span class="normal">1667</span>
<span class="normal">1668</span>
<span class="normal">1669</span>
<span class="normal">1670</span>
<span class="normal">1671</span>
<span class="normal">1672</span>
<span class="normal">1673</span>
<span class="normal">1674</span>
<span class="normal">1675</span>
<span class="normal">1676</span>
<span class="normal">1677</span>
<span class="normal">1678</span>
<span class="normal">1679</span>
<span class="normal">1680</span>
<span class="normal">1681</span>
<span class="normal">1682</span>
<span class="normal">1683</span>
<span class="normal">1684</span>
<span class="normal">1685</span>
<span class="normal">1686</span>
<span class="normal">1687</span>
<span class="normal">1688</span>
<span class="normal">1689</span>
<span class="normal">1690</span>
<span class="normal">1691</span>
<span class="normal">1692</span>
<span class="normal">1693</span>
<span class="normal">1694</span>
<span class="normal">1695</span>
<span class="normal">1696</span>
<span class="normal">1697</span>
<span class="normal">1698</span>
<span class="normal">1699</span>
<span class="normal">1700</span>
<span class="normal">1701</span>
<span class="normal">1702</span>
<span class="normal">1703</span>
<span class="normal">1704</span>
<span class="normal">1705</span>
<span class="normal">1706</span>
<span class="normal">1707</span>
<span class="normal">1708</span>
<span class="normal">1709</span>
<span class="normal">1710</span>
<span class="normal">1711</span>
<span class="normal">1712</span>
<span class="normal">1713</span>
<span class="normal">1714</span>
<span class="normal">1715</span>
<span class="normal">1716</span>
<span class="normal">1717</span>
<span class="normal">1718</span>
<span class="normal">1719</span>
<span class="normal">1720</span>
<span class="normal">1721</span>
<span class="normal">1722</span>
<span class="normal">1723</span>
<span class="normal">1724</span>
<span class="normal">1725</span>
<span class="normal">1726</span>
<span class="normal">1727</span>
<span class="normal">1728</span>
<span class="normal">1729</span>
<span class="normal">1730</span>
<span class="normal">1731</span>
<span class="normal">1732</span>
<span class="normal">1733</span>
<span class="normal">1734</span>
<span class="normal">1735</span>
<span class="normal">1736</span>
<span class="normal">1737</span>
<span class="normal">1738</span>
<span class="normal">1739</span>
<span class="normal">1740</span>
<span class="normal">1741</span>
<span class="normal">1742</span>
<span class="normal">1743</span>
<span class="normal">1744</span>
<span class="normal">1745</span>
<span class="normal">1746</span>
<span class="normal">1747</span>
<span class="normal">1748</span>
<span class="normal">1749</span>
<span class="normal">1750</span>
<span class="normal">1751</span>
<span class="normal">1752</span>
<span class="normal">1753</span>
<span class="normal">1754</span>
<span class="normal">1755</span>
<span class="normal">1756</span>
<span class="normal">1757</span>
<span class="normal">1758</span>
<span class="normal">1759</span>
<span class="normal">1760</span>
<span class="normal">1761</span>
<span class="normal">1762</span>
<span class="normal">1763</span>
<span class="normal">1764</span>
<span class="normal">1765</span>
<span class="normal">1766</span>
<span class="normal">1767</span>
<span class="normal">1768</span>
<span class="normal">1769</span>
<span class="normal">1770</span>
<span class="normal">1771</span>
<span class="normal">1772</span>
<span class="normal">1773</span>
<span class="normal">1774</span>
<span class="normal">1775</span>
<span class="normal">1776</span>
<span class="normal">1777</span>
<span class="normal">1778</span>
<span class="normal">1779</span>
<span class="normal">1780</span>
<span class="normal">1781</span>
<span class="normal">1782</span>
<span class="normal">1783</span>
<span class="normal">1784</span>
<span class="normal">1785</span>
<span class="normal">1786</span>
<span class="normal">1787</span>
<span class="normal">1788</span>
<span class="normal">1789</span>
<span class="normal">1790</span>
<span class="normal">1791</span>
<span class="normal">1792</span>
<span class="normal">1793</span>
<span class="normal">1794</span>
<span class="normal">1795</span>
<span class="normal">1796</span>
<span class="normal">1797</span>
<span class="normal">1798</span>
<span class="normal">1799</span>
<span class="normal">1800</span>
<span class="normal">1801</span>
<span class="normal">1802</span>
<span class="normal">1803</span>
<span class="normal">1804</span>
<span class="normal">1805</span>
<span class="normal">1806</span>
<span class="normal">1807</span>
<span class="normal">1808</span>
<span class="normal">1809</span>
<span class="normal">1810</span>
<span class="normal">1811</span>
<span class="normal">1812</span>
<span class="normal">1813</span>
<span class="normal">1814</span>
<span class="normal">1815</span>
<span class="normal">1816</span>
<span class="normal">1817</span>
<span class="normal">1818</span>
<span class="normal">1819</span>
<span class="normal">1820</span>
<span class="normal">1821</span>
<span class="normal">1822</span>
<span class="normal">1823</span>
<span class="normal">1824</span>
<span class="normal">1825</span>
<span class="normal">1826</span>
<span class="normal">1827</span>
<span class="normal">1828</span>
<span class="normal">1829</span>
<span class="normal">1830</span>
<span class="normal">1831</span>
<span class="normal">1832</span>
<span class="normal">1833</span>
<span class="normal">1834</span>
<span class="normal">1835</span>
<span class="normal">1836</span>
<span class="normal">1837</span>
<span class="normal">1838</span>
<span class="normal">1839</span>
<span class="normal">1840</span>
<span class="normal">1841</span>
<span class="normal">1842</span>
<span class="normal">1843</span>
<span class="normal">1844</span>
<span class="normal">1845</span>
<span class="normal">1846</span>
<span class="normal">1847</span>
<span class="normal">1848</span>
<span class="normal">1849</span>
<span class="normal">1850</span>
<span class="normal">1851</span>
<span class="normal">1852</span>
<span class="normal">1853</span>
<span class="normal">1854</span>
<span class="normal">1855</span>
<span class="normal">1856</span>
<span class="normal">1857</span>
<span class="normal">1858</span>
<span class="normal">1859</span>
<span class="normal">1860</span>
<span class="normal">1861</span>
<span class="normal">1862</span>
<span class="normal">1863</span>
<span class="normal">1864</span>
<span class="normal">1865</span>
<span class="normal">1866</span>
<span class="normal">1867</span>
<span class="normal">1868</span>
<span class="normal">1869</span>
<span class="normal">1870</span>
<span class="normal">1871</span>
<span class="normal">1872</span>
<span class="normal">1873</span>
<span class="normal">1874</span>
<span class="normal">1875</span>
<span class="normal">1876</span>
<span class="normal">1877</span>
<span class="normal">1878</span>
<span class="normal">1879</span>
<span class="normal">1880</span>
<span class="normal">1881</span>
<span class="normal">1882</span>
<span class="normal">1883</span>
<span class="normal">1884</span>
<span class="normal">1885</span>
<span class="normal">1886</span>
<span class="normal">1887</span>
<span class="normal">1888</span>
<span class="normal">1889</span>
<span class="normal">1890</span>
<span class="normal">1891</span>
<span class="normal">1892</span>
<span class="normal">1893</span>
<span class="normal">1894</span>
<span class="normal">1895</span>
<span class="normal">1896</span>
<span class="normal">1897</span>
<span class="normal">1898</span>
<span class="normal">1899</span>
<span class="normal">1900</span>
<span class="normal">1901</span>
<span class="normal">1902</span>
<span class="normal">1903</span>
<span class="normal">1904</span>
<span class="normal">1905</span>
<span class="normal">1906</span>
<span class="normal">1907</span>
<span class="normal">1908</span>
<span class="normal">1909</span>
<span class="normal">1910</span>
<span class="normal">1911</span>
<span class="normal">1912</span>
<span class="normal">1913</span>
<span class="normal">1914</span>
<span class="normal">1915</span>
<span class="normal">1916</span>
<span class="normal">1917</span>
<span class="normal">1918</span>
<span class="normal">1919</span>
<span class="normal">1920</span>
<span class="normal">1921</span>
<span class="normal">1922</span>
<span class="normal">1923</span>
<span class="normal">1924</span>
<span class="normal">1925</span>
<span class="normal">1926</span>
<span class="normal">1927</span>
<span class="normal">1928</span>
<span class="normal">1929</span>
<span class="normal">1930</span>
<span class="normal">1931</span>
<span class="normal">1932</span>
<span class="normal">1933</span>
<span class="normal">1934</span>
<span class="normal">1935</span>
<span class="normal">1936</span>
<span class="normal">1937</span>
<span class="normal">1938</span>
<span class="normal">1939</span>
<span class="normal">1940</span>
<span class="normal">1941</span>
<span class="normal">1942</span>
<span class="normal">1943</span>
<span class="normal">1944</span>
<span class="normal">1945</span>
<span class="normal">1946</span>
<span class="normal">1947</span>
<span class="normal">1948</span>
<span class="normal">1949</span>
<span class="normal">1950</span>
<span class="normal">1951</span>
<span class="normal">1952</span>
<span class="normal">1953</span>
<span class="normal">1954</span>
<span class="normal">1955</span>
<span class="normal">1956</span>
<span class="normal">1957</span>
<span class="normal">1958</span>
<span class="normal">1959</span>
<span class="normal">1960</span>
<span class="normal">1961</span>
<span class="normal">1962</span>
<span class="normal">1963</span>
<span class="normal">1964</span>
<span class="normal">1965</span>
<span class="normal">1966</span>
<span class="normal">1967</span>
<span class="normal">1968</span>
<span class="normal">1969</span>
<span class="normal">1970</span>
<span class="normal">1971</span>
<span class="normal">1972</span>
<span class="normal">1973</span>
<span class="normal">1974</span>
<span class="normal">1975</span>
<span class="normal">1976</span>
<span class="normal">1977</span>
<span class="normal">1978</span>
<span class="normal">1979</span>
<span class="normal">1980</span>
<span class="normal">1981</span>
<span class="normal">1982</span>
<span class="normal">1983</span>
<span class="normal">1984</span>
<span class="normal">1985</span>
<span class="normal">1986</span>
<span class="normal">1987</span>
<span class="normal">1988</span>
<span class="normal">1989</span>
<span class="normal">1990</span>
<span class="normal">1991</span>
<span class="normal">1992</span>
<span class="normal">1993</span>
<span class="normal">1994</span>
<span class="normal">1995</span>
<span class="normal">1996</span>
<span class="normal">1997</span>
<span class="normal">1998</span>
<span class="normal">1999</span>
<span class="normal">2000</span>
<span class="normal">2001</span>
<span class="normal">2002</span>
<span class="normal">2003</span>
<span class="normal">2004</span>
<span class="normal">2005</span>
<span class="normal">2006</span>
<span class="normal">2007</span>
<span class="normal">2008</span>
<span class="normal">2009</span>
<span class="normal">2010</span>
<span class="normal">2011</span>
<span class="normal">2012</span>
<span class="normal">2013</span>
<span class="normal">2014</span>
<span class="normal">2015</span>
<span class="normal">2016</span>
<span class="normal">2017</span>
<span class="normal">2018</span>
<span class="normal">2019</span>
<span class="normal">2020</span>
<span class="normal">2021</span>
<span class="normal">2022</span>
<span class="normal">2023</span>
<span class="normal">2024</span>
<span class="normal">2025</span>
<span class="normal">2026</span>
<span class="normal">2027</span>
<span class="normal">2028</span>
<span class="normal">2029</span>
<span class="normal">2030</span>
<span class="normal">2031</span>
<span class="normal">2032</span>
<span class="normal">2033</span>
<span class="normal">2034</span>
<span class="normal">2035</span>
<span class="normal">2036</span>
<span class="normal">2037</span>
<span class="normal">2038</span>
<span class="normal">2039</span>
<span class="normal">2040</span>
<span class="normal">2041</span>
<span class="normal">2042</span>
<span class="normal">2043</span>
<span class="normal">2044</span>
<span class="normal">2045</span>
<span class="normal">2046</span>
<span class="normal">2047</span>
<span class="normal">2048</span>
<span class="normal">2049</span>
<span class="normal">2050</span>
<span class="normal">2051</span>
<span class="normal">2052</span>
<span class="normal">2053</span>
<span class="normal">2054</span>
<span class="normal">2055</span>
<span class="normal">2056</span>
<span class="normal">2057</span>
<span class="normal">2058</span>
<span class="normal">2059</span>
<span class="normal">2060</span>
<span class="normal">2061</span>
<span class="normal">2062</span>
<span class="normal">2063</span>
<span class="normal">2064</span>
<span class="normal">2065</span>
<span class="normal">2066</span>
<span class="normal">2067</span>
<span class="normal">2068</span>
<span class="normal">2069</span>
<span class="normal">2070</span>
<span class="normal">2071</span>
<span class="normal">2072</span>
<span class="normal">2073</span>
<span class="normal">2074</span>
<span class="normal">2075</span>
<span class="normal">2076</span>
<span class="normal">2077</span>
<span class="normal">2078</span>
<span class="normal">2079</span>
<span class="normal">2080</span>
<span class="normal">2081</span>
<span class="normal">2082</span>
<span class="normal">2083</span>
<span class="normal">2084</span>
<span class="normal">2085</span>
<span class="normal">2086</span>
<span class="normal">2087</span>
<span class="normal">2088</span>
<span class="normal">2089</span>
<span class="normal">2090</span>
<span class="normal">2091</span>
<span class="normal">2092</span>
<span class="normal">2093</span>
<span class="normal">2094</span>
<span class="normal">2095</span>
<span class="normal">2096</span>
<span class="normal">2097</span>
<span class="normal">2098</span>
<span class="normal">2099</span>
<span class="normal">2100</span>
<span class="normal">2101</span>
<span class="normal">2102</span>
<span class="normal">2103</span>
<span class="normal">2104</span>
<span class="normal">2105</span>
<span class="normal">2106</span>
<span class="normal">2107</span>
<span class="normal">2108</span>
<span class="normal">2109</span>
<span class="normal">2110</span>
<span class="normal">2111</span>
<span class="normal">2112</span>
<span class="normal">2113</span>
<span class="normal">2114</span>
<span class="normal">2115</span>
<span class="normal">2116</span>
<span class="normal">2117</span>
<span class="normal">2118</span>
<span class="normal">2119</span>
<span class="normal">2120</span>
<span class="normal">2121</span>
<span class="normal">2122</span>
<span class="normal">2123</span>
<span class="normal">2124</span>
<span class="normal">2125</span>
<span class="normal">2126</span>
<span class="normal">2127</span>
<span class="normal">2128</span>
<span class="normal">2129</span>
<span class="normal">2130</span>
<span class="normal">2131</span>
<span class="normal">2132</span>
<span class="normal">2133</span>
<span class="normal">2134</span>
<span class="normal">2135</span>
<span class="normal">2136</span>
<span class="normal">2137</span>
<span class="normal">2138</span>
<span class="normal">2139</span>
<span class="normal">2140</span>
<span class="normal">2141</span>
<span class="normal">2142</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python</span>
<span id="2"><span class="c1"># coding: utf-8</span></span>
<span id="3"></span>
<span id="4"><span class="c1"># # Before Starting:</span></span>
<span id="5"><span class="c1"># </span></span>
<span id="6"><span class="c1"># If you liked this kernel please don&#39;t forget to upvote the project, this will keep me motivated to other kernels in the future. I hope you enjoy our deep exploration into this dataset. Let&#39;s begin!</span></span>
<span id="7"></span>
<span id="8"><span class="c1"># # **Credit Card Fraud Detection**</span></span>
<span id="9"><span class="c1"># **Anonymized credit card transactions labeled as fraudulent or genuine**</span></span>
<span id="10"><span class="c1"># </span></span>
<span id="11"><span class="c1"># &lt;img src=&quot;https://i.imgur.com/lBuWqxx.png&quot; /&gt;</span></span>
<span id="12"></span>
<span id="13"><span class="c1"># # Table of Contents</span></span>
<span id="14"><span class="c1"># </span></span>
<span id="15"><span class="c1"># - [Credit Card Fraud Detection Introduction](#introduction)</span></span>
<span id="16"><span class="c1"># - [Dataset Understanding](#dataset)</span></span>
<span id="17"><span class="c1"># - [Exploratory Data Analysis](#eda)</span></span>
<span id="18"><span class="c1">#     - [Feature Scaling](#feature)</span></span>
<span id="19"><span class="c1">#     - [Concise Summary](#info)</span></span>
<span id="20"><span class="c1">#     - [Uique Labels](#unique)</span></span>
<span id="21"><span class="c1">#     - [Descriptive Statistics](#describe)</span></span>
<span id="22"><span class="c1">#     - [Finding null values](#null)</span></span>
<span id="23"><span class="c1">#     - [Distribution of Amount](#amountdist)</span></span>
<span id="24"><span class="c1">#     - [Removal of Outliers](#outliers)</span></span>
<span id="25"><span class="c1">#     - [Categorical vs Continuous Features](#catcont)</span></span>
<span id="26"><span class="c1">#     - [Correlation Among Explanatory Variables](#corr)</span></span>
<span id="27"><span class="c1"># - [Feature Engineering](#feateng)</span></span>
<span id="28"><span class="c1">#     - [Feature engineering on Time](#timefeateng)</span></span>
<span id="29"><span class="c1"># - [Scaling](#scaleamount)</span></span>
<span id="30"><span class="c1">#     - [Scale amount by Log](#scalelog)</span></span>
<span id="31"><span class="c1">#     - [Scale  amount by Standardization](#scalestand)</span></span>
<span id="32"><span class="c1">#     - [Scale  amount by Normalization](scalenorm)</span></span>
<span id="33"><span class="c1"># - [Saving preprossed data](#pickle)</span></span>
<span id="34"><span class="c1"># - [Split data](#splitdata)</span></span>
<span id="35"><span class="c1"># - [Baseline for models](#modelbaseline)</span></span>
<span id="36"><span class="c1"># - [Class Imbalance](#classimbalance)</span></span>
<span id="37"><span class="c1">#     - [Under Sampling and Over Sampling](#undovrsamp)</span></span>
<span id="38"><span class="c1">#     - [Synthetic Minority OverSampling Technique (SMOTE)](#smote)</span></span>
<span id="39"><span class="c1">#     - [Adaptive Synthetic Sampling Method for Imbalanced Data (ADASYN)](#adasyn)</span></span>
<span id="40"><span class="c1"># - [Model Building](#modelbuild)</span></span>
<span id="41"><span class="c1">#     - [Logistic Regression](#logreg)</span></span>
<span id="42"><span class="c1">#         - [Logistic Regression with imbalanced data](#logregim)</span></span>
<span id="43"><span class="c1">#             - [Model Evolution](#modevel)</span></span>
<span id="44"><span class="c1">#             - [Model Evolution Matrix](#modevelmatrix)</span></span>
<span id="45"><span class="c1">#             - [Receiver Operating Characteristics (ROC)](#roccurve)</span></span>
<span id="46"><span class="c1">#         - [Logistic Regression with Random Undersampling technique](#logregundsamp)</span></span>
<span id="47"><span class="c1">#         - [Logistic Regression with Random Oversampling technique](#logregovrsamp)</span></span>
<span id="48"><span class="c1">#         - [Logistic Regression with SMOTE technique](#logregsomote)</span></span>
<span id="49"><span class="c1">#         - [Logistic Regression with ADASYN technique](#logregadasyn)</span></span>
<span id="50"><span class="c1"># - [Spatial nature of class imbalance](#spatial)</span></span>
<span id="51"><span class="c1">#     - [Distribution of balaced dataset](#distimbds)</span></span>
<span id="52"><span class="c1">#     - [Distribution of balaced dataset](#distbalds)</span></span>
<span id="53"><span class="c1"># - [Building different models with different balanced datasets](#modelwith)</span></span>
<span id="54"><span class="c1">#     - [Undersampled Data](#usdata)</span></span>
<span id="55"><span class="c1">#     - [Oversampled Data](#osdata)</span></span>
<span id="56"><span class="c1">#     - [SMOTE Data](#smotedata)</span></span>
<span id="57"><span class="c1">#     - [ADASYN Data](#adasyndata)</span></span>
<span id="58"><span class="c1"># - [Grid Search](#)</span></span>
<span id="59"><span class="c1">#     - [Grid Search with Logistic Regression](#gridsearchLR)</span></span>
<span id="60"><span class="c1">#     - [Grid Search with K Nearest Neighbour Classifier](#gridsearchKNN)</span></span>
<span id="61"><span class="c1">#     - [Grid Search with Support Vector Classifier](#gridsearchSVC)</span></span>
<span id="62"><span class="c1">#     - [Grid Search with Decision Tree Classifier](#gridsearchDT)</span></span>
<span id="63"><span class="c1"># - [Conclusion](#concl)</span></span>
<span id="64"></span>
<span id="65"><span class="c1"># # &lt;a id=&#39;introduction&#39;&gt;Introduction&lt;/a&gt;</span></span>
<span id="66"><span class="c1"># </span></span>
<span id="67"><span class="c1"># It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase. Eventually, it is also important for companies NOT to detect transactions which are genuine as fraudulent, otherwise, companies would keep blocking the credit card, and which may lead to customer dissatisfaction. So here are two important expects of this analysis:</span></span>
<span id="68"><span class="c1"># </span></span>
<span id="69"><span class="c1"># * What would happen when the company will not able to detect the fraudulent transaction and would not confirm from a customer about this recent transaction whether it was made by him/her.</span></span>
<span id="70"><span class="c1"># </span></span>
<span id="71"><span class="c1"># * In contract, what would happen when the company will detect a genuine transaction as fraudulent and keep calling customer for confirmation or might block thecard.</span></span>
<span id="72"><span class="c1"># </span></span>
<span id="73"><span class="c1"># The datasets contain transactions that have 492 frauds out of 284,807 transactions. So the dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions. When we try to build the prediction model with this kindof unbalanced dataset, then the model will be more inclined towards to detect new unseen transaction as genuine as our dataset contains about 99% genuine data.</span></span>
<span id="74"><span class="c1"># </span></span>
<span id="75"><span class="c1"># As our dataset is highly imbalanced, so we shouldn&#39;t use accuracy score as a metric because it will be usually high and misleading, instead use we should focus on f1-score, precision/recall score or confusion matrix.</span></span>
<span id="76"></span>
<span id="77"><span class="c1"># # &lt;a id=&#39;dataset&#39;&gt;Load Data&lt;/a&gt;</span></span>
<span id="78"></span>
<span id="79"><span class="c1"># In[1]:</span></span>
<span id="80"></span>
<span id="81"></span>
<span id="82"><span class="c1"># Import Libraries</span></span>
<span id="83"><span class="kn">import</span> <span class="nn">warnings</span></span>
<span id="84"><span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span></span>
<span id="85"></span>
<span id="86"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span></span>
<span id="87"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span></span>
<span id="88"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span></span>
<span id="89"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span></span>
<span id="90"><span class="c1"># import cufflinks as cf</span></span>
<span id="91"><span class="kn">import</span> <span class="nn">plotly</span></span>
<span id="92"><span class="kn">import</span> <span class="nn">datetime</span></span>
<span id="93"><span class="kn">import</span> <span class="nn">math</span></span>
<span id="94"><span class="kn">import</span> <span class="nn">matplotlib</span></span>
<span id="95"><span class="kn">import</span> <span class="nn">sklearn</span></span>
<span id="96"><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span></span>
<span id="97"><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span></span>
<span id="98"></span>
<span id="99"><span class="kn">import</span> <span class="nn">pickle</span></span>
<span id="100"><span class="kn">import</span> <span class="nn">os</span></span>
<span id="101"></span>
<span id="102"><span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="nn">px</span></span>
<span id="103"><span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="nn">go</span></span>
<span id="104"><span class="kn">import</span> <span class="nn">plotly.figure_factory</span> <span class="k">as</span> <span class="nn">ff</span></span>
<span id="105"><span class="kn">from</span> <span class="nn">plotly.subplots</span> <span class="kn">import</span> <span class="n">make_subplots</span></span>
<span id="106"></span>
<span id="107"><span class="c1"># Print versions of libraries</span></span>
<span id="108"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Numpy version : Numpy </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></span>
<span id="109"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pandas version : Pandas </span><span class="si">{</span><span class="n">pd</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></span>
<span id="110"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Matplotlib version : Matplotlib </span><span class="si">{</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></span>
<span id="111"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Seaborn version : Seaborn </span><span class="si">{</span><span class="n">sns</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></span>
<span id="112"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SkLearn version : SkLearn </span><span class="si">{</span><span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></span>
<span id="113"><span class="c1"># print(f&quot;Cufflinks version : cufflinks {cf.__version__}&quot;)</span></span>
<span id="114"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Plotly version : plotly </span><span class="si">{</span><span class="n">plotly</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></span>
<span id="115"></span>
<span id="116"><span class="c1"># Magic Functions for In-Notebook Display</span></span>
<span id="117"><span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">&#39;matplotlib&#39;</span><span class="p">,</span> <span class="s1">&#39;inline&#39;</span><span class="p">)</span></span>
<span id="118"></span>
<span id="119"><span class="c1"># Setting seabon style</span></span>
<span id="120"><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;darkgrid&#39;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;colorblind&#39;</span><span class="p">)</span></span>
<span id="121"></span>
<span id="122"></span>
<span id="123"><span class="c1"># ## Import the Dataset</span></span>
<span id="124"></span>
<span id="125"><span class="c1"># In[2]:</span></span>
<span id="126"></span>
<span id="127"></span>
<span id="128"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../input/creditcardfraud/creditcard.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;latin_1&#39;</span><span class="p">)</span></span>
<span id="129"></span>
<span id="130"></span>
<span id="131"><span class="c1"># In[3]:</span></span>
<span id="132"></span>
<span id="133"></span>
<span id="134"><span class="c1"># Converting all column names to lower case</span></span>
<span id="135"><span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span></span>
<span id="136"></span>
<span id="137"></span>
<span id="138"><span class="c1"># In[4]:</span></span>
<span id="139"></span>
<span id="140"></span>
<span id="141"><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></span>
<span id="142"></span>
<span id="143"></span>
<span id="144"><span class="c1"># In[5]:</span></span>
<span id="145"></span>
<span id="146"></span>
<span id="147"><span class="n">df</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span></span>
<span id="148"></span>
<span id="149"></span>
<span id="150"><span class="c1"># * **Due to confidentiality issue, original features V1, V2,... V28 have been transformed with PCA, however, we may guess that these features might be originally credit card number, expiry date, CVV, cardholder name, transaction location, transaction date-time, etc.** </span></span>
<span id="151"><span class="c1"># </span></span>
<span id="152"><span class="c1"># * The only features which have not been transformed with PCA are &#39;Time&#39; and &#39;Amount&#39;. Feature &#39;Time&#39; contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature &#39;Amount&#39; is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. </span></span>
<span id="153"><span class="c1"># </span></span>
<span id="154"><span class="c1"># * Feature &#39;Class&#39; is the response variable and it takes value 1 in case of fraud and 0 otherwise.</span></span>
<span id="155"></span>
<span id="156"><span class="c1"># In[6]:</span></span>
<span id="157"></span>
<span id="158"></span>
<span id="159"><span class="c1"># Customising default values to view all columns</span></span>
<span id="160"><span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">100</span></span>
<span id="161"><span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_columns</span> <span class="o">=</span> <span class="mi">100</span></span>
<span id="162"></span>
<span id="163"><span class="c1"># pd.set_option(&#39;display.max_rows&#39;,1000)</span></span>
<span id="164"></span>
<span id="165"></span>
<span id="166"><span class="c1"># In[7]:</span></span>
<span id="167"></span>
<span id="168"></span>
<span id="169"><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span></span>
<span id="170"></span>
<span id="171"></span>
<span id="172"><span class="c1"># # &lt;a id=&#39;eda&#39;&gt;Exploratory Data Analysis&lt;/a&gt;</span></span>
<span id="173"><span class="c1"># </span></span>
<span id="174"><span class="c1"># Once the data is read into python, we need to explore/clean/filter it before processing it for machine learning It involves adding/deleting few columns or rows, joining some other data, and handling qualitative variables like dates.</span></span>
<span id="175"><span class="c1"># </span></span>
<span id="176"><span class="c1"># Now that we have the data, I wanted to run a few initial comparisons between the three columns - Time, Amount, and Class.</span></span>
<span id="177"></span>
<span id="178"><span class="c1"># ## &lt;a id=&#39;info&#39;&gt;Checking concise summary of dataset&lt;/a&gt;</span></span>
<span id="179"><span class="c1"># </span></span>
<span id="180"><span class="c1"># It is also a good practice to know the features and their corresponding data types, along with finding whether they contain null values or not.</span></span>
<span id="181"></span>
<span id="182"><span class="c1"># In[8]:</span></span>
<span id="183"></span>
<span id="184"></span>
<span id="185"><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span></span>
<span id="186"></span>
<span id="187"></span>
<span id="188"><span class="c1"># **Highlights**</span></span>
<span id="189"><span class="c1"># </span></span>
<span id="190"><span class="c1"># * Dataset contains details of 284807 transactions with 31 features.</span></span>
<span id="191"><span class="c1"># * There is no missing data in our dataset, every column contain exactly 284807 rows.</span></span>
<span id="192"><span class="c1"># * All data types are float64, except 1: Class </span></span>
<span id="193"><span class="c1"># * All data types are float64, except 1: Class </span></span>
<span id="194"><span class="c1"># * 28 columns have Sequential Names and values that don&#39;t make any logical sense - &gt; V1, V2 ....V28</span></span>
<span id="195"><span class="c1"># * 3 columns: TIME, AMOUNT and CLASS which can be analysed for various INSIGHTS! </span></span>
<span id="196"><span class="c1"># * Memory Usage: 67.4 MB, not so Harsh !!</span></span>
<span id="197"></span>
<span id="198"><span class="c1"># ## &lt;a id=&#39;unique&#39;&gt;Count unique values of label&lt;/a&gt;</span></span>
<span id="199"></span>
<span id="200"><span class="c1"># In[9]:</span></span>
<span id="201"></span>
<span id="202"></span>
<span id="203"><span class="nb">print</span><span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()))</span></span>
<span id="204"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span></span>
<span id="205"><span class="nb">print</span><span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)))</span></span>
<span id="206"></span>
<span id="207"></span>
<span id="208"><span class="c1"># In[10]:</span></span>
<span id="209"></span>
<span id="210"></span>
<span id="211"><span class="n">df</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s1">&#39;pie&#39;</span><span class="p">,</span><span class="n">explode</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span><span class="n">autopct</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%1.1f%%</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">shadow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></span>
<span id="212"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Fraudulent and Non-Fraudulent Distribution&quot;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span></span>
<span id="213"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;Genuine&quot;</span><span class="p">])</span></span>
<span id="214"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="215"></span>
<span id="216"></span>
<span id="217"><span class="c1"># **Highlights**</span></span>
<span id="218"><span class="c1"># </span></span>
<span id="219"><span class="c1"># This dataset has 492 frauds out of 284,315 transactions. The dataset is **highly unbalanced**, the positive class (frauds) account for 0.172% of all transactions. Most of the transactions are non-fraud. If we use this dataframe as the base for our predictive models and analysis, our algorithms will probably overfit since it will &quot;assume&quot; that most transactions are not a fraud. But we don&#39;t want our model to assume, we want our model to detect patterns that give signs of fraud!</span></span>
<span id="220"></span>
<span id="221"><span class="c1"># ## &lt;a id=&#39;describe&#39;&gt;Generate descriptive statistics&lt;/a&gt;</span></span>
<span id="222"><span class="c1"># </span></span>
<span id="223"><span class="c1"># The describe() function generates descriptive statistics that summarize the central tendency, dispersion and shape of a dataset&#39;s distribution, excluding ``NaN`` values.</span></span>
<span id="224"><span class="c1"># </span></span>
<span id="225"><span class="c1"># Let&#39;s summarize the central tendency, dispersion and shape of a dataset&#39;s distribution. Out of all the columns, the only ones that made the most sense were Time, Amount, and Class (fraud or not fraud). The other 28 columns were transformed using what seems to be a PCA dimensionality reduction in order to protect user identities.</span></span>
<span id="226"><span class="c1"># </span></span>
<span id="227"><span class="c1"># The data itself is short in terms of time (its only 2 days long), and these transactions were made by European cardholders.</span></span>
<span id="228"></span>
<span id="229"><span class="c1"># In[11]:</span></span>
<span id="230"></span>
<span id="231"></span>
<span id="232"><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;time&#39;</span><span class="p">,</span><span class="s1">&#39;amount&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span></span>
<span id="233"></span>
<span id="234"></span>
<span id="235"><span class="c1"># **Highlights**</span></span>
<span id="236"><span class="c1"># * On an average, credit card transaction is happening at every 94813.86 seconds.</span></span>
<span id="237"><span class="c1"># * Average transaction amount is 88.35 with a standard deviation of 250, with a minimum amount of 0.0 and the maximum amount 25,691.16. By seeing the 75% and the maximum amount, it looks like the feature &#39;Amount&#39; is highly ** positively skewed**. We will check the distribution graph of the amount to get more clarity.</span></span>
<span id="238"></span>
<span id="239"><span class="c1"># ## &lt;a id=&#39;null&#39;&gt;Finding null values&lt;/a&gt;</span></span>
<span id="240"></span>
<span id="241"><span class="c1"># In[12]:</span></span>
<span id="242"></span>
<span id="243"></span>
<span id="244"><span class="c1"># Dealing with missing data</span></span>
<span id="245"><span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span></span>
<span id="246"></span>
<span id="247"></span>
<span id="248"><span class="c1"># **Highlights**</span></span>
<span id="249"><span class="c1"># </span></span>
<span id="250"><span class="c1"># There are no missing values present in the dataset. It is not necessary that missing values are present in the dataset in the form of NA, NAN, Zeroes etc, it may be present by some other values also that can be explored by analysing each feature.</span></span>
<span id="251"></span>
<span id="252"><span class="c1"># ## &lt;a id=&#39;amountdist&#39;&gt;Distribution of Amount&lt;a id=&#39;&#39;&gt;</span></span>
<span id="253"></span>
<span id="254"><span class="c1"># In[13]:</span></span>
<span id="255"></span>
<span id="256"></span>
<span id="257"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span></span>
<span id="258"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of Transaction Amount&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span></span>
<span id="259"><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;amount&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span></span>
<span id="260"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="261"></span>
<span id="262"></span>
<span id="263"><span class="c1"># **Highlights**</span></span>
<span id="264"><span class="c1"># </span></span>
<span id="265"><span class="c1"># Most the transaction amount falls between 0 and about 3000 and we have some outliers for really big amount transactions and it may actually make sense to drop those outliers in our analysis if they are just a few points that are very extreme.</span></span>
<span id="266"><span class="c1"># </span></span>
<span id="267"><span class="c1"># Most daily transactions are not extremely expensive, but its likely where most fraudulent transactions are occurring as well.</span></span>
<span id="268"></span>
<span id="269"><span class="c1"># ### Distribution of Amount for Fradulent &amp; Genuine transactions</span></span>
<span id="270"></span>
<span id="271"><span class="c1"># In[14]:</span></span>
<span id="272"></span>
<span id="273"></span>
<span id="274"><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span></span>
<span id="275"><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="s1">&#39;amount&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></span>
<span id="276"><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distribution of Fraud Transactions&quot;</span><span class="p">)</span></span>
<span id="277"></span>
<span id="278"><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s1">&#39;amount&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></span>
<span id="279"><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distribution of Genuine Transactions&quot;</span><span class="p">)</span></span>
<span id="280"></span>
<span id="281"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="282"></span>
<span id="283"></span>
<span id="284"><span class="c1"># **Highlights**</span></span>
<span id="285"><span class="c1"># </span></span>
<span id="286"><span class="c1"># This graph shows that most of the fraud transaction amount is less than 500 dollars. This also shows that the fraud transaction is very high for an amount near to 0, let&#39;s find that amount.</span></span>
<span id="287"></span>
<span id="288"><span class="c1"># In[15]:</span></span>
<span id="289"></span>
<span id="290"></span>
<span id="291"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Fraud Transaction distribution : </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)][</span><span class="s1">&#39;amount&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">()))</span></span>
<span id="292"><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span></span>
<span id="293"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Maximum amount of fraud transaction - &quot;</span><span class="p">,</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)][</span><span class="s1">&#39;amount&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()))</span></span>
<span id="294"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Minimum amount of fraud transaction - &quot;</span><span class="p">,</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)][</span><span class="s1">&#39;amount&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()))</span></span>
<span id="295"></span>
<span id="296"></span>
<span id="297"><span class="c1"># **Highlights**</span></span>
<span id="298"><span class="c1"># </span></span>
<span id="299"><span class="c1"># * There are 113 fraud transactions for just one dollor and 27 fraud transaction for $99.99. And higest fraud transaction amount was 2125.87 and lowest was just 0.00.</span></span>
<span id="300"><span class="c1"># * There are 27 fraud transaction for zero amount. Zero Authorization is an account verification method for credit cards that is used to verify a cardholders information without charging the consumer. Instead, an amount of zero is charged on the card to store the credit card information in the form of a token and to determine whether the card is legitimate or not. After creating the token, is then possible to charge the consumer with a new transaction with either Tokenization or Recurring Payments</span></span>
<span id="301"><span class="c1"># </span></span>
<span id="302"><span class="c1"># Ref : https://docs.multisafepay.com/tools/zero-authorization/what-is-zero-authorization/</span></span>
<span id="303"></span>
<span id="304"><span class="c1"># In[16]:</span></span>
<span id="305"></span>
<span id="306"></span>
<span id="307"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Genuine Transaction distribution : </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)][</span><span class="s1">&#39;amount&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">()))</span></span>
<span id="308"><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span></span>
<span id="309"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Maximum amount of Genuine transaction - &quot;</span><span class="p">,</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)][</span><span class="s1">&#39;amount&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()))</span></span>
<span id="310"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Minimum amount of Genuine transaction - &quot;</span><span class="p">,</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)][</span><span class="s1">&#39;amount&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()))</span></span>
<span id="311"></span>
<span id="312"></span>
<span id="313"><span class="c1"># ### Distribution of Amount w.r.t Class</span></span>
<span id="314"></span>
<span id="315"><span class="c1"># In[17]:</span></span>
<span id="316"></span>
<span id="317"></span>
<span id="318"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span></span>
<span id="319"><span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;class&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;amount&#39;</span><span class="p">,</span><span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">)</span></span>
<span id="320"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Amount Distribution for Fraud and Genuine transactions&#39;</span><span class="p">)</span></span>
<span id="321"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="322"></span>
<span id="323"></span>
<span id="324"><span class="c1"># **Highlights**</span></span>
<span id="325"><span class="c1"># </span></span>
<span id="326"><span class="c1"># Most the transaction amount falls between 0 and about 3000 and we have some outliers for really big amount transactions and it may actually make sense to drop those outliers in our analysis if they are just a few points that are very extreme. Also, we should be conscious about that these **outliers should not be the fraudulent transaction**. Generally, fraudulent transactions of the very big amount and removing them from the data can make the predicting model bais. </span></span>
<span id="327"><span class="c1"># </span></span>
<span id="328"><span class="c1"># So we can essentially build a model that realistically predicts transaction as fraud without affected by outliers. It may not be really useful to actually have our model train on these extreme outliers.</span></span>
<span id="329"></span>
<span id="330"><span class="c1"># ## &lt;a id=&#39;timedist&#39;&gt;Distribution of Time&lt;/a&gt;</span></span>
<span id="331"></span>
<span id="332"><span class="c1"># In[18]:</span></span>
<span id="333"></span>
<span id="334"></span>
<span id="335"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span></span>
<span id="336"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of Transaction Time&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span></span>
<span id="337"><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span></span>
<span id="338"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="339"></span>
<span id="340"></span>
<span id="341"><span class="c1"># **Highlights**</span></span>
<span id="342"><span class="c1"># </span></span>
<span id="343"><span class="c1"># By seeing the graph, we can see there are two peaks in the graph and even there are some local peaks. We can think of these as the time of the day like the peak is the day time when most people do the transactions and the depth is the night time when most people just sleeps. We already know that data contains a credit card transaction for only two days, so there are two peaks for day time and one depth for one night time.</span></span>
<span id="344"></span>
<span id="345"><span class="c1"># ### Distribution of time w.r.t. transactions types</span></span>
<span id="346"></span>
<span id="347"><span class="c1"># In[19]:</span></span>
<span id="348"></span>
<span id="349"></span>
<span id="350"><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span></span>
<span id="351"></span>
<span id="352"><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)][</span><span class="s1">&#39;time&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></span>
<span id="353"><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distribution of Fraud Transactions&quot;</span><span class="p">)</span></span>
<span id="354"></span>
<span id="355"><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)][</span><span class="s1">&#39;time&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span></span>
<span id="356"><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distribution of Genuine Transactions&quot;</span><span class="p">)</span></span>
<span id="357"></span>
<span id="358"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="359"></span>
<span id="360"></span>
<span id="361"><span class="c1"># In[20]:</span></span>
<span id="362"></span>
<span id="363"></span>
<span id="364"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span></span>
<span id="365"><span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;class&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;time&#39;</span><span class="p">,</span><span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">)</span></span>
<span id="366"></span>
<span id="367"><span class="c1"># Change the appearance of that box</span></span>
<span id="368"><span class="n">ax</span><span class="o">.</span><span class="n">artists</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;#90EE90&#39;</span><span class="p">)</span></span>
<span id="369"><span class="n">ax</span><span class="o">.</span><span class="n">artists</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;#FA8072&#39;</span><span class="p">)</span></span>
<span id="370"></span>
<span id="371"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Time Distribution for Fraud and Genuine transactions&#39;</span><span class="p">)</span></span>
<span id="372"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="373"></span>
<span id="374"></span>
<span id="375"><span class="c1"># ### Distribution of transaction type w.r.t amount</span></span>
<span id="376"></span>
<span id="377"><span class="c1"># In[21]:</span></span>
<span id="378"></span>
<span id="379"></span>
<span id="380"><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span></span>
<span id="381"></span>
<span id="382"><span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;time&#39;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s1">&#39;amount&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></span>
<span id="383"><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distribution of Fraud Transactions&quot;</span><span class="p">)</span></span>
<span id="384"></span>
<span id="385"><span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;time&#39;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s1">&#39;amount&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span></span>
<span id="386"><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distribution of Genue Transactions&quot;</span><span class="p">)</span></span>
<span id="387"></span>
<span id="388"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="389"></span>
<span id="390"></span>
<span id="391"><span class="c1"># ## &lt;a id=&#39;catcont&#39;&gt;Categorical vs Continuous Features&lt;/a&gt;</span></span>
<span id="392"><span class="c1"># </span></span>
<span id="393"><span class="c1"># Finding unique values for each column to understand which column is categorical and which one is Continuous</span></span>
<span id="394"></span>
<span id="395"><span class="c1"># In[22]:</span></span>
<span id="396"></span>
<span id="397"></span>
<span id="398"><span class="c1"># Finging unique values for each column</span></span>
<span id="399"><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;time&#39;</span><span class="p">,</span><span class="s1">&#39;amount&#39;</span><span class="p">,</span><span class="s1">&#39;class&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span></span>
<span id="400"></span>
<span id="401"></span>
<span id="402"><span class="c1"># In[23]:</span></span>
<span id="403"></span>
<span id="404"></span>
<span id="405"><span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;time&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;amount&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;class&quot;</span><span class="p">,</span> </span>
<span id="406">                 <span class="n">marginal_y</span><span class="o">=</span><span class="s2">&quot;violin&quot;</span><span class="p">,</span><span class="n">marginal_x</span><span class="o">=</span><span class="s2">&quot;box&quot;</span><span class="p">,</span> <span class="n">trendline</span><span class="o">=</span><span class="s2">&quot;ols&quot;</span><span class="p">,</span> <span class="n">template</span><span class="o">=</span><span class="s2">&quot;simple_white&quot;</span><span class="p">)</span></span>
<span id="407"><span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="408"></span>
<span id="409"></span>
<span id="410"><span class="c1"># ## &lt;a id=&#39;corr&#39;&gt;Correlation Among Explanatory Variables&lt;/a&gt;</span></span>
<span id="411"><span class="c1"># </span></span>
<span id="412"><span class="c1"># Having **too many features** in a model is not always a good thing because it might cause overfitting and worse results when we want to predict values for a new dataset. Thus, **if a feature does not improve your model a lot, not adding it may be a better choice.**</span></span>
<span id="413"><span class="c1"># </span></span>
<span id="414"><span class="c1"># Another important thing is **correlation. If there is a very high correlation between two features, keeping both of them is not a good idea most of the time not to cause overfitting.** However, this does not mean that you must remove one of the highly correlated features. </span></span>
<span id="415"><span class="c1"># </span></span>
<span id="416"><span class="c1"># Let&#39;s find out top 10 features which are highly correlated with a price.</span></span>
<span id="417"></span>
<span id="418"><span class="c1"># In[24]:</span></span>
<span id="419"></span>
<span id="420"></span>
<span id="421"><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;time&#39;</span><span class="p">,</span><span class="s1">&#39;amount&#39;</span><span class="p">,</span><span class="s1">&#39;class&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">corr</span><span class="p">()[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span></span>
<span id="422"></span>
<span id="423"></span>
<span id="424"><span class="c1"># In[25]:</span></span>
<span id="425"></span>
<span id="426"></span>
<span id="427"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Pearson Correlation Matrix&#39;</span><span class="p">)</span></span>
<span id="428"><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;time&#39;</span><span class="p">,</span> <span class="s1">&#39;amount&#39;</span><span class="p">,</span><span class="s1">&#39;class&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span><span class="n">linewidths</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span><span class="n">square</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;winter&quot;</span><span class="p">,</span></span>
<span id="429">            <span class="n">linecolor</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span><span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span></span>
<span id="430"></span>
<span id="431"></span>
<span id="432"><span class="c1"># **Highlights**</span></span>
<span id="433"><span class="c1"># </span></span>
<span id="434"><span class="c1"># It looks like that no features are highly correlated with any other features.</span></span>
<span id="435"></span>
<span id="436"><span class="c1"># ## Lets check the data again after cleaning</span></span>
<span id="437"></span>
<span id="438"><span class="c1"># In[26]:</span></span>
<span id="439"></span>
<span id="440"></span>
<span id="441"><span class="n">df</span><span class="o">.</span><span class="n">shape</span></span>
<span id="442"></span>
<span id="443"></span>
<span id="444"><span class="c1"># In[27]:</span></span>
<span id="445"></span>
<span id="446"></span>
<span id="447"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></span>
<span id="448"></span>
<span id="449"></span>
<span id="450"><span class="c1"># # &lt;a id=&#39;feateng&#39;&gt;Feature Engineering&lt;/a&gt; </span></span>
<span id="451"></span>
<span id="452"><span class="c1"># ## &lt;a id=&#39;timefeateng&#39;&gt;Feature engineering on Time&lt;/a&gt;</span></span>
<span id="453"></span>
<span id="454"><span class="c1"># ### Converting time from second to hour</span></span>
<span id="455"></span>
<span id="456"><span class="c1"># In[28]:</span></span>
<span id="457"></span>
<span id="458"></span>
<span id="459"><span class="c1"># Converting time from second to hour</span></span>
<span id="460"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">sec</span> <span class="p">:</span> <span class="p">(</span><span class="n">sec</span><span class="o">/</span><span class="mi">3600</span><span class="p">))</span></span>
<span id="461"></span>
<span id="462"></span>
<span id="463"><span class="c1"># ### Calculating hour of the day</span></span>
<span id="464"></span>
<span id="465"><span class="c1"># In[29]:</span></span>
<span id="466"></span>
<span id="467"></span>
<span id="468"><span class="c1"># Calculating hour of the day</span></span>
<span id="469"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;hour&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">%</span><span class="mi">24</span>   <span class="c1"># 2 days of data</span></span>
<span id="470"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;hour&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;hour&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">x</span><span class="p">))</span></span>
<span id="471"></span>
<span id="472"></span>
<span id="473"><span class="c1"># ### Calculating First and Second Day</span></span>
<span id="474"></span>
<span id="475"><span class="c1"># In[30]:</span></span>
<span id="476"></span>
<span id="477"></span>
<span id="478"><span class="c1"># Calculating First and Second day</span></span>
<span id="479"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;day&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">/</span><span class="mi">24</span>   <span class="c1"># 2 days of data</span></span>
<span id="480"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;day&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;day&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="mi">1</span> <span class="k">if</span><span class="p">(</span><span class="n">x</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="k">else</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">x</span><span class="p">))</span></span>
<span id="481"></span>
<span id="482"></span>
<span id="483"><span class="c1"># In[31]:</span></span>
<span id="484"></span>
<span id="485"></span>
<span id="486"><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;time&#39;</span><span class="p">,</span><span class="s1">&#39;hour&#39;</span><span class="p">,</span><span class="s1">&#39;day&#39;</span><span class="p">,</span><span class="s1">&#39;amount&#39;</span><span class="p">,</span><span class="s1">&#39;class&#39;</span><span class="p">]]</span></span>
<span id="487"></span>
<span id="488"></span>
<span id="489"><span class="c1"># ### Fraud and Genuine transaction Day wise</span></span>
<span id="490"></span>
<span id="491"><span class="c1"># In[32]:</span></span>
<span id="492"></span>
<span id="493"></span>
<span id="494"><span class="c1"># calculating fraud transaction daywise</span></span>
<span id="495"><span class="n">dayFrdTran</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)][</span><span class="s1">&#39;day&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span></span>
<span id="496"></span>
<span id="497"><span class="c1"># calculating genuine transaction daywise</span></span>
<span id="498"><span class="n">dayGenuTran</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)][</span><span class="s1">&#39;day&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span></span>
<span id="499"></span>
<span id="500"><span class="c1"># calculating total transaction daywise</span></span>
<span id="501"><span class="n">dayTran</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;day&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span></span>
<span id="502"></span>
<span id="503"><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No of transaction Day wise:&quot;</span><span class="p">)</span></span>
<span id="504"><span class="nb">print</span><span class="p">(</span><span class="n">dayTran</span><span class="p">)</span></span>
<span id="505"></span>
<span id="506"><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span></span>
<span id="507"></span>
<span id="508"><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No of fraud transaction Day wise:&quot;</span><span class="p">)</span></span>
<span id="509"><span class="nb">print</span><span class="p">(</span><span class="n">dayFrdTran</span><span class="p">)</span></span>
<span id="510"></span>
<span id="511"><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span></span>
<span id="512"></span>
<span id="513"><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No of genuine transactions Day wise:&quot;</span><span class="p">)</span></span>
<span id="514"><span class="nb">print</span><span class="p">(</span><span class="n">dayGenuTran</span><span class="p">)</span></span>
<span id="515"></span>
<span id="516"><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span></span>
<span id="517"></span>
<span id="518"><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Percentage of fraud transactions Day wise:&quot;</span><span class="p">)</span></span>
<span id="519"><span class="nb">print</span><span class="p">(((</span><span class="n">dayFrdTran</span><span class="o">/</span><span class="n">dayTran</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span></span>
<span id="520"></span>
<span id="521"></span>
<span id="522"><span class="c1"># **Highlights**</span></span>
<span id="523"><span class="c1"># </span></span>
<span id="524"><span class="c1"># * Total number of transaction on Day 1 was 144787, out of which 281 was a fraud and 144506 was genuine. Fraud transaction was 0.19% of the total transaction on day 1.</span></span>
<span id="525"><span class="c1"># </span></span>
<span id="526"><span class="c1"># * Total number of transaction on Day 2 was 140020, out of which 211 was a fraud and 139809 was genuine. Fraud transaction was 0.15% of the total transaction on day 2.</span></span>
<span id="527"><span class="c1"># </span></span>
<span id="528"><span class="c1"># * Most of the transaction including the fraud transaction happened on day 1.</span></span>
<span id="529"><span class="c1"># </span></span>
<span id="530"><span class="c1"># Let&#39;s see the above numbers in the graph.</span></span>
<span id="531"></span>
<span id="532"><span class="c1"># In[33]:</span></span>
<span id="533"></span>
<span id="534"></span>
<span id="535"><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span></span>
<span id="536"></span>
<span id="537"><span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;day&#39;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></span>
<span id="538"><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distribution of Total Transactions&quot;</span><span class="p">)</span></span>
<span id="539"></span>
<span id="540"><span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)][</span><span class="s1">&#39;day&#39;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span></span>
<span id="541"><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distribution of Fraud Transactions&quot;</span><span class="p">)</span></span>
<span id="542"></span>
<span id="543"><span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)][</span><span class="s1">&#39;day&#39;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span></span>
<span id="544"><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Distribution of Genuine Transactions&quot;</span><span class="p">)</span></span>
<span id="545"></span>
<span id="546"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="547"></span>
<span id="548"></span>
<span id="549"><span class="c1"># In[34]:</span></span>
<span id="550"></span>
<span id="551"></span>
<span id="552"><span class="c1"># Time plots </span></span>
<span id="553"><span class="n">fig</span> <span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span> <span class="o">=</span> <span class="mi">1</span> <span class="p">,</span> <span class="n">ncols</span> <span class="o">=</span> <span class="mi">2</span> <span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span></span>
<span id="554"></span>
<span id="555"><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;green&#39;</span> <span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></span>
<span id="556"><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Genuine Transactions&#39;</span><span class="p">)</span></span>
<span id="557"></span>
<span id="558"><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span> <span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span></span>
<span id="559"><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Fraud Transactions&#39;</span><span class="p">)</span></span>
<span id="560"></span>
<span id="561"><span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Comparison between Transaction Frequencies vs Time for Fraud and Genuine Transactions&#39;</span><span class="p">)</span></span>
<span id="562"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="563"></span>
<span id="564"></span>
<span id="565"><span class="c1"># In[35]:</span></span>
<span id="566"></span>
<span id="567"></span>
<span id="568"><span class="c1"># Let&#39;s see if we find any particular pattern between time ( in hours ) and Fraud vs Genuine Transactions</span></span>
<span id="569"></span>
<span id="570"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span></span>
<span id="571"></span>
<span id="572"><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s2">&quot;hour&quot;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span> <span class="c1"># Genuine - green</span></span>
<span id="573"><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="s2">&quot;hour&quot;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span> <span class="c1"># Fraudulent - Red</span></span>
<span id="574"></span>
<span id="575"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Fraud vs Genuine Transactions by Hours&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span></span>
<span id="576"><span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">25</span><span class="p">])</span></span>
<span id="577"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="578"></span>
<span id="579"></span>
<span id="580"><span class="c1"># **Highlights**</span></span>
<span id="581"><span class="c1"># </span></span>
<span id="582"><span class="c1"># **Above graph shows that most of the Fraud transactions are happening at night time (0 to 7 hours) when most of the people are sleeping and Genuine transaction are happening during day time (9 to 21 hours).**</span></span>
<span id="583"></span>
<span id="584"><span class="c1"># In[36]:</span></span>
<span id="585"></span>
<span id="586"></span>
<span id="587"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span></span>
<span id="588"><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;time&#39;</span><span class="p">,</span><span class="s1">&#39;hour&#39;</span><span class="p">,</span><span class="s1">&#39;day&#39;</span><span class="p">,</span><span class="s1">&#39;amount&#39;</span><span class="p">,</span><span class="s1">&#39;class&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;hour&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span></span>
<span id="589"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="590"></span>
<span id="591"></span>
<span id="592"><span class="c1"># ### Visualising Data for detecting any particular Pattern or Anomaly using Histogram Plots</span></span>
<span id="593"><span class="c1"># </span></span>
<span id="594"><span class="c1"># Finally visulaising all columns once and for all to observe any abnormality</span></span>
<span id="595"></span>
<span id="596"><span class="c1"># In[37]:</span></span>
<span id="597"></span>
<span id="598"></span>
<span id="599"><span class="n">df</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">25</span><span class="p">,</span><span class="mi">25</span><span class="p">))</span></span>
<span id="600"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="601"></span>
<span id="602"></span>
<span id="603"><span class="c1"># ## Reset the index</span></span>
<span id="604"></span>
<span id="605"><span class="c1"># In[38]:</span></span>
<span id="606"></span>
<span id="607"></span>
<span id="608"><span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span> <span class="p">,</span> <span class="n">drop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span></span>
<span id="609"></span>
<span id="610"></span>
<span id="611"><span class="c1"># # &lt;a id=&#39;scaleamount&#39;&gt;Scale Amount Feature&lt;/a&gt;</span></span>
<span id="612"><span class="c1"># </span></span>
<span id="613"><span class="c1"># * It is a good idea to scale the data so that the column(feature) with lesser significance might not end up dominating the objective function due to its larger range. like a column like age has a range between 0 to 80, but a column like a salary has ranged from thousands to lakhs, hence, salary column will dominate to predict the outcome even if it may not be important.</span></span>
<span id="614"><span class="c1"># * In addition, features having different unit should also be scaled thus providing each feature equal initial weightage. Like Age in years and Sales in Dollars must be brought down to a common scale before feeding it to the ML algorithm</span></span>
<span id="615"><span class="c1"># * This will result in a better prediction model.</span></span>
<span id="616"><span class="c1"># </span></span>
<span id="617"><span class="c1"># </span></span>
<span id="618"><span class="c1"># </span></span>
<span id="619"><span class="c1"># **PCA Transformation**: The description of the data says that all the features went through a PCA transformation (Dimensionality Reduction technique) except for time and amount.</span></span>
<span id="620"><span class="c1"># </span></span>
<span id="621"><span class="c1"># **Scaling**: Keep in mind that in order to implement a PCA transformation features need to be previously scaled.</span></span>
<span id="622"></span>
<span id="623"><span class="c1"># ## &lt;a id=&#39;scalelog&#39;&gt;1. Scale amount by Log&lt;/a&gt;</span></span>
<span id="624"><span class="c1"># </span></span>
<span id="625"><span class="c1"># **Scaling using the log**: There are two main reasons to use logarithmic scales in charts and graphs. </span></span>
<span id="626"><span class="c1"># * The first is to respond to skewness towards large values; i.e., cases in which one or a few points are much larger than the bulk of the data. </span></span>
<span id="627"><span class="c1"># * The second is to show per cent change or multiplicative factors.</span></span>
<span id="628"></span>
<span id="629"><span class="c1"># In[39]:</span></span>
<span id="630"></span>
<span id="631"></span>
<span id="632"><span class="c1"># Scale amount by log</span></span>
<span id="633"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;amount_log&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">amount</span> <span class="o">+</span> <span class="mf">0.01</span><span class="p">)</span></span>
<span id="634"></span>
<span id="635"></span>
<span id="636"><span class="c1"># ## &lt;a id=&#39;scalestand&#39;&gt;2. Scale  amount by Standardization&lt;/a&gt;</span></span>
<span id="637"><span class="c1"># </span></span>
<span id="638"><span class="c1"># Standardization is another scaling technique where the values are centered around the mean with a unit standard deviation. This means that the mean of the attribute becomes zero and the resultant distribution has a unit standard deviation.</span></span>
<span id="639"><span class="c1"># </span></span>
<span id="640"><span class="c1"># $$ z = \frac{x_i - \mu}{\sigma} $$</span></span>
<span id="641"></span>
<span id="642"><span class="c1"># In[40]:</span></span>
<span id="643"></span>
<span id="644"></span>
<span id="645"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span> <span class="c1"># importing a class from a module of a library</span></span>
<span id="646"></span>
<span id="647"><span class="n">ss</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span> <span class="c1"># object of the class StandardScaler ()</span></span>
<span id="648"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;amount_scaled&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;amount&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span></span>
<span id="649"></span>
<span id="650"></span>
<span id="651"><span class="c1"># ## &lt;a id=&#39;scalenorm&#39;&gt;3. Scale  amount by Normalization&lt;/a&gt;</span></span>
<span id="652"><span class="c1"># </span></span>
<span id="653"><span class="c1"># Normalization is a scaling technique in which values are shifted and rescaled so that they end up ranging between 0 and 1. It is also known as Min-Max scaling.</span></span>
<span id="654"><span class="c1"># </span></span>
<span id="655"><span class="c1"># $$ x_{norm} = \frac{x_i - x_{min}}{x_{max}-x_{min}} $$</span></span>
<span id="656"></span>
<span id="657"><span class="c1"># In[41]:</span></span>
<span id="658"></span>
<span id="659"></span>
<span id="660"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span></span>
<span id="661"></span>
<span id="662"><span class="n">mm</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span> <span class="c1"># object of the class StandardScaler ()</span></span>
<span id="663"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;amount_minmax&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mm</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;amount&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span></span>
<span id="664"></span>
<span id="665"></span>
<span id="666"><span class="c1"># In[42]:</span></span>
<span id="667"></span>
<span id="668"></span>
<span id="669"><span class="c1">#Feature engineering to a better visualization of the values</span></span>
<span id="670"></span>
<span id="671"><span class="c1"># Let&#39;s explore the Amount by Class and see the distribuition of Amount transactions</span></span>
<span id="672"><span class="n">fig</span> <span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span> <span class="o">=</span> <span class="mi">1</span> <span class="p">,</span> <span class="n">ncols</span> <span class="o">=</span> <span class="mi">4</span> <span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span></span>
<span id="673"></span>
<span id="674"><span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span><span class="s2">&quot;class&quot;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;amount&quot;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></span>
<span id="675"><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Class vs Amount&quot;</span><span class="p">)</span></span>
<span id="676"></span>
<span id="677"><span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span><span class="s2">&quot;class&quot;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;amount_log&quot;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span></span>
<span id="678"><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Class vs Log Amount&quot;</span><span class="p">)</span></span>
<span id="679"></span>
<span id="680"><span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span><span class="s2">&quot;class&quot;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;amount_scaled&quot;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span></span>
<span id="681"><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Class vs Scaled Amount&quot;</span><span class="p">)</span></span>
<span id="682"></span>
<span id="683"><span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span><span class="s2">&quot;class&quot;</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;amount_minmax&quot;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span></span>
<span id="684"><span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Class vs Min Max Amount&quot;</span><span class="p">)</span></span>
<span id="685"></span>
<span id="686"><span class="c1"># fig.suptitle(&#39;Amount by Class&#39;, fontsize=20)</span></span>
<span id="687"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="688"></span>
<span id="689"></span>
<span id="690"><span class="c1"># **Hightlights**</span></span>
<span id="691"><span class="c1"># </span></span>
<span id="692"><span class="c1"># * We can see a slight difference in the log amount of our two Classes. </span></span>
<span id="693"><span class="c1"># * The IQR of fraudulent transactions are higher than normal transactions, but normal transactions have the highest values.</span></span>
<span id="694"><span class="c1"># * **By seeing the above three graphs, I think scaling the amount by log will best suit for our model.**</span></span>
<span id="695"></span>
<span id="696"><span class="c1"># In[43]:</span></span>
<span id="697"></span>
<span id="698"></span>
<span id="699"><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;time&#39;</span><span class="p">,</span><span class="s1">&#39;hour&#39;</span><span class="p">,</span><span class="s1">&#39;day&#39;</span><span class="p">,</span><span class="s1">&#39;amount&#39;</span><span class="p">,</span><span class="s1">&#39;amount_log&#39;</span><span class="p">,</span><span class="s1">&#39;amount_scaled&#39;</span><span class="p">,</span><span class="s1">&#39;amount_minmax&#39;</span><span class="p">,</span><span class="s1">&#39;class&#39;</span><span class="p">]]</span></span>
<span id="700"></span>
<span id="701"></span>
<span id="702"><span class="c1"># # &lt;a id=&#39;pickle&#39;&gt;Saving preprossed data as serialized files&lt;/a&gt;</span></span>
<span id="703"><span class="c1"># * To deploy the predictive models built we save them along with the required data files as serialized file objects</span></span>
<span id="704"><span class="c1"># * We save cleaned and processed input data, tuned predictive models as files so that they can later be re-used/shared</span></span>
<span id="705"></span>
<span id="706"><span class="c1"># In[44]:</span></span>
<span id="707"></span>
<span id="708"></span>
<span id="709"><span class="n">CreditCardFraudDataCleaned</span> <span class="o">=</span> <span class="n">df</span></span>
<span id="710"></span>
<span id="711"><span class="c1"># Saving the Python objects as serialized files can be done using pickle library</span></span>
<span id="712"><span class="c1"># Here let us save the Final Data set after all the transformations as a file</span></span>
<span id="713"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;CreditCardFraudDataCleaned.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fileWriteStream</span><span class="p">:</span></span>
<span id="714">    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">CreditCardFraudDataCleaned</span><span class="p">,</span> <span class="n">fileWriteStream</span><span class="p">)</span></span>
<span id="715">    <span class="c1"># Don&#39;t forget to close the filestream!</span></span>
<span id="716">    <span class="n">fileWriteStream</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></span>
<span id="717">    </span>
<span id="718"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;pickle file is saved at Location:&#39;</span><span class="p">,</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()))</span></span>
<span id="719"></span>
<span id="720"></span>
<span id="721"><span class="c1"># ### Load preprocessed data</span></span>
<span id="722"></span>
<span id="723"><span class="c1"># In[45]:</span></span>
<span id="724"></span>
<span id="725"></span>
<span id="726"><span class="c1"># Reading a Pickle file</span></span>
<span id="727"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;CreditCardFraudDataCleaned.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fileReadStream</span><span class="p">:</span></span>
<span id="728">    <span class="n">CreditCardFraudDataFromPickle</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fileReadStream</span><span class="p">)</span></span>
<span id="729">    <span class="c1"># Don&#39;t forget to close the filestream!</span></span>
<span id="730">    <span class="n">fileReadStream</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></span>
<span id="731">    </span>
<span id="732"><span class="c1"># Checking the data read from pickle file. It is exactly same as the DiamondPricesData</span></span>
<span id="733"><span class="n">df</span> <span class="o">=</span> <span class="n">CreditCardFraudDataFromPickle</span></span>
<span id="734"><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></span>
<span id="735"></span>
<span id="736"></span>
<span id="737"><span class="c1"># In[46]:</span></span>
<span id="738"></span>
<span id="739"></span>
<span id="740"><span class="n">df</span><span class="o">.</span><span class="n">shape</span></span>
<span id="741"></span>
<span id="742"></span>
<span id="743"><span class="c1"># In[47]:</span></span>
<span id="744"></span>
<span id="745"></span>
<span id="746"><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></span>
<span id="747"></span>
<span id="748"></span>
<span id="749"><span class="c1"># # &lt;a id=&#39;splitdata&#39;&gt;Splitting data into Training and Testing samples&lt;/a&gt;</span></span>
<span id="750"><span class="c1"># </span></span>
<span id="751"><span class="c1"># We don&#39;t use the full data for creating the model. Some data is randomly selected and kept aside for checking how good the model is. This is known as Testing Data and the remaining data is called Training data on which the model is built. Typically 70% of data is used as training data and the rest 30% is used as testing data.</span></span>
<span id="752"></span>
<span id="753"><span class="c1"># In[48]:</span></span>
<span id="754"></span>
<span id="755"></span>
<span id="756"><span class="n">df</span><span class="o">.</span><span class="n">columns</span></span>
<span id="757"></span>
<span id="758"></span>
<span id="759"><span class="c1"># **Highlights**</span></span>
<span id="760"><span class="c1"># </span></span>
<span id="761"><span class="c1"># * We have created few new features like an hour, day, scaled amount. However, these are just for visualization purpose only, not for building the model.</span></span>
<span id="762"></span>
<span id="763"><span class="c1"># In[49]:</span></span>
<span id="764"></span>
<span id="765"></span>
<span id="766"><span class="c1"># Separate Target Variable and Predictor Variables</span></span>
<span id="767"><span class="c1"># Here I am keeping the log amount and dropping the amount and scaled amount columns.</span></span>
<span id="768"><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;time&#39;</span><span class="p">,</span><span class="s1">&#39;class&#39;</span><span class="p">,</span><span class="s1">&#39;hour&#39;</span><span class="p">,</span><span class="s1">&#39;day&#39;</span><span class="p">,</span><span class="s1">&#39;amount&#39;</span><span class="p">,</span><span class="s1">&#39;amount_minmax&#39;</span><span class="p">,</span><span class="s1">&#39;amount_scaled&#39;</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></span>
<span id="769"><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span></span>
<span id="770"></span>
<span id="771"></span>
<span id="772"><span class="c1"># In[50]:</span></span>
<span id="773"></span>
<span id="774"></span>
<span id="775"><span class="n">X</span></span>
<span id="776"></span>
<span id="777"></span>
<span id="778"><span class="c1"># In[51]:</span></span>
<span id="779"></span>
<span id="780"></span>
<span id="781"><span class="c1"># Load the library for splitting the data</span></span>
<span id="782"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span></span>
<span id="783"></span>
<span id="784"></span>
<span id="785"><span class="c1"># In[52]:</span></span>
<span id="786"></span>
<span id="787"></span>
<span id="788"><span class="c1"># Split the data into training and testing set</span></span>
<span id="789"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.30</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">101</span><span class="p">)</span></span>
<span id="790"></span>
<span id="791"></span>
<span id="792"><span class="c1"># In[53]:</span></span>
<span id="793"></span>
<span id="794"></span>
<span id="795"><span class="c1"># Quick sanity check with the shapes of Training and testing datasets</span></span>
<span id="796"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;X_train - &quot;</span><span class="p">,</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span></span>
<span id="797"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;y_train - &quot;</span><span class="p">,</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span></span>
<span id="798"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;X_test - &quot;</span><span class="p">,</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span></span>
<span id="799"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;y_test - &quot;</span><span class="p">,</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span></span>
<span id="800"></span>
<span id="801"></span>
<span id="802"><span class="c1"># # &lt;a id=&#39;modelbaseline&#39;&gt;Baseline for models&lt;/a&gt;</span></span>
<span id="803"><span class="c1"># </span></span>
<span id="804"><span class="c1"># We will train four types of classifiers and decide which classifier will be more effective in detecting **fraud transactions**.</span></span>
<span id="805"></span>
<span id="806"><span class="c1"># #### Let&#39;s Discuss Next Steps - </span></span>
<span id="807"><span class="c1"># </span></span>
<span id="808"><span class="c1"># 1  __Classification Models__</span></span>
<span id="809"><span class="c1"># </span></span>
<span id="810"><span class="c1"># - Logistic Regression</span></span>
<span id="811"><span class="c1"># - Decision Trees</span></span>
<span id="812"><span class="c1"># - Random Forest</span></span>
<span id="813"><span class="c1"># - Naive Bayes Classifier </span></span>
<span id="814"><span class="c1"># </span></span>
<span id="815"><span class="c1"># 2  __Class Imbalance Solutions__</span></span>
<span id="816"><span class="c1"># </span></span>
<span id="817"><span class="c1"># - Under Sampling</span></span>
<span id="818"><span class="c1"># - Over Sampling</span></span>
<span id="819"><span class="c1"># - SMOTE</span></span>
<span id="820"><span class="c1"># - ADASYN</span></span>
<span id="821"><span class="c1"># </span></span>
<span id="822"><span class="c1"># 3  __Metrics__</span></span>
<span id="823"><span class="c1"># </span></span>
<span id="824"><span class="c1"># - Accuracy Score</span></span>
<span id="825"><span class="c1"># - Confusion Matrix</span></span>
<span id="826"><span class="c1"># - Precision Score</span></span>
<span id="827"><span class="c1"># - Recall Score</span></span>
<span id="828"><span class="c1"># - ROC_AUC</span></span>
<span id="829"><span class="c1"># - F1 Score</span></span>
<span id="830"></span>
<span id="831"><span class="c1"># # &lt;a id=&#39;modelbuild&#39;&gt;Model Building&lt;/a&gt;</span></span>
<span id="832"><span class="c1"># </span></span>
<span id="833"><span class="c1"># ##### We are aware that our dataset is highly imbalanced, however, we check the performance of imbalance dataset first and later we implement some techniques to balance the dataset and again check the performance of balanced dataset. Finally, we will compare each regression models performance.</span></span>
<span id="834"></span>
<span id="835"><span class="c1"># # &lt;a id=&#39;logreg&#39;&gt;1. Logistic Regression&lt;/a&gt;</span></span>
<span id="836"></span>
<span id="837"><span class="c1"># ## &lt;a id=&#39;logregim&#39;&gt;1.1 Logistic Regression with imbalanced data&lt;/a&gt;</span></span>
<span id="838"></span>
<span id="839"><span class="c1"># In[54]:</span></span>
<span id="840"></span>
<span id="841"></span>
<span id="842"><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span> <span class="c1"># Importing Classifier Step</span></span>
<span id="843"></span>
<span id="844"></span>
<span id="845"><span class="c1"># In[55]:</span></span>
<span id="846"></span>
<span id="847"></span>
<span id="848"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> </span>
<span id="849"></span>
<span id="850"></span>
<span id="851"><span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span></span>
<span id="852"><span class="n">logreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> </span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">train</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1071, 852, 860])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">no independent test data</button>
<span id="853"></span>
<span id="854"></span>
<span id="855"><span class="c1"># ### Predict from Test set</span></span>
<span id="856"></span>
<span id="857"><span class="c1"># In[56]:</span></span>
<span id="858"></span>
<span id="859"></span>
<span id="860"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1071, 852, 860])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1259, 1343, 1421, 1789, 1790, 860])">highlight other usage</button>
<span id="861"></span>
<span id="862"></span>
<span id="863"><span class="c1"># ### &lt;a id=&#39;modevel&#39;&gt;Model Evolution&lt;/a&gt;</span></span>
<span id="864"></span>
<span id="865"><span class="c1"># In[57]:</span></span>
<span id="866"></span>
<span id="867"></span>
<span id="868"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span></span>
<span id="869"></span>
<span id="870"></span>
<span id="871"><span class="c1"># In[58]:</span></span>
<span id="872"></span>
<span id="873"></span>
<span id="874"><span class="c1"># https://en.wikipedia.org/wiki/Precision_and_recall</span></span>
<span id="875"><span class="nb">print</span><span class="p">((</span><span class="n">metrics</span><span class="o">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span></span>
<span id="876"></span>
<span id="877"></span>
<span id="878"><span class="c1"># In[59]:</span></span>
<span id="879"></span>
<span id="880"></span>
<span id="881"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Accuracy :</span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_pred</span> <span class="p">,</span> <span class="n">y_test</span><span class="p">))))</span> </span>
<span id="882"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;AUC : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="883"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Precision : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="884"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Recall : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="885"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;F1 : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="886"><span class="c1"># print(&#39;Confusion Matrix : \n&#39;, cnf_matrix)</span></span>
<span id="887"><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span></span>
<span id="888"></span>
<span id="889"></span>
<span id="890"><span class="c1"># In[60]:</span></span>
<span id="891"></span>
<span id="892"></span>
<span id="893"><span class="c1"># Predicted values counts for fraud and genuine of test dataset</span></span>
<span id="894"><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span></span>
<span id="895"></span>
<span id="896"></span>
<span id="897"><span class="c1"># **Highlights**</span></span>
<span id="898"><span class="c1"># </span></span>
<span id="899"><span class="c1"># Our model predicted 103 transactions as fraud and 85340 transactions as genuine from the test dataset.</span></span>
<span id="900"></span>
<span id="901"><span class="c1"># In[61]:</span></span>
<span id="902"></span>
<span id="903"></span>
<span id="904"><span class="c1"># Actual values counts for fraud and genuine of test dataset</span></span>
<span id="905"><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span></span>
<span id="906"></span>
<span id="907"></span>
<span id="908"><span class="c1"># **There are originally 147 fraud transactions and our model predicted only 103 fraud transaction. So the accuracy of our model should be ${103}\over{147}$, right?**</span></span>
<span id="909"></span>
<span id="910"><span class="c1"># In[62]:</span></span>
<span id="911"></span>
<span id="912"></span>
<span id="913"><span class="mi">103</span><span class="o">/</span><span class="mi">147</span></span>
<span id="914"></span>
<span id="915"></span>
<span id="916"><span class="c1"># So 71.533% should be our accuracy.</span></span>
<span id="917"></span>
<span id="918"><span class="c1"># **However, this not the case. Actually there are originally 147 fraud transactions and 85296 genuine transactions in the test dataset. However, our model predicted only 103 fraud transaction. Also, it should be keptin mind that these 103 predicted fraud transaction may not be identified correctly. It means that these predicted 103 fraud transactions are NOT only from 147 originally fraud transaction, but they may also be from genuine transactions as well.**</span></span>
<span id="919"><span class="c1"># </span></span>
<span id="920"><span class="c1"># We will see our real accuracy in below cells.</span></span>
<span id="921"></span>
<span id="922"><span class="c1"># ### &lt;a id=&#39;modevelmatrix&#39;&gt;Model Evolution Matrix&lt;/a&gt;</span></span>
<span id="923"><span class="c1"># </span></span>
<span id="924"><span class="c1"># Every problem is different and derives a different set of values for a particular business use case , thus every model must be evaluated differently.</span></span>
<span id="925"><span class="c1"># </span></span>
<span id="926"><span class="c1"># **Let&#39;s get to know the terminology and Structure first**</span></span>
<span id="927"><span class="c1"># </span></span>
<span id="928"><span class="c1"># A confusion matrix is defined into four parts : __{ TRUE , FALSE } (Actual) ,{POSITIVE , NEGATIVE} (Predicted)__</span></span>
<span id="929"><span class="c1"># Positive and Negative is what you predict , True and False is what you are told</span></span>
<span id="930"><span class="c1"># </span></span>
<span id="931"><span class="c1"># Which brings us to 4 relations : True Positive , True Negative , False Positive , False Negative &lt;br&gt;</span></span>
<span id="932"><span class="c1"># __P__ redicted - __R__ ows and __A__ ctual as __C__ olumns &lt;br&gt;</span></span>
<span id="933"><span class="c1"># </span></span>
<span id="934"><span class="c1"># &lt;img src = &#39;https://github.com/dktalaicha/Kaggle/blob/master/CreditCardFraudDetection/images/final_cnf.png?raw=true&#39;&gt;</span></span>
<span id="935"><span class="c1"># </span></span>
<span id="936"><span class="c1"># </span></span>
<span id="937"><span class="c1"># ### Accuracy , Precision and Recall</span></span>
<span id="938"><span class="c1"># </span></span>
<span id="939"><span class="c1"># ##### __Accuracy__ : The most used and classic classification metric : Suited for binary classification problems.</span></span>
<span id="940"><span class="c1"># </span></span>
<span id="941"><span class="c1"># $$  \text{Accuracy} = \frac{( TP + TN ) }{ (TP + TN + FP + FN )}$$</span></span>
<span id="942"><span class="c1"># </span></span>
<span id="943"><span class="c1"># Basically Rightly predicted results amongst all the results , used when the classes are balanced</span></span>
<span id="944"><span class="c1"># </span></span>
<span id="945"><span class="c1"># ##### __Precision__ : What proportion of predicted positives are truly positive ? Used when we need to predict the positive thoroughly, sure about it !</span></span>
<span id="946"><span class="c1"># </span></span>
<span id="947"><span class="c1"># $$ \text{Precision} = \frac{( TP )}{( TP + FP )} $$</span></span>
<span id="948"><span class="c1"># </span></span>
<span id="949"><span class="c1"># ##### __Sensitivity or Recall__ : What proportion of actual positives is correctly classified ? choice when we want to capture as many positives as possible</span></span>
<span id="950"><span class="c1"># </span></span>
<span id="951"><span class="c1"># $$ \text{Recall} = \frac{(TP)}{( TP + FN )} $$</span></span>
<span id="952"><span class="c1"># </span></span>
<span id="953"><span class="c1"># ##### __F1 Score__ : Harmonic mean of Precision and Recall. It basically maintains a balance between the precision and recall for your classifier</span></span>
<span id="954"><span class="c1"># </span></span>
<span id="955"><span class="c1"># $$ F1 = \frac{2 * (\text{ precision } * \text{ recall })}{(\text{ precision } + \text{ recall } )} $$</span></span>
<span id="956"><span class="c1"># </span></span>
<span id="957"><span class="c1"># &lt;img src=&#39;https://i.imgur.com/IYuqqic.gif&#39; /&gt;</span></span>
<span id="958"><span class="c1"># </span></span>
<span id="959"><span class="c1"># **Precision as the name says, says how precise (how sure) is our model in detecting fraud transactions while recall is the amount of fraud cases our model is able to detect.**</span></span>
<span id="960"><span class="c1"># </span></span>
<span id="961"><span class="c1"># </span></span>
<span id="962"><span class="c1"># **In reference of our case**:</span></span>
<span id="963"><span class="c1"># </span></span>
<span id="964"><span class="c1"># Recall (True Positive Rate): % of all fraudulent transactions cases captured.</span></span>
<span id="965"><span class="c1"># </span></span>
<span id="966"><span class="c1"># Precision: Out of all items labeled as fraud, what percentage of them is actually fraud?</span></span>
<span id="967"><span class="c1"># </span></span>
<span id="968"><span class="c1"># Accuracy: How correct the model is (misleading for fraud/imbalanced data)</span></span>
<span id="969"><span class="c1"># </span></span>
<span id="970"><span class="c1"># F1 score: combination of recall and precision into one metric. F1 score is the weighted average of precision and recall, taking BOTH false positives and false negatives into account. Usually much more useful than accuracy, especially with uneven classes.</span></span>
<span id="971"></span>
<span id="972"><span class="c1"># ### Confusion Matrix</span></span>
<span id="973"></span>
<span id="974"><span class="c1"># In[63]:</span></span>
<span id="975"></span>
<span id="976"></span>
<span id="977"><span class="n">cnf_matrix</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span></span>
<span id="978"><span class="n">cnf_matrix</span></span>
<span id="979"></span>
<span id="980"></span>
<span id="981"><span class="c1"># In[64]:</span></span>
<span id="982"></span>
<span id="983"></span>
<span id="984"><span class="c1"># Heatmap for Confusion Matrix</span></span>
<span id="985"><span class="n">p</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">25</span><span class="p">},</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;winter&quot;</span> <span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span></span>
<span id="986"></span>
<span id="987"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion matrix&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">22</span><span class="p">)</span></span>
<span id="988"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual&#39;</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span></span>
<span id="989"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span></span>
<span id="990"></span>
<span id="991"><span class="c1"># ax.xaxis.set_ticklabels([&#39;Genuine&#39;, &#39;Fraud&#39;]); </span></span>
<span id="992"><span class="c1"># ax.yaxis.set_ticklabels([&#39;Genuine&#39;, &#39;Fraud&#39;]);</span></span>
<span id="993"></span>
<span id="994"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="995"></span>
<span id="996"></span>
<span id="997"><span class="c1"># **There are 84 transaction recognised as True Postive, means they are orignally fraud transactions and our model precited them as fraud.**</span></span>
<span id="998"><span class="c1"># </span></span>
<span id="999"><span class="c1"># **True Negative** - 85285 (truely saying negative - genuine transaction correctly identified as genuine)</span></span>
<span id="1000"><span class="c1"># </span></span>
<span id="1001"><span class="c1"># **True Postive** - 92 (truely saying positive - fraud transaction correctly identified as fraud)</span></span>
<span id="1002"><span class="c1"># </span></span>
<span id="1003"><span class="c1"># **False Negative** - 55 ( falsely saying negative - fraud transaction incorrectly identified as genuine)</span></span>
<span id="1004"><span class="c1"># </span></span>
<span id="1005"><span class="c1"># **False Positive** - 11 ( falsely saying positive - genuine transaction incorrectly identified as fraud)</span></span>
<span id="1006"></span>
<span id="1007"><span class="c1"># #### We already know that we have 147 fraud transaction in our test dataset, but our model predicted only 92 fraud transaction. So the real accuracy of our model is ${92}\over{147}$</span></span>
<span id="1008"></span>
<span id="1009"><span class="c1"># In[65]:</span></span>
<span id="1010"></span>
<span id="1011"></span>
<span id="1012"><span class="mi">92</span><span class="o">/</span><span class="mi">147</span></span>
<span id="1013"></span>
<span id="1014"></span>
<span id="1015"><span class="c1"># So, **62.59%** is the real accuracy of our model, which is nothing but the **Recall Score**. So we have the emphasis on Recall score and F1 score to measure the performance of our model, not the accuracy.</span></span>
<span id="1016"></span>
<span id="1017"><span class="c1"># ### &lt;a id=&#39;roccurve&#39;&gt;Receiver Operating Characteristics (ROC)&lt;/a&gt;</span></span>
<span id="1018"><span class="c1"># </span></span>
<span id="1019"><span class="c1"># The ROC is a performance measurement for classification problems at various thresholds. It is essentially a probability curve, and the higher the Area Under the Curve (AUC) score the better the model is at predicting fraudulent/non-fraudulent transactions.</span></span>
<span id="1020"><span class="c1"># </span></span>
<span id="1021"><span class="c1"># It is an evaluation metric that helps identify the strength of the model to **distinguish between two outcomes**. It defines if a model can create a clear boundary between the postive and the negative class. </span></span>
<span id="1022"><span class="c1"># </span></span>
<span id="1023"><span class="c1"># &lt;div style=&#39;width:100%;&#39;&gt;</span></span>
<span id="1024"><span class="c1">#    &lt;div style=&#39;width:30%; float:left;&#39;&gt; &lt;img  src =&#39;https://i.imgur.com/fzBGUDy.jpg&#39; /&gt; &lt;/div&gt;</span></span>
<span id="1025"><span class="c1">#    &lt;div style=&#39;&#39;&gt; &lt;img  src =&#39;https://i.imgur.com/hZQiNCn.png&#39; /&gt; &lt;/div&gt;</span></span>
<span id="1026"><span class="c1"># &lt;/div&gt;</span></span>
<span id="1027"><span class="c1"># </span></span>
<span id="1028"><span class="c1"># </span></span>
<span id="1029"><span class="c1"># Let&#39;s talk about some definitions first: </span></span>
<span id="1030"><span class="c1"># </span></span>
<span id="1031"><span class="c1"># ##### __Sensitivity__ or __Recall__</span></span>
<span id="1032"><span class="c1"># </span></span>
<span id="1033"><span class="c1"># The sensitivity of a model is defined by the proportion of actual positives that are classified as Positives , i.e = TP / ( TP + FN )</span></span>
<span id="1034"><span class="c1"># </span></span>
<span id="1035"><span class="c1"># $$ \text{Recall or Sensitivity} = \frac{(TP)}{( TP + FN )} $$</span></span>
<span id="1036"><span class="c1"># </span></span>
<span id="1037"><span class="c1"># &lt;img src = &quot;https://github.com/dktalaicha/Kaggle/blob/master/CreditCardFraudDetection/images/sens.png?raw=true&quot;&gt;</span></span>
<span id="1038"><span class="c1"># </span></span>
<span id="1039"><span class="c1"># ##### __Specificity__</span></span>
<span id="1040"><span class="c1"># </span></span>
<span id="1041"><span class="c1"># The specificity of a model is defined by the proportion of actual negatives that are classified as Negatives , i.e = TN / ( TN + FP )</span></span>
<span id="1042"><span class="c1"># </span></span>
<span id="1043"><span class="c1"># $$ \text{Specificity} = \frac{(TN)}{( TN + FP )} $$</span></span>
<span id="1044"><span class="c1"># </span></span>
<span id="1045"><span class="c1"># &lt;img src = &quot;https://github.com/dktalaicha/Kaggle/blob/master/CreditCardFraudDetection/images/spec.png?raw=true&quot;&gt;</span></span>
<span id="1046"><span class="c1"># </span></span>
<span id="1047"><span class="c1"># As we can see that both are independent of each other and lie in teo different quadrants , we can understand that they are inversely related to each other. Thus as Sensitivity goes up , Specificity goes down and vice versa.</span></span>
<span id="1048"><span class="c1"># </span></span>
<span id="1049"><span class="c1"># ### ROC CURVE</span></span>
<span id="1050"><span class="c1"># </span></span>
<span id="1051"><span class="c1"># It is a plot between Sesitivity and ( 1 - Specificity ) , which intuitively is a plot between True Positive Rate and False Positive Rate. </span></span>
<span id="1052"><span class="c1"># It depicts if a model can clearly identify each class or not</span></span>
<span id="1053"><span class="c1"># </span></span>
<span id="1054"><span class="c1"># Higher the area under the curve , better the model and it&#39;s ability to seperate the positive and negative class.</span></span>
<span id="1055"><span class="c1"># </span></span>
<span id="1056"><span class="c1"># &lt;img src = &quot;https://github.com/dktalaicha/Kaggle/blob/master/CreditCardFraudDetection/images/tpfpfntn.jpeg?raw=true&quot;&gt;</span></span>
<span id="1057"><span class="c1"># &lt;img src = &quot;https://github.com/dktalaicha/Kaggle/blob/master/CreditCardFraudDetection/images/auc.png?raw=true&quot;&gt;</span></span>
<span id="1058"><span class="c1"># &lt;img src = &quot;https://github.com/dktalaicha/Kaggle/blob/master/CreditCardFraudDetection/images/auc2.png?raw=true&quot;&gt;</span></span>
<span id="1059"><span class="c1"># </span></span>
<span id="1060"><span class="c1"># &lt;img src=&#39;https://i.imgur.com/GRuZpez.gif&#39;&gt;</span></span>
<span id="1061"></span>
<span id="1062"><span class="c1"># In[66]:</span></span>
<span id="1063"></span>
<span id="1064"></span>
<span id="1065"><span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span> </span>
<span id="1066"></span>
<span id="1067"></span>
<span id="1068"><span class="c1"># In[67]:</span></span>
<span id="1069"></span>
<span id="1070"></span>
<span id="1071"><span class="n">y_pred_proba</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1071, 852, 860])">highlight train/test sites</button>
<span id="1072"><span class="n">y_pred_proba</span></span>
<span id="1073"></span>
<span id="1074"></span>
<span id="1075"><span class="c1"># In[68]:</span></span>
<span id="1076"></span>
<span id="1077"></span>
<span id="1078"><span class="c1"># plot ROC Curve</span></span>
<span id="1079"></span>
<span id="1080"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span></span>
<span id="1081"></span>
<span id="1082"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></span>
<span id="1083"></span>
<span id="1084"><span class="n">auc</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></span>
<span id="1085"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;AUC - &quot;</span><span class="p">,</span><span class="n">auc</span><span class="p">,</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">))</span></span>
<span id="1086"></span>
<span id="1087"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;data 1, auc=&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">auc</span><span class="p">))</span></span>
<span id="1088"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span></span>
<span id="1089"></span>
<span id="1090"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span> <span class="p">)</span></span>
<span id="1091"></span>
<span id="1092"><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span></span>
<span id="1093"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;ROC curve for Predicting a credit card fraud detection&#39;</span><span class="p">)</span></span>
<span id="1094"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate (1 - Specificity)&#39;</span><span class="p">)</span></span>
<span id="1095"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate (Sensitivity)&#39;</span><span class="p">)</span></span>
<span id="1096"></span>
<span id="1097"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="1098"></span>
<span id="1099"></span>
<span id="1100"><span class="c1"># # &lt;a id=&#39;classimbalance&#39;&gt;Class Imbalance&lt;/a&gt;</span></span>
<span id="1101"><span class="c1"># </span></span>
<span id="1102"><span class="c1"># Imbalanced data typically refers to a problem with classification problems where the classes are not represented equally.  If one applies classifiers on the dataset, they are likely to predict everything as the majority class. This was often regarded as a problem in learning from highly imbalanced datasets.</span></span>
<span id="1103"><span class="c1"># </span></span>
<span id="1104"><span class="c1"># &lt;img src=&#39;https://i.imgur.com/uqh1peJ.gif&#39; /&gt;</span></span>
<span id="1105"><span class="c1"># </span></span>
<span id="1106"><span class="c1"># </span></span>
<span id="1107"><span class="c1"># Let&#39;s Fix the class Imbalance and apply some sampling techniques.</span></span>
<span id="1108"><span class="c1"># </span></span>
<span id="1109"><span class="c1"># </span></span>
<span id="1110"><span class="c1"># Ref : https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/</span></span>
<span id="1111"></span>
<span id="1112"><span class="c1"># ## &lt;a id=&#39;undovrsamp&#39;&gt;Under Sampling and Over Sampling&lt;/a&gt;</span></span>
<span id="1113"><span class="c1"># </span></span>
<span id="1114"><span class="c1"># Oversampling and undersampling in data analysis are techniques used to adjust the class distribution of a data set. </span></span>
<span id="1115"><span class="c1"># </span></span>
<span id="1116"><span class="c1"># * Random oversampling duplicates examples from the minority class in the training dataset and can result in overfitting for some models.</span></span>
<span id="1117"><span class="c1"># </span></span>
<span id="1118"><span class="c1"># * Random undersampling deletes examples from the majority class and can result in losing information invaluable to a model.</span></span>
<span id="1119"><span class="c1"># </span></span>
<span id="1120"><span class="c1"># &lt;img src = &#39;https://github.com/dktalaicha/Kaggle/blob/master/CreditCardFraudDetection/images/under_over_sampling.jpg?raw=true&#39;&gt;</span></span>
<span id="1121"><span class="c1"># </span></span>
<span id="1122"><span class="c1"># ## &lt;a id=&#39;smote&#39;&gt;Synthetic Minority OverSampling Technique (SMOTE)&lt;/a&gt;</span></span>
<span id="1123"><span class="c1"># </span></span>
<span id="1124"><span class="c1"># In this technique, instead of simply duplicating data from the minority class, we synthesize new data from the minority class. This is a type of data augmentation for tabular data can be very effective. This approach to synthesizing new data is called the Synthetic Minority Oversampling TEchnique, or SMOTE for short. </span></span>
<span id="1125"><span class="c1"># </span></span>
<span id="1126"><span class="c1"># &lt;img src=&#39;https://github.com/dktalaicha/Kaggle/blob/master/CreditCardFraudDetection/images/smote.png?raw=true&#39;&gt;</span></span>
<span id="1127"><span class="c1"># </span></span>
<span id="1128"><span class="c1"># ## &lt;a id=&#39;adasyn&#39;&gt;Adaptive Synthetic Sampling Method for Imbalanced Data (ADASYN)&lt;/a&gt;</span></span>
<span id="1129"><span class="c1"># </span></span>
<span id="1130"><span class="c1"># ADASYN (Adaptive Synthetic) is an algorithm that generates synthetic data, and its greatest advantages are not copying the same minority data, and generating more data for harder to learn examples.</span></span>
<span id="1131"><span class="c1"># </span></span>
<span id="1132"><span class="c1"># Ref : https://medium.com/@ruinian/an-introduction-to-adasyn-with-code-1383a5ece7aa</span></span>
<span id="1133"></span>
<span id="1134"><span class="c1"># ## Import imbalace technique algorithims</span></span>
<span id="1135"></span>
<span id="1136"><span class="c1"># In[69]:</span></span>
<span id="1137"></span>
<span id="1138"></span>
<span id="1139"><span class="c1"># Import imbalace technique algorithims</span></span>
<span id="1140"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span></span>
<span id="1141"><span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span><span class="p">,</span> <span class="n">ADASYN</span></span>
<span id="1142"><span class="kn">from</span> <span class="nn">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">RandomUnderSampler</span></span>
<span id="1143"></span>
<span id="1144"></span>
<span id="1145"><span class="c1"># ## &lt;a id=&#39;logregundsamp&#39;&gt;1.2.Logistic Regression with Random Undersampling technique&lt;/a&gt;</span></span>
<span id="1146"></span>
<span id="1147"><span class="c1"># In[70]:</span></span>
<span id="1148"></span>
<span id="1149"></span>
<span id="1150"><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span> <span class="c1"># counter takes values returns value_counts dictionary</span></span>
<span id="1151"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span></span>
<span id="1152"></span>
<span id="1153"></span>
<span id="1154"><span class="c1"># In[71]:</span></span>
<span id="1155"></span>
<span id="1156"></span>
<span id="1157"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Original dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span></span>
<span id="1158"></span>
<span id="1159"><span class="n">rus</span> <span class="o">=</span> <span class="n">RandomUnderSampler</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span></span>
<span id="1160"><span class="n">X_res</span><span class="p">,</span> <span class="n">y_res</span> <span class="o">=</span> <span class="n">rus</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></span>
<span id="1161"></span>
<span id="1162"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Resampled dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y_res</span><span class="p">)))</span></span>
<span id="1163"></span>
<span id="1164"></span>
<span id="1165"><span class="c1"># In[72]:</span></span>
<span id="1166"></span>
<span id="1167"></span>
<span id="1168"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_res</span><span class="p">,</span> <span class="n">y_res</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></span>
<span id="1169"></span>
<span id="1170"><span class="c1"># Undersampling with Logistic Regression</span></span>
<span id="1171"><span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span></span>
<span id="1172"><span class="n">logreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">train</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1172, 1174])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">no independent test data</button>
<span id="1173"></span>
<span id="1174"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1172, 1174])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1174, 1259, 1343, 1421, 1789, 1790])">highlight other usage</button>
<span id="1175"></span>
<span id="1176"></span>
<span id="1177"><span class="c1"># In[73]:</span></span>
<span id="1178"></span>
<span id="1179"></span>
<span id="1180"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Accuracy :</span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_pred</span> <span class="p">,</span> <span class="n">y_test</span><span class="p">))))</span> </span>
<span id="1181"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;AUC : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1182"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Precision : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1183"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Recall : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1184"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;F1 : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1185"></span>
<span id="1186"></span>
<span id="1187"><span class="c1"># In[74]:</span></span>
<span id="1188"></span>
<span id="1189"></span>
<span id="1190"><span class="c1"># plot ROC Curve</span></span>
<span id="1191"></span>
<span id="1192"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span></span>
<span id="1193"></span>
<span id="1194"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></span>
<span id="1195"></span>
<span id="1196"><span class="n">auc</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></span>
<span id="1197"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;AUC - &quot;</span><span class="p">,</span><span class="n">auc</span><span class="p">,</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">))</span></span>
<span id="1198"></span>
<span id="1199"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;data 1, auc=&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">auc</span><span class="p">))</span></span>
<span id="1200"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span></span>
<span id="1201"></span>
<span id="1202"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span> <span class="p">)</span></span>
<span id="1203"></span>
<span id="1204"><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span></span>
<span id="1205"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;ROC curve for Predicting a credit card fraud detection&#39;</span><span class="p">)</span></span>
<span id="1206"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate (1 - Specificity)&#39;</span><span class="p">)</span></span>
<span id="1207"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate (Sensitivity)&#39;</span><span class="p">)</span></span>
<span id="1208"></span>
<span id="1209"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="1210"></span>
<span id="1211"></span>
<span id="1212"><span class="c1"># In[75]:</span></span>
<span id="1213"></span>
<span id="1214"></span>
<span id="1215"><span class="c1"># Heatmap for Confusion Matrix</span></span>
<span id="1216"></span>
<span id="1217"><span class="n">cnf_matrix</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></span>
<span id="1218"><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">25</span><span class="p">},</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;winter&quot;</span> <span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span></span>
<span id="1219"></span>
<span id="1220"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion matrix&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">22</span><span class="p">)</span></span>
<span id="1221"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span></span>
<span id="1222"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual&#39;</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span></span>
<span id="1223"></span>
<span id="1224"><span class="c1"># ax.xaxis.set_ticklabels([&#39;Genuine&#39;, &#39;Fraud&#39;]); </span></span>
<span id="1225"><span class="c1"># ax.yaxis.set_ticklabels([&#39;Genuine&#39;, &#39;Fraud&#39;]);</span></span>
<span id="1226"></span>
<span id="1227"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="1228"></span>
<span id="1229"></span>
<span id="1230"><span class="c1"># ## &lt;a id=&#39;logregovrsamp&#39;&gt;1.3.Logistic Regression with Random Oversampling technique&lt;/a&gt;</span></span>
<span id="1231"></span>
<span id="1232"><span class="c1"># In[76]:</span></span>
<span id="1233"></span>
<span id="1234"></span>
<span id="1235"><span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">RandomOverSampler</span></span>
<span id="1236"></span>
<span id="1237"></span>
<span id="1238"><span class="c1"># In[77]:</span></span>
<span id="1239"></span>
<span id="1240"></span>
<span id="1241"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Original dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span></span>
<span id="1242"><span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span></span>
<span id="1243"></span>
<span id="1244"><span class="n">ros</span> <span class="o">=</span> <span class="n">RandomOverSampler</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span></span>
<span id="1245"><span class="n">X_res</span><span class="p">,</span> <span class="n">y_res</span> <span class="o">=</span> <span class="n">ros</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></span>
<span id="1246"></span>
<span id="1247"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Resampled dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y_res</span><span class="p">)))</span></span>
<span id="1248"></span>
<span id="1249"></span>
<span id="1250"><span class="c1"># In[78]:</span></span>
<span id="1251"></span>
<span id="1252"></span>
<span id="1253"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_res</span><span class="p">,</span> <span class="n">y_res</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></span>
<span id="1254"></span>
<span id="1255"><span class="c1"># Oversampling with Logistic Regression</span></span>
<span id="1256"><span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span></span>
<span id="1257"><span class="n">logreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">train</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1257, 1259])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">overlap with all test data</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">no independent test data</button>
<span id="1258"></span>
<span id="1259"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1257, 1259])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">overlap with training data</button> <button type="button" style="line-height: 85%; None" onclick="mark_leak_lines([1245, 1329, 1408, 1567, 1582, 1597])">potential leak src</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1174, 1259, 1343, 1421, 1789, 1790, 2053, 2076, 2098, 2128, 860])">highlight other usage</button>
<span id="1260"></span>
<span id="1261"></span>
<span id="1262"><span class="c1"># In[79]:</span></span>
<span id="1263"></span>
<span id="1264"></span>
<span id="1265"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Accuracy :</span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span> </span>
<span id="1266"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;AUC : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1267"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Precision : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1268"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Recall : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1269"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;F1 : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1270"></span>
<span id="1271"></span>
<span id="1272"><span class="c1"># In[80]:</span></span>
<span id="1273"></span>
<span id="1274"></span>
<span id="1275"><span class="c1"># plot ROC Curve</span></span>
<span id="1276"></span>
<span id="1277"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span></span>
<span id="1278"></span>
<span id="1279"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></span>
<span id="1280"></span>
<span id="1281"><span class="n">auc</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></span>
<span id="1282"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;AUC - &quot;</span><span class="p">,</span><span class="n">auc</span><span class="p">,</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">))</span></span>
<span id="1283"></span>
<span id="1284"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;data 1, auc=&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">auc</span><span class="p">))</span></span>
<span id="1285"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span></span>
<span id="1286"></span>
<span id="1287"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span> <span class="p">)</span></span>
<span id="1288"></span>
<span id="1289"><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span></span>
<span id="1290"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;ROC curve for Predicting a breast cancer classifier&#39;</span><span class="p">)</span></span>
<span id="1291"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate (1 - Specificity)&#39;</span><span class="p">)</span></span>
<span id="1292"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate (Sensitivity)&#39;</span><span class="p">)</span></span>
<span id="1293"></span>
<span id="1294"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="1295"></span>
<span id="1296"></span>
<span id="1297"><span class="c1"># In[81]:</span></span>
<span id="1298"></span>
<span id="1299"></span>
<span id="1300"><span class="c1"># Heatmap for Confusion Matrix</span></span>
<span id="1301"></span>
<span id="1302"><span class="n">cnf_matrix</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></span>
<span id="1303"><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">25</span><span class="p">},</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;winter&quot;</span> <span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span></span>
<span id="1304"></span>
<span id="1305"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion matrix&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">22</span><span class="p">)</span></span>
<span id="1306"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span></span>
<span id="1307"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual&#39;</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span></span>
<span id="1308"></span>
<span id="1309"><span class="c1"># ax.xaxis.set_ticklabels([&#39;Genuine&#39;, &#39;Fraud&#39;]); </span></span>
<span id="1310"><span class="c1"># ax.yaxis.set_ticklabels([&#39;Genuine&#39;, &#39;Fraud&#39;]);</span></span>
<span id="1311"></span>
<span id="1312"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="1313"></span>
<span id="1314"></span>
<span id="1315"><span class="c1"># ## &lt;a id=&#39;logregsomote&#39;&gt;1.4 Logistic Regression with SMOTE data&lt;/a&gt;</span></span>
<span id="1316"></span>
<span id="1317"><span class="c1"># In[82]:</span></span>
<span id="1318"></span>
<span id="1319"></span>
<span id="1320"><span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span><span class="p">,</span> <span class="n">ADASYN</span></span>
<span id="1321"></span>
<span id="1322"></span>
<span id="1323"><span class="c1"># In[83]:</span></span>
<span id="1324"></span>
<span id="1325"></span>
<span id="1326"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Original dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span></span>
<span id="1327"></span>
<span id="1328"><span class="n">smote</span> <span class="o">=</span> <span class="n">SMOTE</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span></span>
<span id="1329"><span class="n">X_res</span><span class="p">,</span> <span class="n">y_res</span> <span class="o">=</span> <span class="n">smote</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></span>
<span id="1330"></span>
<span id="1331"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Resampled dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y_res</span><span class="p">)))</span></span>
<span id="1332"></span>
<span id="1333"></span>
<span id="1334"><span class="c1"># In[84]:</span></span>
<span id="1335"></span>
<span id="1336"></span>
<span id="1337"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_res</span><span class="p">,</span> <span class="n">y_res</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></span>
<span id="1338"></span>
<span id="1339"><span class="c1"># SMOTE Sampling with Logistic Regression</span></span>
<span id="1340"><span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span></span>
<span id="1341"><span class="n">logreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">train</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1341, 1343])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">overlap with all test data</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">no independent test data</button>
<span id="1342"></span>
<span id="1343"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1341, 1343])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">overlap with training data</button> <button type="button" style="line-height: 85%; None" onclick="mark_leak_lines([1245, 1329, 1408, 1567, 1582, 1597])">potential leak src</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1174, 1259, 1343, 1421, 1789, 1790, 2053, 2076, 2098, 2128, 860])">highlight other usage</button>
<span id="1344"></span>
<span id="1345"></span>
<span id="1346"><span class="c1"># In[85]:</span></span>
<span id="1347"></span>
<span id="1348"></span>
<span id="1349"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Accuracy :</span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span> </span>
<span id="1350"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;AUC : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1351"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Precision : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1352"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Recall : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1353"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;F1 : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1354"></span>
<span id="1355"></span>
<span id="1356"><span class="c1"># In[86]:</span></span>
<span id="1357"></span>
<span id="1358"></span>
<span id="1359"><span class="c1"># plot ROC Curve</span></span>
<span id="1360"></span>
<span id="1361"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span></span>
<span id="1362"></span>
<span id="1363"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></span>
<span id="1364"></span>
<span id="1365"><span class="n">auc</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></span>
<span id="1366"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;AUC - &quot;</span><span class="p">,</span><span class="n">auc</span><span class="p">,</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">))</span></span>
<span id="1367"></span>
<span id="1368"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;data 1, auc=&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">auc</span><span class="p">))</span></span>
<span id="1369"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span></span>
<span id="1370"></span>
<span id="1371"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span> <span class="p">)</span></span>
<span id="1372"></span>
<span id="1373"><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span></span>
<span id="1374"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;ROC curve for Predicting a breast cancer classifier&#39;</span><span class="p">)</span></span>
<span id="1375"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate (1 - Specificity)&#39;</span><span class="p">)</span></span>
<span id="1376"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate (Sensitivity)&#39;</span><span class="p">)</span></span>
<span id="1377"></span>
<span id="1378"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="1379"></span>
<span id="1380"></span>
<span id="1381"><span class="c1"># In[87]:</span></span>
<span id="1382"></span>
<span id="1383"></span>
<span id="1384"><span class="c1"># Heatmap for Confusion Matrix</span></span>
<span id="1385"></span>
<span id="1386"><span class="n">cnf_matrix</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></span>
<span id="1387"><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">25</span><span class="p">},</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;winter&quot;</span> <span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span></span>
<span id="1388"></span>
<span id="1389"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion matrix&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">22</span><span class="p">)</span></span>
<span id="1390"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span></span>
<span id="1391"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual&#39;</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span></span>
<span id="1392"></span>
<span id="1393"><span class="c1"># ax.xaxis.set_ticklabels([&#39;Genuine&#39;, &#39;Fraud&#39;]); </span></span>
<span id="1394"><span class="c1"># ax.yaxis.set_ticklabels([&#39;Genuine&#39;, &#39;Fraud&#39;]);</span></span>
<span id="1395"></span>
<span id="1396"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="1397"></span>
<span id="1398"></span>
<span id="1399"><span class="c1"># ## &lt;a id=&#39;logregadasyn&#39;&gt;1.5 Logistic Regression with ADASYN data&lt;/a&gt;</span></span>
<span id="1400"></span>
<span id="1401"><span class="c1"># In[88]:</span></span>
<span id="1402"></span>
<span id="1403"></span>
<span id="1404"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Original dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span></span>
<span id="1405"></span>
<span id="1406"><span class="n">adasyn</span> <span class="o">=</span> <span class="n">ADASYN</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span></span>
<span id="1407"></span>
<span id="1408"><span class="n">X_res</span><span class="p">,</span> <span class="n">y_res</span> <span class="o">=</span> <span class="n">adasyn</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></span>
<span id="1409"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Resampled dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y_res</span><span class="p">)))</span></span>
<span id="1410"></span>
<span id="1411"></span>
<span id="1412"><span class="c1"># In[89]:</span></span>
<span id="1413"></span>
<span id="1414"></span>
<span id="1415"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_res</span><span class="p">,</span> <span class="n">y_res</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></span>
<span id="1416"></span>
<span id="1417"><span class="c1">#  ADASYN Sampling with Logistic Regression</span></span>
<span id="1418"><span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span></span>
<span id="1419"><span class="n">logreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">train</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1419, 1421])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">overlap with all test data</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">no independent test data</button>
<span id="1420"></span>
<span id="1421"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1419, 1421])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">overlap with training data</button> <button type="button" style="line-height: 85%; None" onclick="mark_leak_lines([1245, 1329, 1408, 1567, 1582, 1597])">potential leak src</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1174, 1259, 1343, 1421, 1789, 1790, 2053, 2076, 2098, 2128, 860])">highlight other usage</button>
<span id="1422"></span>
<span id="1423"></span>
<span id="1424"><span class="c1"># In[90]:</span></span>
<span id="1425"></span>
<span id="1426"></span>
<span id="1427"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Accuracy :</span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_pred</span> <span class="p">,</span> <span class="n">y_test</span><span class="p">))))</span> </span>
<span id="1428"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;AUC : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1429"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Precision : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1430"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Recall : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1431"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;F1 : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">))))</span></span>
<span id="1432"></span>
<span id="1433"></span>
<span id="1434"><span class="c1"># In[91]:</span></span>
<span id="1435"></span>
<span id="1436"></span>
<span id="1437"><span class="c1"># plot ROC Curve</span></span>
<span id="1438"></span>
<span id="1439"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span></span>
<span id="1440"></span>
<span id="1441"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></span>
<span id="1442"></span>
<span id="1443"><span class="n">auc</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></span>
<span id="1444"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;AUC - &quot;</span><span class="p">,</span><span class="n">auc</span><span class="p">,</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">))</span></span>
<span id="1445"></span>
<span id="1446"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;data 1, auc=&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">auc</span><span class="p">))</span></span>
<span id="1447"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span></span>
<span id="1448"></span>
<span id="1449"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span> <span class="p">)</span></span>
<span id="1450"></span>
<span id="1451"><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span></span>
<span id="1452"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;ROC curve for Predicting a breast cancer classifier&#39;</span><span class="p">)</span></span>
<span id="1453"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate (1 - Specificity)&#39;</span><span class="p">)</span></span>
<span id="1454"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate (Sensitivity)&#39;</span><span class="p">)</span></span>
<span id="1455"></span>
<span id="1456"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="1457"></span>
<span id="1458"></span>
<span id="1459"><span class="c1"># In[92]:</span></span>
<span id="1460"></span>
<span id="1461"></span>
<span id="1462"><span class="c1"># Heatmap for Confusion Matrix</span></span>
<span id="1463"></span>
<span id="1464"><span class="n">cnf_matrix</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></span>
<span id="1465"><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">25</span><span class="p">},</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;winter&quot;</span> <span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span></span>
<span id="1466"></span>
<span id="1467"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion matrix&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">22</span><span class="p">)</span></span>
<span id="1468"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span></span>
<span id="1469"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual&#39;</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span></span>
<span id="1470"></span>
<span id="1471"><span class="c1"># ax.xaxis.set_ticklabels([&#39;Genuine&#39;, &#39;Fraud&#39;]); </span></span>
<span id="1472"><span class="c1"># ax.yaxis.set_ticklabels([&#39;Genuine&#39;, &#39;Fraud&#39;]);</span></span>
<span id="1473"></span>
<span id="1474"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="1475"></span>
<span id="1476"></span>
<span id="1477"><span class="c1"># ### We have seen that imbalance dataset have Recall score of only 62.59%. It means that creating a model from the imbalanced dataset is highly biased towards genuine transactions and creates a model which is not able to predict the fraudulent transactions correctly. However, the balanced dataset has Recall score of above 85.48%.</span></span>
<span id="1478"></span>
<span id="1479"><span class="c1"># # &lt;a id=&#39;spatial&#39;&gt;Spatial nature of class imbalance&lt;/a&gt;</span></span>
<span id="1480"><span class="c1"># </span></span>
<span id="1481"><span class="c1"># I will reduce 29 columns to 2 columns with the help of **Principal Component Analysis** so that I can look at them in a plot! (because to plot graph we need two dimensions)</span></span>
<span id="1482"></span>
<span id="1483"><span class="c1"># In[93]:</span></span>
<span id="1484"></span>
<span id="1485"></span>
<span id="1486"><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span></span>
<span id="1487"></span>
<span id="1488"></span>
<span id="1489"><span class="c1"># ## &lt;a id=&#39;distimbds&#39;&gt;Distribution of balaced dataset&lt;/a&gt;</span></span>
<span id="1490"><span class="c1"># </span></span>
<span id="1491"><span class="c1"># Finally, we can create a scatter plot of the dataset and colour the examples for each class a different colour to clearly see the spatial nature of the class imbalance.</span></span>
<span id="1492"><span class="c1"># </span></span>
<span id="1493"><span class="c1"># A scatter plot of the dataset is created showing the large mass of points that belong to the minority class (red) and a small number of points spread out for the minority class (blue). We can see some measure of overlap between the two classes.</span></span>
<span id="1494"></span>
<span id="1495"><span class="c1"># In[94]:</span></span>
<span id="1496"></span>
<span id="1497"></span>
<span id="1498"><span class="n">X_reduced_pca_im</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></span>
<span id="1499"></span>
<span id="1500"></span>
<span id="1501"><span class="c1"># In[95]:</span></span>
<span id="1502"></span>
<span id="1503"></span>
<span id="1504"><span class="c1"># Generate and plot a synthetic imbalanced classification dataset</span></span>
<span id="1505"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span></span>
<span id="1506"></span>
<span id="1507"><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_reduced_pca_im</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced_pca_im</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;No Fraud&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></span>
<span id="1508"><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_reduced_pca_im</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced_pca_im</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Fraud&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></span>
<span id="1509"></span>
<span id="1510"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Scatter Plot of Imbalanced Dataset&quot;</span><span class="p">)</span></span>
<span id="1511"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span></span>
<span id="1512"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="1513"></span>
<span id="1514"></span>
<span id="1515"><span class="c1"># ## &lt;a id=&#39;distbalds&#39;&gt;Distribution of balaced dataset&lt;/a&gt;</span></span>
<span id="1516"><span class="c1"># </span></span>
<span id="1517"><span class="c1"># Finally, a scatter plot of the transformed dataset is created.</span></span>
<span id="1518"><span class="c1"># </span></span>
<span id="1519"><span class="c1"># It shows many more examples in the minority class created along the lines between the original examples in the minority class.</span></span>
<span id="1520"></span>
<span id="1521"><span class="c1"># In[96]:</span></span>
<span id="1522"></span>
<span id="1523"></span>
<span id="1524"><span class="n">X_reduced_pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_res</span><span class="p">)</span></span>
<span id="1525"></span>
<span id="1526"></span>
<span id="1527"><span class="c1"># In[97]:</span></span>
<span id="1528"></span>
<span id="1529"></span>
<span id="1530"><span class="c1"># Oversample and plot imbalanced dataset with ADASYN</span></span>
<span id="1531"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span></span>
<span id="1532"></span>
<span id="1533"><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_reduced_pca</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced_pca</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="p">(</span><span class="n">y_res</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;No Fraud&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></span>
<span id="1534"><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_reduced_pca</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced_pca</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="p">(</span><span class="n">y_res</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Fraud&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></span>
<span id="1535"></span>
<span id="1536"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Scatter Plot of Imbalanced Dataset With Adaptive Synthetic Sampling \(ADASYN\)&quot;</span><span class="p">)</span></span>
<span id="1537"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span></span>
<span id="1538"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="1539"></span>
<span id="1540"></span>
<span id="1541"><span class="c1"># # &lt;a id=&#39;modelwith&#39;&gt;Building different models with different balanced datasets&lt;/a&gt;</span></span>
<span id="1542"><span class="c1"># Let&#39;s now try different models , first by creating multiple datasets for undersampled , oversampled and SMOTE sampled</span></span>
<span id="1543"></span>
<span id="1544"><span class="c1"># ## &lt;a id=&#39;usdata&#39;&gt;1. Undersampled Data&lt;/a&gt;</span></span>
<span id="1545"></span>
<span id="1546"><span class="c1"># In[98]:</span></span>
<span id="1547"></span>
<span id="1548"></span>
<span id="1549"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Original dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span></span>
<span id="1550"></span>
<span id="1551"><span class="n">rus</span> <span class="o">=</span> <span class="n">RandomUnderSampler</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span></span>
<span id="1552"><span class="n">X_under</span><span class="p">,</span> <span class="n">y_under</span> <span class="o">=</span> <span class="n">rus</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></span>
<span id="1553"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Resampled dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y_under</span><span class="p">)))</span></span>
<span id="1554"></span>
<span id="1555"><span class="c1"># Slit into train and test datasets</span></span>
<span id="1556"><span class="n">X_train_under</span><span class="p">,</span> <span class="n">X_test_under</span><span class="p">,</span> <span class="n">y_train_under</span><span class="p">,</span> <span class="n">y_test_under</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_under</span><span class="p">,</span> <span class="n">y_under</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></span>
<span id="1557"></span>
<span id="1558"></span>
<span id="1559"><span class="c1"># ## &lt;a id=&#39;osdata&#39;&gt;2. Oversampled Data&lt;/a&gt;</span></span>
<span id="1560"></span>
<span id="1561"><span class="c1"># In[99]:</span></span>
<span id="1562"></span>
<span id="1563"></span>
<span id="1564"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Original dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span></span>
<span id="1565"></span>
<span id="1566"><span class="n">ros</span> <span class="o">=</span> <span class="n">RandomOverSampler</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span></span>
<span id="1567"><span class="n">X_over</span><span class="p">,</span> <span class="n">y_over</span> <span class="o">=</span> <span class="n">ros</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></span>
<span id="1568"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Resampled dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y_over</span><span class="p">)))</span></span>
<span id="1569"></span>
<span id="1570"><span class="c1"># Slit into train and test datasets</span></span>
<span id="1571"><span class="n">X_train_over</span><span class="p">,</span> <span class="n">X_test_over</span><span class="p">,</span> <span class="n">y_train_over</span><span class="p">,</span> <span class="n">y_test_over</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_over</span><span class="p">,</span> <span class="n">y_over</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></span>
<span id="1572"></span>
<span id="1573"></span>
<span id="1574"><span class="c1"># ## &lt;a id=&#39;smotedata&#39;&gt;3. SMOTE Data&lt;/a&gt;</span></span>
<span id="1575"></span>
<span id="1576"><span class="c1"># In[100]:</span></span>
<span id="1577"></span>
<span id="1578"></span>
<span id="1579"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Original dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span></span>
<span id="1580"></span>
<span id="1581"><span class="n">smote</span> <span class="o">=</span> <span class="n">SMOTE</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span></span>
<span id="1582"><span class="n">X_smote</span><span class="p">,</span> <span class="n">y_smote</span> <span class="o">=</span> <span class="n">smote</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></span>
<span id="1583"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Resampled dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y_smote</span><span class="p">)))</span></span>
<span id="1584"></span>
<span id="1585"><span class="c1"># Slit into train and test datasets</span></span>
<span id="1586"><span class="n">X_train_smote</span><span class="p">,</span> <span class="n">X_test_smote</span><span class="p">,</span> <span class="n">y_train_smote</span><span class="p">,</span> <span class="n">y_test_smote</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_smote</span><span class="p">,</span> <span class="n">y_smote</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></span>
<span id="1587"></span>
<span id="1588"></span>
<span id="1589"><span class="c1"># ## &lt;a id=&#39;adasyndata&#39;&gt;4. ADASYN Data&lt;/a&gt;</span></span>
<span id="1590"></span>
<span id="1591"><span class="c1"># In[101]:</span></span>
<span id="1592"></span>
<span id="1593"></span>
<span id="1594"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Original dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span></span>
<span id="1595"></span>
<span id="1596"><span class="n">adasyn</span> <span class="o">=</span> <span class="n">ADASYN</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span></span>
<span id="1597"><span class="n">X_adasyn</span><span class="p">,</span> <span class="n">y_adasyn</span> <span class="o">=</span> <span class="n">adasyn</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></span>
<span id="1598"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Resampled dataset shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y_adasyn</span><span class="p">)))</span></span>
<span id="1599"></span>
<span id="1600"><span class="c1"># Slit into train and test datasets</span></span>
<span id="1601"><span class="n">X_train_adasyn</span><span class="p">,</span> <span class="n">X_test_adasyn</span><span class="p">,</span> <span class="n">y_train_adasyn</span><span class="p">,</span> <span class="n">y_test_adasyn</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_adasyn</span><span class="p">,</span> <span class="n">y_adasyn</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></span>
<span id="1602"></span>
<span id="1603"></span>
<span id="1604"><span class="c1"># In[102]:</span></span>
<span id="1605"></span>
<span id="1606"></span>
<span id="1607"><span class="c1"># from sklearn.model_selection import cross_val_score</span></span>
<span id="1608"><span class="c1"># from sklearn.model_selection import StratifiedKFold</span></span>
<span id="1609"><span class="c1"># from sklearn.linear_model import LogisticRegression</span></span>
<span id="1610"><span class="c1"># from sklearn.tree import DecisionTreeClassifier</span></span>
<span id="1611"><span class="c1"># # from sklearn.ensemble import RandomForestClassifier</span></span>
<span id="1612"><span class="c1"># from sklearn.svm import SVC</span></span>
<span id="1613"><span class="c1"># from sklearn.neighbors import KNeighborsClassifier</span></span>
<span id="1614"><span class="c1"># from sklearn.naive_bayes import GaussianNB</span></span>
<span id="1615"></span>
<span id="1616"><span class="c1"># # Build Models</span></span>
<span id="1617"><span class="c1"># # Lets test 5 different algorithms:</span></span>
<span id="1618"></span>
<span id="1619"><span class="c1"># # Spot Check Algorithms</span></span>
<span id="1620"><span class="c1"># models = []</span></span>
<span id="1621"></span>
<span id="1622"><span class="c1"># #------------------ Logistic Regression (LR) ------------------#</span></span>
<span id="1623"><span class="c1"># models.append((&#39;LR imbalance&#39;, LogisticRegression(solver=&#39;liblinear&#39;, multi_class=&#39;ovr&#39;),X,y))</span></span>
<span id="1624"><span class="c1"># models.append((&#39;LR Undersampling&#39;, LogisticRegression(solver=&#39;liblinear&#39;, multi_class=&#39;ovr&#39;),X_under,y_under))</span></span>
<span id="1625"><span class="c1"># models.append((&#39;LR Oversampling&#39;, LogisticRegression(solver=&#39;liblinear&#39;, multi_class=&#39;ovr&#39;),X_over,y_over))</span></span>
<span id="1626"><span class="c1"># models.append((&#39;LR SMOTE&#39;, LogisticRegression(solver=&#39;liblinear&#39;, multi_class=&#39;ovr&#39;),X_smote,y_smote))</span></span>
<span id="1627"><span class="c1"># # models.append((&#39;LR ADASYN&#39;, LogisticRegression(solver=&#39;liblinear&#39;, multi_class=&#39;ovr&#39;),X_adasyn,y_adasyn))</span></span>
<span id="1628"></span>
<span id="1629"><span class="c1"># #-----------------Decision Tree (DT)------------------#</span></span>
<span id="1630"><span class="c1"># models.append((&#39;DT imbalance&#39;, DecisionTreeClassifier(),X,y))</span></span>
<span id="1631"><span class="c1"># models.append((&#39;DT Undersampling&#39;, DecisionTreeClassifier(),X_under,y_under))</span></span>
<span id="1632"><span class="c1"># models.append((&#39;DT Oversampling&#39;, DecisionTreeClassifier(),X_over,y_over))</span></span>
<span id="1633"><span class="c1"># models.append((&#39;DT SMOTE&#39;, DecisionTreeClassifier(),X_smote,y_smote))</span></span>
<span id="1634"><span class="c1"># # models.append((&#39;DT ADASYN&#39;, DecisionTreeClassifier(),X_adasyn,y_adasyn))</span></span>
<span id="1635"></span>
<span id="1636"><span class="c1"># #------------------ K-Nearest Neighbors (KNN) ------------------#</span></span>
<span id="1637"><span class="c1"># models.append((&#39;KNN imbalance&#39;, KNeighborsClassifier(),X,y))</span></span>
<span id="1638"><span class="c1"># models.append((&#39;KNN Undersampling&#39;, KNeighborsClassifier(),X_under,y_under))</span></span>
<span id="1639"><span class="c1"># models.append((&#39;KNN Oversampling&#39;, KNeighborsClassifier(),X_over,y_over))</span></span>
<span id="1640"><span class="c1"># models.append((&#39;KNN SMOTE&#39;, KNeighborsClassifier(),X_smote,y_smote))</span></span>
<span id="1641"><span class="c1"># # models.append((&#39;DT ADASYN&#39;, KNeighborsClassifier(),X_adasyn,y_adasyn))</span></span>
<span id="1642"></span>
<span id="1643"><span class="c1"># #------------------ Support Vector Machines (SVM) ------------------#</span></span>
<span id="1644"><span class="c1"># # models.append((&#39;SVM imbalance&#39;, SVC(gamma=&#39;auto&#39;),X,y))</span></span>
<span id="1645"><span class="c1"># # models.append((&#39;SVM Undersampling&#39;, SVC(gamma=&#39;auto&#39;),X_under,y_under))</span></span>
<span id="1646"><span class="c1"># # models.append((&#39;SVM Oversampling&#39;, SVC(gamma=&#39;auto&#39;),X_over,y_over))</span></span>
<span id="1647"><span class="c1"># # models.append((&#39;SVM SMOTE&#39;, SVC(gamma=&#39;auto&#39;),X_smote,y_smote))</span></span>
<span id="1648"><span class="c1"># # # models.append((&#39;SVM ADASYN&#39;, SVC(gamma=&#39;auto&#39;),X_adasyn,y_adasyn))</span></span>
<span id="1649"></span>
<span id="1650"><span class="c1"># #------------------ Gaussian Naive Bayes (NB) ------------------#</span></span>
<span id="1651"><span class="c1"># models.append((&#39;NB imbalance&#39;, GaussianNB(),X,y))</span></span>
<span id="1652"><span class="c1"># models.append((&#39;NB Undersampling&#39;, GaussianNB(),X_under,y_under))</span></span>
<span id="1653"><span class="c1"># models.append((&#39;NB Oversampling&#39;, GaussianNB(),X_over,y_over))</span></span>
<span id="1654"><span class="c1"># models.append((&#39;NB SMOTE&#39;, GaussianNB(),X_smote,y_smote))</span></span>
<span id="1655"><span class="c1"># # models.append((&#39;NB ADASYN&#39;, GaussianNB(),X_adasyn,y_adasyn))</span></span>
<span id="1656"></span>
<span id="1657"><span class="c1"># # evaluate each model in turn</span></span>
<span id="1658"><span class="c1"># names_lst = []</span></span>
<span id="1659"><span class="c1"># aucs_lst = []</span></span>
<span id="1660"><span class="c1"># accuracy_lst = []</span></span>
<span id="1661"><span class="c1"># precision_lst = []</span></span>
<span id="1662"><span class="c1"># recall_lst = []</span></span>
<span id="1663"><span class="c1"># f1_lst = []</span></span>
<span id="1664"></span>
<span id="1665"><span class="c1"># plt.figure(figsize=(14,8))</span></span>
<span id="1666"></span>
<span id="1667"><span class="c1"># for name, model,Xdata,ydata in models:</span></span>
<span id="1668">    </span>
<span id="1669"><span class="c1">#     names_lst.append(name)</span></span>
<span id="1670">    </span>
<span id="1671"><span class="c1">#     # split data in train test set</span></span>
<span id="1672"><span class="c1">#     X_train, X_test, y_train, y_test = train_test_split(Xdata, ydata, test_size=0.3, random_state=0)</span></span>
<span id="1673"><span class="c1">#     # Build model</span></span>
<span id="1674"><span class="c1">#     model.fit(X_train, y_train)</span></span>
<span id="1675"><span class="c1">#     # Predict</span></span>
<span id="1676"><span class="c1">#     y_pred = model.predict(X_test)</span></span>
<span id="1677">    </span>
<span id="1678"><span class="c1">#     # calculate accuracy</span></span>
<span id="1679"><span class="c1">#     Accuracy = metrics.accuracy_score(y_pred , y_test)</span></span>
<span id="1680"><span class="c1">#     accuracy_lst.append(Accuracy)</span></span>
<span id="1681">    </span>
<span id="1682"><span class="c1">#     # calculate auc</span></span>
<span id="1683"><span class="c1">#     Aucs = metrics.roc_auc_score(y_test , y_pred)</span></span>
<span id="1684"><span class="c1">#     aucs_lst.append(Aucs)</span></span>
<span id="1685">    </span>
<span id="1686"><span class="c1">#     # calculate precision</span></span>
<span id="1687"><span class="c1">#     PrecisionScore = metrics.precision_score(y_test , y_pred)</span></span>
<span id="1688"><span class="c1">#     precision_lst.append(PrecisionScore)</span></span>
<span id="1689">    </span>
<span id="1690"><span class="c1">#     # calculate recall</span></span>
<span id="1691"><span class="c1">#     RecallScore = metrics.recall_score(y_test , y_pred)</span></span>
<span id="1692"><span class="c1">#     recall_lst.append(RecallScore)</span></span>
<span id="1693">    </span>
<span id="1694"><span class="c1">#     # calculate f1 score</span></span>
<span id="1695"><span class="c1">#     F1Score = metrics.f1_score(y_test , y_pred)</span></span>
<span id="1696"><span class="c1">#     f1_lst.append(F1Score)</span></span>
<span id="1697">    </span>
<span id="1698"><span class="c1">#     print(&#39;F1 Score of &#39;+ name +&#39; model : {0:0.5f}&#39;.format(F1Score))</span></span>
<span id="1699">    </span>
<span id="1700"><span class="c1"># #     draw confusion matrix</span></span>
<span id="1701"><span class="c1"># #     cnf_matrix = metrics.confusion_matrix(y_test , y_pred)</span></span>
<span id="1702"></span>
<span id="1703"><span class="c1"># #     print(&quot;Model Name :&quot;, name)</span></span>
<span id="1704"><span class="c1"># #     print(&#39;Accuracy :{0:0.5f}&#39;.format(Accuracy)) </span></span>
<span id="1705"><span class="c1"># #     print(&#39;AUC : {0:0.5f}&#39;.format(Aucs))</span></span>
<span id="1706"><span class="c1"># #     print(&#39;Precision : {0:0.5f}&#39;.format(PrecisionScore))</span></span>
<span id="1707"><span class="c1"># #     print(&#39;Recall : {0:0.5f}&#39;.format(RecallScore))</span></span>
<span id="1708"><span class="c1"># #     print(&#39;F1 : {0:0.5f}&#39;.format(F1Score))</span></span>
<span id="1709"><span class="c1"># #     print(&#39;Confusion Matrix : \n&#39;, cnf_matrix)</span></span>
<span id="1710"><span class="c1"># #     print(&quot;\n&quot;)</span></span>
<span id="1711"></span>
<span id="1712">    </span>
<span id="1713"><span class="c1">#     # plot ROC Curve</span></span>
<span id="1714"><span class="c1">#     fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)</span></span>
<span id="1715"><span class="c1">#     auc = metrics.roc_auc_score(y_test, y_pred)</span></span>
<span id="1716"><span class="c1">#     plt.plot(fpr,tpr,linewidth=2, label=name + &quot;, auc=&quot;+str(auc))</span></span>
<span id="1717"><span class="c1">#     #---------- For loops ends here--------#</span></span>
<span id="1718">    </span>
<span id="1719"></span>
<span id="1720"><span class="c1"># plt.legend(loc=4)</span></span>
<span id="1721"><span class="c1"># plt.plot([0,1], [0,1], &#39;k--&#39; )</span></span>
<span id="1722"><span class="c1"># plt.rcParams[&#39;font.size&#39;] = 12</span></span>
<span id="1723"><span class="c1"># plt.title(&#39;ROC curve for Predicting a credit card fraud detection&#39;)</span></span>
<span id="1724"><span class="c1"># plt.xlabel(&#39;False Positive Rate (1 - Specificity)&#39;)</span></span>
<span id="1725"><span class="c1"># plt.ylabel(&#39;True Positive Rate (Sensitivity)&#39;)</span></span>
<span id="1726"><span class="c1"># plt.show()</span></span>
<span id="1727"></span>
<span id="1728"><span class="c1"># data = {&#39;Model&#39;:names_lst,</span></span>
<span id="1729"><span class="c1">#        &#39;Accuracy&#39;:accuracy_lst,</span></span>
<span id="1730"><span class="c1">#        &#39;AUC&#39;:aucs_lst,</span></span>
<span id="1731"><span class="c1">#        &#39;PrecisionScore&#39;:precision_lst,</span></span>
<span id="1732"><span class="c1">#        &#39;RecallScore&#39;:recall_lst,</span></span>
<span id="1733"><span class="c1">#        &#39;F1Score&#39;:f1_lst}</span></span>
<span id="1734"></span>
<span id="1735"><span class="c1"># print(&quot;Performance measures of various classifiers: \n&quot;)</span></span>
<span id="1736"><span class="c1"># performance_df = pd.DataFrame(data) </span></span>
<span id="1737"><span class="c1"># performance_df.sort_values([&#39;AUC&#39;,&#39;RecallScore&#39;,&#39;F1Score&#39;,&#39;PrecisionScore&#39;],ascending=False)</span></span>
<span id="1738"></span>
<span id="1739"></span>
<span id="1740"><span class="c1"># In[103]:</span></span>
<span id="1741"></span>
<span id="1742"></span>
<span id="1743"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span></span>
<span id="1744"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span></span>
<span id="1745"></span>
<span id="1746"><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span></span>
<span id="1747"><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span></span>
<span id="1748"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span></span>
<span id="1749"><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span></span>
<span id="1750"><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span></span>
<span id="1751"><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span></span>
<span id="1752"></span>
<span id="1753"></span>
<span id="1754"><span class="c1"># In[104]:</span></span>
<span id="1755"></span>
<span id="1756"></span>
<span id="1757"><span class="n">names_lst</span> <span class="o">=</span> <span class="p">[]</span></span>
<span id="1758"></span>
<span id="1759"><span class="c1"># Empty list to capture performance matrix for train set</span></span>
<span id="1760"><span class="n">aucs_train_lst</span> <span class="o">=</span> <span class="p">[]</span></span>
<span id="1761"><span class="n">accuracy_train_lst</span> <span class="o">=</span> <span class="p">[]</span></span>
<span id="1762"><span class="n">precision_train_lst</span> <span class="o">=</span> <span class="p">[]</span></span>
<span id="1763"><span class="n">recall_train_lst</span> <span class="o">=</span> <span class="p">[]</span></span>
<span id="1764"><span class="n">f1_train_lst</span> <span class="o">=</span> <span class="p">[]</span></span>
<span id="1765"></span>
<span id="1766"><span class="c1"># Empty list to capture performance matrix for test set</span></span>
<span id="1767"><span class="n">aucs_test_lst</span> <span class="o">=</span> <span class="p">[]</span></span>
<span id="1768"><span class="n">accuracy_test_lst</span> <span class="o">=</span> <span class="p">[]</span></span>
<span id="1769"><span class="n">precision_test_lst</span> <span class="o">=</span> <span class="p">[]</span></span>
<span id="1770"><span class="n">recall_test_lst</span> <span class="o">=</span> <span class="p">[]</span></span>
<span id="1771"><span class="n">f1_test_lst</span> <span class="o">=</span> <span class="p">[]</span></span>
<span id="1772"></span>
<span id="1773"><span class="c1"># Function for model building and performance measure</span></span>
<span id="1774"></span>
<span id="1775"><span class="k">def</span> <span class="nf">build_measure_model</span><span class="p">(</span><span class="n">models</span><span class="p">):</span></span>
<span id="1776">    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span></span>
<span id="1777"></span>
<span id="1778">    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span><span class="n">Xdata</span><span class="p">,</span><span class="n">ydata</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span></span>
<span id="1779">        </span>
<span id="1780">        <span class="n">names_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span></span>
<span id="1781"></span>
<span id="1782">        <span class="c1"># split data in train test set</span></span>
<span id="1783">        <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">Xdata</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></span>
<span id="1784">        </span>
<span id="1785">        <span class="c1"># Build model</span></span>
<span id="1786">        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">train</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1786, 1789, 1790])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">overlap with all test data</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">no independent test data</button>
<span id="1787">        </span>
<span id="1788">        <span class="c1"># Predict</span></span>
<span id="1789">        <span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1786, 1789, 1790])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">overlap with training data</button> <button type="button" style="line-height: 85%; None" onclick="mark_leak_lines([1245, 1329, 1408, 1567, 1582, 1597])">potential leak src</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1174, 1259, 1343, 1421, 1789, 1790, 2053, 2076, 2098, 2128, 860])">highlight other usage</button>
<span id="1790">        <span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1786, 1789, 1790])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">overlap with training data</button> <button type="button" style="line-height: 85%; None" onclick="mark_leak_lines([1245, 1329, 1408, 1567, 1582, 1597])">potential leak src</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1174, 1259, 1343, 1421, 1789, 1790, 2053, 2076, 2098, 2128, 860])">highlight other usage</button>
<span id="1791"></span>
<span id="1792">        <span class="c1"># calculate accuracy</span></span>
<span id="1793">        <span class="n">Accuracy_train</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span></span>
<span id="1794">        <span class="n">accuracy_train_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Accuracy_train</span><span class="p">)</span></span>
<span id="1795">        </span>
<span id="1796">        <span class="n">Accuracy_test</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span></span>
<span id="1797">        <span class="n">accuracy_test_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Accuracy_test</span><span class="p">)</span></span>
<span id="1798"></span>
<span id="1799">        <span class="c1"># calculate auc</span></span>
<span id="1800">        <span class="n">Aucs_train</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span></span>
<span id="1801">        <span class="n">aucs_train_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Aucs_train</span><span class="p">)</span></span>
<span id="1802">        </span>
<span id="1803">        <span class="n">Aucs_test</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span></span>
<span id="1804">        <span class="n">aucs_test_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Aucs_test</span><span class="p">)</span></span>
<span id="1805"></span>
<span id="1806">        <span class="c1"># calculate precision</span></span>
<span id="1807">        <span class="n">PrecisionScore_train</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_train</span> <span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span></span>
<span id="1808">        <span class="n">precision_train_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PrecisionScore_train</span><span class="p">)</span></span>
<span id="1809">        </span>
<span id="1810">        <span class="n">PrecisionScore_test</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span></span>
<span id="1811">        <span class="n">precision_test_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PrecisionScore_test</span><span class="p">)</span></span>
<span id="1812"></span>
<span id="1813">        <span class="c1"># calculate recall</span></span>
<span id="1814">        <span class="n">RecallScore_train</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_train</span> <span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span></span>
<span id="1815">        <span class="n">recall_train_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">RecallScore_train</span><span class="p">)</span></span>
<span id="1816">        </span>
<span id="1817">        <span class="n">RecallScore_test</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span></span>
<span id="1818">        <span class="n">recall_test_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">RecallScore_test</span><span class="p">)</span></span>
<span id="1819"></span>
<span id="1820">        <span class="c1"># calculate f1 score</span></span>
<span id="1821">        <span class="n">F1Score_train</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_train</span> <span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span></span>
<span id="1822">        <span class="n">f1_train_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F1Score_train</span><span class="p">)</span></span>
<span id="1823">        </span>
<span id="1824">        <span class="n">F1Score_test</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span></span>
<span id="1825">        <span class="n">f1_test_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F1Score_test</span><span class="p">)</span></span>
<span id="1826"></span>
<span id="1827">        <span class="c1">#print(&#39;F1 Score of &#39;+ name +&#39; model : {0:0.5f}&#39;.format(F1Score_test))</span></span>
<span id="1828"></span>
<span id="1829">        <span class="c1"># draw confusion matrix</span></span>
<span id="1830">        <span class="n">cnf_matrix</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span></span>
<span id="1831"></span>
<span id="1832">        <span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Model Name :&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span></span>
<span id="1833">        </span>
<span id="1834">        <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Train Accuracy :</span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">Accuracy_train</span><span class="p">)))</span> </span>
<span id="1835">        <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Test Accuracy :</span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">Accuracy_test</span><span class="p">)))</span></span>
<span id="1836">        </span>
<span id="1837">        <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Train AUC : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">Aucs_train</span><span class="p">)))</span></span>
<span id="1838">        <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Test AUC : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">Aucs_test</span><span class="p">)))</span></span>
<span id="1839">        </span>
<span id="1840">        <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Train Precision : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">PrecisionScore_train</span><span class="p">)))</span></span>
<span id="1841">        <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Test Precision : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">PrecisionScore_test</span><span class="p">)))</span></span>
<span id="1842">        </span>
<span id="1843">        <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Train Recall : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">RecallScore_train</span><span class="p">)))</span></span>
<span id="1844">        <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Test Recall : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">RecallScore_test</span><span class="p">)))</span></span>
<span id="1845">        </span>
<span id="1846">        <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Train F1 : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">F1Score_train</span><span class="p">)))</span></span>
<span id="1847">        <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Test F1 : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">F1Score_test</span><span class="p">)))</span></span>
<span id="1848">        </span>
<span id="1849">        <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Confusion Matrix : </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">cnf_matrix</span><span class="p">))</span></span>
<span id="1850">        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span></span>
<span id="1851"></span>
<span id="1852"></span>
<span id="1853">        <span class="c1"># plot ROC Curve</span></span>
<span id="1854">        <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span></span>
<span id="1855">        <span class="n">auc</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span></span>
<span id="1856">        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;, auc=&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">auc</span><span class="p">))</span></span>
<span id="1857">    </span>
<span id="1858">        <span class="c1">#---------- For loops ends here--------#</span></span>
<span id="1859"></span>
<span id="1860"></span>
<span id="1861">    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span></span>
<span id="1862">    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span> <span class="p">)</span></span>
<span id="1863">    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span></span>
<span id="1864">    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;ROC curve for Predicting a credit card fraud detection&#39;</span><span class="p">)</span></span>
<span id="1865">    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate (1 - Specificity)&#39;</span><span class="p">)</span></span>
<span id="1866">    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate (Sensitivity)&#39;</span><span class="p">)</span></span>
<span id="1867">    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span>
<span id="1868"></span>
<span id="1869"></span>
<span id="1870"><span class="c1"># ### Logistic Regression (LR)</span></span>
<span id="1871"></span>
<span id="1872"><span class="c1"># In[105]:</span></span>
<span id="1873"></span>
<span id="1874"></span>
<span id="1875"><span class="c1">#------------------ Logistic Regression (LR) ------------------#</span></span>
<span id="1876"><span class="n">LRmodels</span> <span class="o">=</span> <span class="p">[]</span></span>
<span id="1877"></span>
<span id="1878"><span class="n">LRmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;LR imbalance&#39;</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">),</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">))</span></span>
<span id="1879"><span class="n">LRmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;LR Undersampling&#39;</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">),</span><span class="n">X_under</span><span class="p">,</span><span class="n">y_under</span><span class="p">))</span></span>
<span id="1880"><span class="n">LRmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;LR Oversampling&#39;</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">),</span><span class="n">X_over</span><span class="p">,</span><span class="n">y_over</span><span class="p">))</span></span>
<span id="1881"><span class="n">LRmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;LR SMOTE&#39;</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">),</span><span class="n">X_smote</span><span class="p">,</span><span class="n">y_smote</span><span class="p">))</span></span>
<span id="1882"><span class="n">LRmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;LR ADASYN&#39;</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">),</span><span class="n">X_adasyn</span><span class="p">,</span><span class="n">y_adasyn</span><span class="p">))</span></span>
<span id="1883"></span>
<span id="1884"><span class="c1"># Call function to create model and measure its performance</span></span>
<span id="1885"><span class="n">build_measure_model</span><span class="p">(</span><span class="n">LRmodels</span><span class="p">)</span></span>
<span id="1886"></span>
<span id="1887"></span>
<span id="1888"><span class="c1"># ### Decision Tree (DT)</span></span>
<span id="1889"></span>
<span id="1890"><span class="c1"># In[106]:</span></span>
<span id="1891"></span>
<span id="1892"></span>
<span id="1893"><span class="c1">#-----------------Decision Tree (DT)------------------#</span></span>
<span id="1894"><span class="n">DTmodels</span> <span class="o">=</span> <span class="p">[]</span></span>
<span id="1895"></span>
<span id="1896"><span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span></span>
<span id="1897"></span>
<span id="1898"><span class="n">DTmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;DT imbalance&#39;</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">))</span></span>
<span id="1899"><span class="n">DTmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;DT Undersampling&#39;</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span><span class="n">X_under</span><span class="p">,</span><span class="n">y_under</span><span class="p">))</span></span>
<span id="1900"><span class="n">DTmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;DT Oversampling&#39;</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span><span class="n">X_over</span><span class="p">,</span><span class="n">y_over</span><span class="p">))</span></span>
<span id="1901"><span class="n">DTmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;DT SMOTE&#39;</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span><span class="n">X_smote</span><span class="p">,</span><span class="n">y_smote</span><span class="p">))</span></span>
<span id="1902"><span class="n">DTmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;DT ADASYN&#39;</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span><span class="n">X_adasyn</span><span class="p">,</span><span class="n">y_adasyn</span><span class="p">))</span></span>
<span id="1903"></span>
<span id="1904"><span class="c1"># Call function to create model and measure its performance</span></span>
<span id="1905"><span class="n">build_measure_model</span><span class="p">(</span><span class="n">DTmodels</span><span class="p">)</span></span>
<span id="1906"></span>
<span id="1907"></span>
<span id="1908"><span class="c1"># ### Random Forest (RF)</span></span>
<span id="1909"></span>
<span id="1910"><span class="c1"># In[107]:</span></span>
<span id="1911"></span>
<span id="1912"></span>
<span id="1913"><span class="c1">#-----------------Random Forest (RF) ------------------#</span></span>
<span id="1914"><span class="n">RFmodels</span> <span class="o">=</span> <span class="p">[]</span></span>
<span id="1915"></span>
<span id="1916"><span class="n">RFmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;RF imbalance&#39;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(),</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">))</span></span>
<span id="1917"><span class="n">RFmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;RF Undersampling&#39;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(),</span><span class="n">X_under</span><span class="p">,</span><span class="n">y_under</span><span class="p">))</span></span>
<span id="1918"><span class="n">RFmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;RF Oversampling&#39;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(),</span><span class="n">X_over</span><span class="p">,</span><span class="n">y_over</span><span class="p">))</span></span>
<span id="1919"><span class="n">RFmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;RF SMOTE&#39;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(),</span><span class="n">X_smote</span><span class="p">,</span><span class="n">y_smote</span><span class="p">))</span></span>
<span id="1920"><span class="n">RFmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;RF ADASYN&#39;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(),</span><span class="n">X_adasyn</span><span class="p">,</span><span class="n">y_adasyn</span><span class="p">))</span></span>
<span id="1921"></span>
<span id="1922"><span class="c1"># Call function to create model and measure its performance</span></span>
<span id="1923"><span class="n">build_measure_model</span><span class="p">(</span><span class="n">RFmodels</span><span class="p">)</span></span>
<span id="1924"></span>
<span id="1925"></span>
<span id="1926"><span class="c1"># In[108]:</span></span>
<span id="1927"></span>
<span id="1928"></span>
<span id="1929"><span class="c1"># #------------------ K-Nearest Neighbors (KNN) ------------------#</span></span>
<span id="1930"><span class="c1"># KNNmodels = []</span></span>
<span id="1931"></span>
<span id="1932"><span class="c1"># KNNmodels.append((&#39;KNN imbalance&#39;, KNeighborsClassifier(),X,y))</span></span>
<span id="1933"><span class="c1"># KNNmodels.append((&#39;KNN Undersampling&#39;, KNeighborsClassifier(),X_under,y_under))</span></span>
<span id="1934"><span class="c1"># KNNmodels.append((&#39;KNN Oversampling&#39;, KNeighborsClassifier(),X_over,y_over))</span></span>
<span id="1935"><span class="c1"># KNNmodels.append((&#39;KNN SMOTE&#39;, KNeighborsClassifier(),X_smote,y_smote))</span></span>
<span id="1936"><span class="c1"># KNNmodels.append((&#39;KNN ADASYN&#39;, KNeighborsClassifier(),X_adasyn,y_adasyn))</span></span>
<span id="1937"></span>
<span id="1938"><span class="c1"># Call function to create model and measure its performance</span></span>
<span id="1939"><span class="c1"># build_measure_model(KNNmodels)</span></span>
<span id="1940"></span>
<span id="1941"></span>
<span id="1942"><span class="c1"># In[109]:</span></span>
<span id="1943"></span>
<span id="1944"></span>
<span id="1945"><span class="c1"># #------------------ Support Vector Machines (SVM) ------------------#</span></span>
<span id="1946"><span class="c1"># SVMmodels = []</span></span>
<span id="1947"></span>
<span id="1948"><span class="c1"># SVMmodels.append((&#39;SVM imbalance&#39;, SVC(gamma=&#39;auto&#39;),X,y))</span></span>
<span id="1949"><span class="c1"># SVMmodels.append((&#39;SVM Undersampling&#39;, SVC(gamma=&#39;auto&#39;),X_under,y_under))</span></span>
<span id="1950"><span class="c1"># SVMmodels.append((&#39;SVM Oversampling&#39;, SVC(gamma=&#39;auto&#39;),X_over,y_over))</span></span>
<span id="1951"><span class="c1"># SVMmodels.append((&#39;SVM SMOTE&#39;, SVC(gamma=&#39;auto&#39;),X_smote,y_smote))</span></span>
<span id="1952"><span class="c1"># SVMmodels.append((&#39;SVM ADASYN&#39;, SVC(gamma=&#39;auto&#39;),X_adasyn,y_adasyn))</span></span>
<span id="1953"></span>
<span id="1954"><span class="c1"># Call function to create model and measure its performance</span></span>
<span id="1955"><span class="c1"># build_measure_model(SVMmodels)</span></span>
<span id="1956"></span>
<span id="1957"></span>
<span id="1958"><span class="c1"># ### Naive Bayes (NB)</span></span>
<span id="1959"></span>
<span id="1960"><span class="c1"># In[110]:</span></span>
<span id="1961"></span>
<span id="1962"></span>
<span id="1963"><span class="c1">#------------------ Gaussian Naive Bayes (NB) ------------------#</span></span>
<span id="1964"><span class="n">NBmodels</span> <span class="o">=</span> <span class="p">[]</span></span>
<span id="1965"></span>
<span id="1966"><span class="n">NBmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;NB imbalance&#39;</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">(),</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">))</span></span>
<span id="1967"><span class="n">NBmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;NB Undersampling&#39;</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">(),</span><span class="n">X_under</span><span class="p">,</span><span class="n">y_under</span><span class="p">))</span></span>
<span id="1968"><span class="n">NBmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;NB Oversampling&#39;</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">(),</span><span class="n">X_over</span><span class="p">,</span><span class="n">y_over</span><span class="p">))</span></span>
<span id="1969"><span class="n">NBmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;NB SMOTE&#39;</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">(),</span><span class="n">X_smote</span><span class="p">,</span><span class="n">y_smote</span><span class="p">))</span></span>
<span id="1970"><span class="n">NBmodels</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;NB ADASYN&#39;</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">(),</span><span class="n">X_adasyn</span><span class="p">,</span><span class="n">y_adasyn</span><span class="p">))</span></span>
<span id="1971"></span>
<span id="1972"><span class="c1"># Call function to create model and measure its performance</span></span>
<span id="1973"><span class="n">build_measure_model</span><span class="p">(</span><span class="n">NBmodels</span><span class="p">)</span></span>
<span id="1974"></span>
<span id="1975"></span>
<span id="1976"><span class="c1"># ### Performance measures of various classifiers</span></span>
<span id="1977"></span>
<span id="1978"><span class="c1"># In[111]:</span></span>
<span id="1979"></span>
<span id="1980"></span>
<span id="1981"><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Model&#39;</span><span class="p">:</span><span class="n">names_lst</span><span class="p">,</span></span>
<span id="1982">       <span class="s1">&#39;Accuracy_Train&#39;</span><span class="p">:</span><span class="n">accuracy_train_lst</span><span class="p">,</span></span>
<span id="1983">       <span class="s1">&#39;Accuracy_Test&#39;</span><span class="p">:</span><span class="n">accuracy_test_lst</span><span class="p">,</span></span>
<span id="1984">       <span class="s1">&#39;AUC_Train&#39;</span><span class="p">:</span><span class="n">aucs_train_lst</span><span class="p">,</span></span>
<span id="1985">       <span class="s1">&#39;AUC_Test&#39;</span><span class="p">:</span><span class="n">aucs_test_lst</span><span class="p">,</span></span>
<span id="1986">       <span class="s1">&#39;PrecisionScore_Train&#39;</span><span class="p">:</span><span class="n">precision_train_lst</span><span class="p">,</span></span>
<span id="1987">       <span class="s1">&#39;PrecisionScore_Test&#39;</span><span class="p">:</span><span class="n">precision_test_lst</span><span class="p">,</span></span>
<span id="1988">       <span class="s1">&#39;RecallScore_Train&#39;</span><span class="p">:</span><span class="n">recall_train_lst</span><span class="p">,</span></span>
<span id="1989">       <span class="s1">&#39;RecallScore_Test&#39;</span><span class="p">:</span><span class="n">recall_test_lst</span><span class="p">,</span></span>
<span id="1990">       <span class="s1">&#39;F1Score_Train&#39;</span><span class="p">:</span><span class="n">f1_train_lst</span><span class="p">,</span></span>
<span id="1991">       <span class="s1">&#39;F1Score_Test&#39;</span><span class="p">:</span><span class="n">f1_test_lst</span><span class="p">}</span></span>
<span id="1992"></span>
<span id="1993"><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Performance measures of various classifiers: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span></span>
<span id="1994"><span class="n">performance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> </span>
<span id="1995"><span class="n">performance_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">([</span><span class="s1">&#39;AUC_Test&#39;</span><span class="p">,</span><span class="s1">&#39;RecallScore_Test&#39;</span><span class="p">,</span><span class="s1">&#39;F1Score_Test&#39;</span><span class="p">],</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></span>
<span id="1996"></span>
<span id="1997"></span>
<span id="1998"><span class="c1"># **Hightlights**</span></span>
<span id="1999"><span class="c1"># </span></span>
<span id="2000"><span class="c1"># After training each of the models, these are the final results. All of the scores for Random Forest with Oversampling technique and the Random Forest with SMOTE technique models are very promising for our dataset! Each model has a high true positive rate and a low false-positive rate, which is exactly what were looking for.</span></span>
<span id="2001"><span class="c1"># </span></span>
<span id="2002"><span class="c1"># </span></span>
<span id="2003"><span class="c1"># In the ROC graph above, the AUC scores for Random Forest with Oversampling technique is pretty high, which is what wed like to see. As we move further right along the curve, we both capture more True Positives but also incur more False Positives. This means we capture more fraudulent transactions, but also flag even more normal transactions as fraudulent.</span></span>
<span id="2004"><span class="c1"># </span></span>
<span id="2005"><span class="c1"># **So Random Forest with Oversampling technique is our final model, as this gives highest Recall score of 100% on both train and test datasets.**</span></span>
<span id="2006"></span>
<span id="2007"><span class="c1"># # &lt;a id=&#39;gridsearch&#39;&gt;Grid Search&lt;/a&gt;</span></span>
<span id="2008"><span class="c1"># </span></span>
<span id="2009"><span class="c1"># Grid search is the process of performing hyper parameter tuning in order to determine the optimal values for a given model. This is significant as the performance of the entire model is based on the hyper parameter values specified.</span></span>
<span id="2010"><span class="c1"># </span></span>
<span id="2011"><span class="c1"># A **model hyperparameter** is a characteristic of a model that is external to the model and whose value cannot be estimated from data. The value of the hyperparameter has to be set before the learning process begins. For example, c in Support Vector Machines, k in k-Nearest Neighbors, the number of hidden layers in Neural Networks.</span></span>
<span id="2012"><span class="c1"># </span></span>
<span id="2013"><span class="c1"># In contrast, a **parameter** is an internal characteristic of the model and its value can be estimated from data. Example, beta coefficients of linear/logistic regression or support vectors in Support Vector Machines.</span></span>
<span id="2014"><span class="c1"># </span></span>
<span id="2015"><span class="c1"># Ref: </span></span>
<span id="2016"><span class="c1"># * https://medium.com/datadriveninvestor/an-introduction-to-grid-search-ff57adcc0998</span></span>
<span id="2017"><span class="c1"># * https://towardsdatascience.com/grid-search-for-hyperparameter-tuning-9f63945e8fec</span></span>
<span id="2018"><span class="c1"># * https://www.youtube.com/watch?v=Gol_qOgRqfA</span></span>
<span id="2019"><span class="c1"># </span></span>
<span id="2020"><span class="c1"># **Youtube**</span></span>
<span id="2021"></span>
<span id="2022"><span class="c1"># In[112]:</span></span>
<span id="2023"></span>
<span id="2024"></span>
<span id="2025"><span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;Gol_qOgRqfA&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span></span>
<span id="2026"></span>
<span id="2027"></span>
<span id="2028"><span class="c1"># In[113]:</span></span>
<span id="2029"></span>
<span id="2030"></span>
<span id="2031"><span class="c1"># Use GridSearchCV to find the best parameters.</span></span>
<span id="2032"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span></span>
<span id="2033"></span>
<span id="2034"></span>
<span id="2035"><span class="c1"># ## &lt;a id=&#39;gridsearchLR&#39;&gt; 1. Grid Search with Logistic Regression&lt;/a&gt;</span></span>
<span id="2036"></span>
<span id="2037"><span class="c1"># In[114]:</span></span>
<span id="2038"></span>
<span id="2039"></span>
<span id="2040"><span class="c1">#------------ Logistic Regression ------------#</span></span>
<span id="2041"><span class="n">log_reg_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;solver&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;saga&#39;</span><span class="p">],</span></span>
<span id="2042">                  <span class="s2">&quot;penalty&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">],</span> </span>
<span id="2043">                  <span class="s1">&#39;C&#39;</span><span class="p">:</span>  <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> </span>
<span id="2044">                  <span class="s2">&quot;max_iter&quot;</span> <span class="p">:</span> <span class="p">[</span><span class="mi">100000</span><span class="p">]},</span></span>
<span id="2045"></span>
<span id="2046"><span class="n">grid_log_reg</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(),</span> <span class="n">log_reg_params</span><span class="p">)</span></span>
<span id="2047"><span class="n">grid_log_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_under</span><span class="p">,</span><span class="n">y_train_under</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">train</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([2047, 2053])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">no independent test data</button>
<span id="2048"></span>
<span id="2049"><span class="c1"># Logistic Regression best estimator</span></span>
<span id="2050"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Logistic Regression best estimator : </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">grid_log_reg</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">))</span></span>
<span id="2051"></span>
<span id="2052"><span class="c1"># predict test dataset</span></span>
<span id="2053"><span class="n">y_pred_lr</span> <span class="o">=</span> <span class="n">grid_log_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_under</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([2047, 2053])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1259, 1343, 1421, 1789, 1790, 2053, 2076, 2098, 2128])">highlight other usage</button>
<span id="2054"></span>
<span id="2055"><span class="c1"># f1 score</span></span>
<span id="2056"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Logistic Regression f1 Score : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test_under</span> <span class="p">,</span> <span class="n">y_pred_lr</span><span class="p">))))</span></span>
<span id="2057"></span>
<span id="2058"></span>
<span id="2059"><span class="c1"># ## &lt;a id=&#39;gridsearchKNN&#39;&gt; 2. Grid Search with K Nearest Neighbour Classifier&lt;/a&gt;</span></span>
<span id="2060"></span>
<span id="2061"><span class="c1"># In[115]:</span></span>
<span id="2062"></span>
<span id="2063"></span>
<span id="2064"><span class="c1">#------------ K Nearest Neighbour ------------#</span></span>
<span id="2065"><span class="n">knears_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;n_neighbors&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">60</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> </span>
<span id="2066">                 <span class="s1">&#39;algorithm&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;ball_tree&#39;</span><span class="p">,</span> <span class="s1">&#39;kd_tree&#39;</span><span class="p">,</span> <span class="s1">&#39;brute&#39;</span><span class="p">]}</span></span>
<span id="2067"></span>
<span id="2068"><span class="n">grid_knears</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">knears_params</span><span class="p">)</span></span>
<span id="2069"></span>
<span id="2070"><span class="n">grid_knears</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_under</span><span class="p">,</span><span class="n">y_train_under</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">train</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([2070, 2076])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">no independent test data</button>
<span id="2071"></span>
<span id="2072"><span class="c1"># KNears best estimator</span></span>
<span id="2073"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;KNN best estimator : </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">grid_knears</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">))</span></span>
<span id="2074"></span>
<span id="2075"><span class="c1"># predict test dataset</span></span>
<span id="2076"><span class="n">y_pred_knn</span> <span class="o">=</span> <span class="n">grid_knears</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_under</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([2070, 2076])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1259, 1343, 1421, 1789, 1790, 2053, 2076, 2098, 2128])">highlight other usage</button>
<span id="2077"></span>
<span id="2078"><span class="c1"># f1 score</span></span>
<span id="2079"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">KNN f1 Score : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test_under</span> <span class="p">,</span> <span class="n">y_pred_knn</span><span class="p">))))</span></span>
<span id="2080"></span>
<span id="2081"></span>
<span id="2082"><span class="c1"># ## &lt;a id=&#39;gridsearchSVC&#39;&gt; 3. Grid Search with Support Vector Classifier&lt;/a&gt;</span></span>
<span id="2083"></span>
<span id="2084"><span class="c1"># In[116]:</span></span>
<span id="2085"></span>
<span id="2086"></span>
<span id="2087"><span class="c1">#------------ Support Vector Classifier ------------#</span></span>
<span id="2088"><span class="n">svc_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> </span>
<span id="2089">              <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="s1">&#39;linear&#39;</span><span class="p">]}</span></span>
<span id="2090"></span>
<span id="2091"><span class="n">grid_svc</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">svc_params</span><span class="p">)</span></span>
<span id="2092"><span class="n">grid_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_under</span><span class="p">,</span><span class="n">y_train_under</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">train</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([2092, 2098])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">no independent test data</button>
<span id="2093"></span>
<span id="2094"><span class="c1"># SVC best estimator</span></span>
<span id="2095"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;SVC best estimator : </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">grid_svc</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">))</span></span>
<span id="2096"></span>
<span id="2097"><span class="c1"># predict test dataset</span></span>
<span id="2098"><span class="n">y_pred_svc</span> <span class="o">=</span> <span class="n">grid_svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_under</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([2092, 2098])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1259, 1343, 1421, 1789, 1790, 2053, 2076, 2098, 2128])">highlight other usage</button>
<span id="2099"></span>
<span id="2100"><span class="c1"># f1 score</span></span>
<span id="2101"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">SVC f1 Score : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test_under</span> <span class="p">,</span> <span class="n">y_pred_svc</span><span class="p">))))</span></span>
<span id="2102"></span>
<span id="2103"></span>
<span id="2104"><span class="c1"># ## &lt;a id=&#39;gridsearchDT&#39;&gt; 4. Grid Search with Decision Tree Classifier&lt;/a&gt;</span></span>
<span id="2105"></span>
<span id="2106"><span class="c1"># In[117]:</span></span>
<span id="2107"></span>
<span id="2108"></span>
<span id="2109"><span class="c1">#------------ DecisionTree Classifier ------------#</span></span>
<span id="2110"><span class="n">tree_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;criterion&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;gini&quot;</span><span class="p">,</span> <span class="s2">&quot;entropy&quot;</span><span class="p">],</span> </span>
<span id="2111">               <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> </span>
<span id="2112">               <span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">))}</span></span>
<span id="2113"></span>
<span id="2114"><span class="n">grid_tree</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(),</span></span>
<span id="2115">                        <span class="n">param_grid</span> <span class="o">=</span> <span class="n">tree_params</span><span class="p">,</span></span>
<span id="2116">                        <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> </span>
<span id="2117">                        <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> </span>
<span id="2118">                        <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span></span>
<span id="2119">                        <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span></span>
<span id="2120"></span>
<span id="2121"></span>
<span id="2122"><span class="n">grid_tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_under</span><span class="p">,</span><span class="n">y_train_under</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">train</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([2122, 2128])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">no independent test data</button>
<span id="2123"></span>
<span id="2124"><span class="c1"># tree best estimator</span></span>
<span id="2125"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Decision Tree best estimator : </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">grid_tree</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">))</span></span>
<span id="2126"></span>
<span id="2127"><span class="c1"># predict test dataset</span></span>
<span id="2128"><span class="n">y_pred_dt</span> <span class="o">=</span> <span class="n">grid_tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_under</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([2122, 2128])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([1259, 1343, 1421, 1789, 1790, 2053, 2076, 2098, 2128])">highlight other usage</button>
<span id="2129"></span>
<span id="2130"></span>
<span id="2131"><span class="c1"># f1 score</span></span>
<span id="2132"><span class="nb">print</span><span class="p">((</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">f1 Score : </span><span class="si">{0:0.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test_under</span> <span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">))))</span></span>
<span id="2133"></span>
<span id="2134"></span>
<span id="2135"><span class="c1"># # &lt;a id=&#39;concl&#39;&gt;Conclusion&lt;/a&gt;</span></span>
<span id="2136"><span class="c1"># </span></span>
<span id="2137"><span class="c1"># We were able to accurately identify fraudulent credit card transactions using a random forest model with oversampling technique. We, therefore, chose the random forest model with oversampling technique as the better model, which obtained recall score of 99% on the test set.</span></span>
<span id="2138"><span class="c1"># </span></span>
<span id="2139"><span class="c1"># **I hope I was able to explain my findings well and thanks so much for reading!**</span></span>
<span id="2140"><span class="c1"># </span></span>
<span id="2141"><span class="c1"># </span></span>
<span id="2142"><span class="c1"># ### I welcome comments, suggestions, corrections and of course votes also.</span></span>
</pre></div>
</td></tr></table></body>
</html>
