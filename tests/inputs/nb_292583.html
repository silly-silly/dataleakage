<script>
    let highlighted = [];
    function highlight_lines(lines) {
        for (let line of highlighted) {
            let ele = document.getElementById(String(line));
            ele.style.backgroundColor = '';
        }
        highlighted = lines;
        for (let line of highlighted) {
            let ele = document.getElementById(String(line));
            ele.style.backgroundColor = 'yellow';
        }
    }
    let marked = [];
    function mark_leak_lines(lines) {
        for (let line of marked) {
            let ele = document.getElementById(String(line));
            ele.style.backgroundColor = '';
        }
        marked = lines;
        for (let line of marked) {
            let ele = document.getElementById(String(line));
            ele.style.backgroundColor = ele.style.backgroundColor = 'lightgreen';
        }
    }
    function show_infos(lines) {
        for (let line of lines) {
            let ele = document.getElementById(String(line) + "-info");
            if (ele) {
                ele.style.display = ele.style.display == 'none'? '': 'none'
            }
        }
    }
</script>
    <style type="text/css">
    .sum table {
    font-family: arial, sans-serif;
    border-collapse: collapse;
    width: 100%;
    }

    .sum td, .sum th {
    border: 1px solid #dddddd;
    text-align: left;
    padding: 8px;
    }

    .sum tr:hover {background-color: #D6EEEE;}
</style>
<center>
<table class="sum">
  <tbody><tr>
    <th>Leakage</th>
    <th>#Detected</th>
    <th>Locations</th>
  </tr>
  <tr>
    <td>Pre-processing leakage</td>
    <td>5</td>
    <td><a href="#307"><button type="button" style="line-height: 85%; None" onclick="None">307</button></a> <a href="#308"><button type="button" style="line-height: 85%; None" onclick="None">308</button></a> <a href="#431"><button type="button" style="line-height: 85%; None" onclick="None">431</button></a> <a href="#432"><button type="button" style="line-height: 85%; None" onclick="None">432</button></a> <a href="#520"><button type="button" style="line-height: 85%; None" onclick="None">520</button></a></td>
  </tr>
  <tr>
    <td>Overlap leakage</td>
    <td>0</td>
    <td></td>
  </tr>
  <tr>
    <td>No independence test data</td>
    <td>1</td>
    <td><a href="#307"><button type="button" style="line-height: 85%; None" onclick="None">307</button></a> <a href="#308"><button type="button" style="line-height: 85%; None" onclick="None">308</button></a> <a href="#370"><button type="button" style="line-height: 85%; None" onclick="None">370</button></a> <a href="#431"><button type="button" style="line-height: 85%; None" onclick="None">431</button></a> <a href="#432"><button type="button" style="line-height: 85%; None" onclick="None">432</button></a> <a href="#520"><button type="button" style="line-height: 85%; None" onclick="None">520</button></a></td>
  </tr>
</tbody></table></center>

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"
   "http://www.w3.org/TR/html4/strict.dtd">
<!--
generated by Pygments <https://pygments.org/>
Copyright 2006-2021 by the Pygments team.
Licensed under the BSD license, see LICENSE for details.
-->
<html>
<head>
  <title></title>
  <meta http-equiv="content-type" content="text/html; charset=None">
  <style type="text/css">
/*
generated by Pygments <https://pygments.org/>
Copyright 2006-2021 by the Pygments team.
Licensed under the BSD license, see LICENSE for details.
*/
pre { line-height: 145%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
body .hll { background-color: #ffffcc }
body { background: #f8f8f8; }
body .c { color: #408080; font-style: italic } /* Comment */
body .err { border: 1px solid #FF0000 } /* Error */
body .k { color: #008000; font-weight: bold } /* Keyword */
body .o { color: #666666 } /* Operator */
body .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
body .cm { color: #408080; font-style: italic } /* Comment.Multiline */
body .cp { color: #BC7A00 } /* Comment.Preproc */
body .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
body .c1 { color: #408080; font-style: italic } /* Comment.Single */
body .cs { color: #408080; font-style: italic } /* Comment.Special */
body .gd { color: #A00000 } /* Generic.Deleted */
body .ge { font-style: italic } /* Generic.Emph */
body .gr { color: #FF0000 } /* Generic.Error */
body .gh { color: #000080; font-weight: bold } /* Generic.Heading */
body .gi { color: #00A000 } /* Generic.Inserted */
body .go { color: #888888 } /* Generic.Output */
body .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
body .gs { font-weight: bold } /* Generic.Strong */
body .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
body .gt { color: #0044DD } /* Generic.Traceback */
body .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
body .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
body .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
body .kp { color: #008000 } /* Keyword.Pseudo */
body .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
body .kt { color: #B00040 } /* Keyword.Type */
body .m { color: #666666 } /* Literal.Number */
body .s { color: #BA2121 } /* Literal.String */
body .na { color: #7D9029 } /* Name.Attribute */
body .nb { color: #008000 } /* Name.Builtin */
body .nc { color: #0000FF; font-weight: bold } /* Name.Class */
body .no { color: #880000 } /* Name.Constant */
body .nd { color: #AA22FF } /* Name.Decorator */
body .ni { color: #999999; font-weight: bold } /* Name.Entity */
body .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
body .nf { color: #0000FF } /* Name.Function */
body .nl { color: #A0A000 } /* Name.Label */
body .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
body .nt { color: #008000; font-weight: bold } /* Name.Tag */
body .nv { color: #19177C } /* Name.Variable */
body .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
body .w { color: #bbbbbb } /* Text.Whitespace */
body .mb { color: #666666 } /* Literal.Number.Bin */
body .mf { color: #666666 } /* Literal.Number.Float */
body .mh { color: #666666 } /* Literal.Number.Hex */
body .mi { color: #666666 } /* Literal.Number.Integer */
body .mo { color: #666666 } /* Literal.Number.Oct */
body .sa { color: #BA2121 } /* Literal.String.Affix */
body .sb { color: #BA2121 } /* Literal.String.Backtick */
body .sc { color: #BA2121 } /* Literal.String.Char */
body .dl { color: #BA2121 } /* Literal.String.Delimiter */
body .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
body .s2 { color: #BA2121 } /* Literal.String.Double */
body .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
body .sh { color: #BA2121 } /* Literal.String.Heredoc */
body .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
body .sx { color: #008000 } /* Literal.String.Other */
body .sr { color: #BB6688 } /* Literal.String.Regex */
body .s1 { color: #BA2121 } /* Literal.String.Single */
body .ss { color: #19177C } /* Literal.String.Symbol */
body .bp { color: #008000 } /* Name.Builtin.Pseudo */
body .fm { color: #0000FF } /* Name.Function.Magic */
body .vc { color: #19177C } /* Name.Variable.Class */
body .vg { color: #19177C } /* Name.Variable.Global */
body .vi { color: #19177C } /* Name.Variable.Instance */
body .vm { color: #19177C } /* Name.Variable.Magic */
body .il { color: #666666 } /* Literal.Number.Integer.Long */

  </style>
</head>
<body>
<h2></h2>

<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">  1</span>
<span class="normal">  2</span>
<span class="normal">  3</span>
<span class="normal">  4</span>
<span class="normal">  5</span>
<span class="normal">  6</span>
<span class="normal">  7</span>
<span class="normal">  8</span>
<span class="normal">  9</span>
<span class="normal"> 10</span>
<span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python</span>
<span id="2"><span class="c1"># coding: utf-8</span></span>
<span id="3"></span>
<span id="4"><span class="c1"># # 机器学习纳米学位</span></span>
<span id="5"><span class="c1"># ## 监督学习</span></span>
<span id="6"><span class="c1"># ## 项目2: 为*CharityML*寻找捐献者</span></span>
<span id="7"></span>
<span id="8"><span class="c1"># 欢迎来到机器学习工程师纳米学位的第二个项目！在此文件中，有些示例代码已经提供给你，但你还需要实现更多的功能让项目成功运行。除非有明确要求，你无须修改任何已给出的代码。以**&#39;练习&#39;**开始的标题表示接下来的代码部分中有你必须要实现的功能。每一部分都会有详细的指导，需要实现的部分也会在注释中以&#39;TODO&#39;标出。请仔细阅读所有的提示！</span></span>
<span id="9"><span class="c1"># </span></span>
<span id="10"><span class="c1"># 除了实现代码外，你还必须回答一些与项目和你的实现有关的问题。每一个需要你回答的问题都会以**&#39;问题 X&#39;**为标题。请仔细阅读每个问题，并且在问题后的**&#39;回答&#39;**文字框中写出完整的答案。我们将根据你对问题的回答和撰写代码所实现的功能来对你提交的项目进行评分。</span></span>
<span id="11"><span class="c1"># &gt;**提示：**Code 和 Markdown 区域可通过**Shift + Enter**快捷键运行。此外，Markdown可以通过双击进入编辑模式。</span></span>
<span id="12"></span>
<span id="13"><span class="c1"># ## 开始</span></span>
<span id="14"><span class="c1"># </span></span>
<span id="15"><span class="c1"># 在这个项目中，你将使用1994年美国人口普查收集的数据，选用几个监督学习算法以准确地建模被调查者的收入。然后，你将根据初步结果从中选择出最佳的候选算法，并进一步优化该算法以最好地建模这些数据。你的目标是建立一个能够准确地预测被调查者年收入是否超过50000美元的模型。这种类型的任务会出现在那些依赖于捐款而存在的非营利性组织。了解人群的收入情况可以帮助一个非营利性的机构更好地了解他们要多大的捐赠，或是否他们应该接触这些人。虽然我们很难直接从公开的资源中推断出一个人的一般收入阶层，但是我们可以（也正是我们将要做的）从其他的一些公开的可获得的资源中获得一些特征从而推断出该值。</span></span>
<span id="16"><span class="c1"># </span></span>
<span id="17"><span class="c1"># 这个项目的数据集来自[UCI机器学习知识库](https://archive.ics.uci.edu/ml/datasets/Census+Income)。这个数据集是由Ron Kohavi和Barry Becker在发表文章_&quot;Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid&quot;_之后捐赠的，你可以在Ron Kohavi提供的[在线版本](https://www.aaai.org/Papers/KDD/1996/KDD96-033.pdf)中找到这个文章。我们在这里探索的数据集相比于原有的数据集有一些小小的改变，比如说移除了特征`&#39;fnlwgt&#39;` 以及一些遗失的或者是格式不正确的记录。</span></span>
<span id="18"></span>
<span id="19"><span class="c1"># ----</span></span>
<span id="20"><span class="c1"># ## 探索数据</span></span>
<span id="21"><span class="c1"># 运行下面的代码单元以载入需要的Python库并导入人口普查数据。注意数据集的最后一列`&#39;income&#39;`将是我们需要预测的列（表示被调查者的年收入会大于或者是最多50,000美元），人口普查数据中的每一列都将是关于被调查者的特征。</span></span>
<span id="22"></span>
<span id="23"><span class="c1"># In[2]:</span></span>
<span id="24"></span>
<span id="25"></span>
<span id="26"><span class="c1"># 为这个项目导入需要的库</span></span>
<span id="27"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span></span>
<span id="28"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span></span>
<span id="29"><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span></span>
<span id="30"><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span> <span class="c1"># 允许为DataFrame使用display()</span></span>
<span id="31"></span>
<span id="32"><span class="c1"># 导入附加的可视化代码visuals.py</span></span>
<span id="33"><span class="kn">import</span> <span class="nn">visuals</span> <span class="k">as</span> <span class="nn">vs</span></span>
<span id="34"></span>
<span id="35"><span class="c1"># 为notebook提供更加漂亮的可视化</span></span>
<span id="36"><span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">&#39;matplotlib&#39;</span><span class="p">,</span> <span class="s1">&#39;inline&#39;</span><span class="p">)</span></span>
<span id="37"></span>
<span id="38"><span class="c1"># 导入人口普查数据</span></span>
<span id="39"><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;census.csv&quot;</span><span class="p">)</span></span>
<span id="40"></span>
<span id="41"><span class="c1"># 成功 - 显示第一条记录</span></span>
<span id="42"><span class="n">display</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span></span>
<span id="43"></span>
<span id="44"></span>
<span id="45"><span class="c1"># ### 练习：数据探索</span></span>
<span id="46"><span class="c1"># 首先我们对数据集进行一个粗略的探索，我们将看看每一个类别里会有多少被调查者？并且告诉我们这些里面多大比例是年收入大于50,000美元的。在下面的代码单元中，你将需要计算以下量：</span></span>
<span id="47"><span class="c1"># </span></span>
<span id="48"><span class="c1"># - 总的记录数量，`&#39;n_records&#39;`</span></span>
<span id="49"><span class="c1"># - 年收入大于50,000美元的人数，`&#39;n_greater_50k&#39;`.</span></span>
<span id="50"><span class="c1"># - 年收入最多为50,000美元的人数 `&#39;n_at_most_50k&#39;`.</span></span>
<span id="51"><span class="c1"># - 年收入大于50,000美元的人所占的比例， `&#39;greater_percent&#39;`.</span></span>
<span id="52"></span>
<span id="53"><span class="c1"># In[3]:</span></span>
<span id="54"></span>
<span id="55"></span>
<span id="56"></span>
<span id="57"><span class="c1"># TODO：总的记录数</span></span>
<span id="58"><span class="n">n_records</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></span>
<span id="59"></span>
<span id="60"><span class="c1"># TODO：被调查者的收入大于$50,000的人数</span></span>
<span id="61"><span class="n">n_greater_50k</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;income&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;&gt;50K&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></span>
<span id="62"></span>
<span id="63"><span class="c1"># TODO：被调查者的收入最多为$50,000的人数</span></span>
<span id="64"><span class="n">n_at_most_50k</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;income&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;&lt;=50K&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></span>
<span id="65"></span>
<span id="66"><span class="c1"># TODO：被调查者收入大于$50,000所占的比例</span></span>
<span id="67"><span class="n">greater_percent</span> <span class="o">=</span> <span class="n">n_greater_50k</span><span class="o">/</span><span class="n">n_records</span><span class="o">*</span><span class="mi">100</span></span>
<span id="68"></span>
<span id="69"><span class="c1"># 打印结果</span></span>
<span id="70"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Total number of records: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_records</span><span class="p">)))</span></span>
<span id="71"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Individuals making more than $50,000: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_greater_50k</span><span class="p">)))</span></span>
<span id="72"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Individuals making at most $50,000: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_at_most_50k</span><span class="p">)))</span></span>
<span id="73"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Percentage of individuals making more than $50,000: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">greater_percent</span><span class="p">)))</span></span>
<span id="74"></span>
<span id="75"></span>
<span id="76"><span class="c1"># ----</span></span>
<span id="77"><span class="c1"># ## 准备数据</span></span>
<span id="78"><span class="c1"># 在数据能够被作为输入提供给机器学习算法之前，它经常需要被清洗，格式化，和重新组织 - 这通常被叫做**预处理**。幸运的是，对于这个数据集，没有我们必须处理的无效或丢失的条目，然而，由于某一些特征存在的特性我们必须进行一定的调整。这个预处理都可以极大地帮助我们提升几乎所有的学习算法的结果和预测能力。</span></span>
<span id="79"></span>
<span id="80"><span class="c1"># ### 转换倾斜的连续特征</span></span>
<span id="81"><span class="c1"># </span></span>
<span id="82"><span class="c1"># 一个数据集有时可能包含至少一个靠近某个数字的特征，但有时也会有一些相对来说存在极大值或者极小值的不平凡分布的的特征。算法对这种分布的数据会十分敏感，并且如果这种数据没有能够很好地规一化处理会使得算法表现不佳。在人口普查数据集的两个特征符合这个描述：&#39;`capital-gain&#39;`和`&#39;capital-loss&#39;`。</span></span>
<span id="83"><span class="c1"># </span></span>
<span id="84"><span class="c1"># 运行下面的代码单元以创建一个关于这两个特征的条形图。请注意当前的值的范围和它们是如何分布的。</span></span>
<span id="85"></span>
<span id="86"><span class="c1"># In[4]:</span></span>
<span id="87"></span>
<span id="88"></span>
<span id="89"><span class="c1"># 将数据切分成特征和对应的标签</span></span>
<span id="90"><span class="n">income_raw</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;income&#39;</span><span class="p">]</span></span>
<span id="91"><span class="n">features_raw</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;income&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span></span>
<span id="92"></span>
<span id="93"><span class="c1"># 可视化原来数据的倾斜的连续特征</span></span>
<span id="94"><span class="n">vs</span><span class="o">.</span><span class="n">distribution</span><span class="p">(</span><span class="n">data</span><span class="p">)</span></span>
<span id="95"></span>
<span id="96"></span>
<span id="97"><span class="c1"># 对于高度倾斜分布的特征如`&#39;capital-gain&#39;`和`&#39;capital-loss&#39;`，常见的做法是对数据施加一个&lt;a href=&quot;https://en.wikipedia.org/wiki/Data_transformation_(statistics)&quot;&gt;对数转换&lt;/a&gt;，将数据转换成对数，这样非常大和非常小的值不会对学习算法产生负面的影响。并且使用对数变换显著降低了由于异常值所造成的数据范围异常。但是在应用这个变换时必须小心：因为0的对数是没有定义的，所以我们必须先将数据处理成一个比0稍微大一点的数以成功完成对数转换。</span></span>
<span id="98"><span class="c1"># </span></span>
<span id="99"><span class="c1"># 运行下面的代码单元来执行数据的转换和可视化结果。再次，注意值的范围和它们是如何分布的。</span></span>
<span id="100"></span>
<span id="101"><span class="c1"># In[5]:</span></span>
<span id="102"></span>
<span id="103"></span>
<span id="104"><span class="c1"># 对于倾斜的数据使用Log转换</span></span>
<span id="105"><span class="n">skewed</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;capital-gain&#39;</span><span class="p">,</span> <span class="s1">&#39;capital-loss&#39;</span><span class="p">]</span></span>
<span id="106"><span class="n">features_raw</span><span class="p">[</span><span class="n">skewed</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">skewed</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span></span>
<span id="107"></span>
<span id="108"><span class="c1"># 可视化经过log之后的数据分布</span></span>
<span id="109"><span class="n">vs</span><span class="o">.</span><span class="n">distribution</span><span class="p">(</span><span class="n">features_raw</span><span class="p">,</span> <span class="n">transformed</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span></span>
<span id="110"></span>
<span id="111"></span>
<span id="112"><span class="c1"># ### 规一化数字特征</span></span>
<span id="113"><span class="c1"># 除了对于高度倾斜的特征施加转换，对数值特征施加一些形式的缩放通常会是一个好的习惯。在数据上面施加一个缩放并不会改变数据分布的形式（比如上面说的&#39;capital-gain&#39; or &#39;capital-loss&#39;）；但是，规一化保证了每一个特征在使用监督学习器的时候能够被平等的对待。注意一旦使用了缩放，观察数据的原始形式不再具有它本来的意义了，就像下面的例子展示的。</span></span>
<span id="114"><span class="c1"># </span></span>
<span id="115"><span class="c1"># 运行下面的代码单元来规一化每一个数字特征。我们将使用[`sklearn.preprocessing.MinMaxScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)来完成这个任务。</span></span>
<span id="116"></span>
<span id="117"><span class="c1"># In[6]:</span></span>
<span id="118"></span>
<span id="119"></span>
<span id="120"><span class="c1"># 导入sklearn.preprocessing.StandardScaler</span></span>
<span id="121"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span></span>
<span id="122"></span>
<span id="123"><span class="c1"># 初始化一个 scaler，并将它施加到特征上</span></span>
<span id="124"><span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span></span>
<span id="125"><span class="n">numerical</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;education-num&#39;</span><span class="p">,</span> <span class="s1">&#39;capital-gain&#39;</span><span class="p">,</span> <span class="s1">&#39;capital-loss&#39;</span><span class="p">,</span> <span class="s1">&#39;hours-per-week&#39;</span><span class="p">]</span></span>
<span id="126"><span class="n">features_raw</span><span class="p">[</span><span class="n">numerical</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">numerical</span><span class="p">])</span></span>
<span id="127"></span>
<span id="128"><span class="c1"># 显示一个经过缩放的样例记录</span></span>
<span id="129"><span class="n">display</span><span class="p">(</span><span class="n">features_raw</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">1</span><span class="p">))</span></span>
<span id="130"></span>
<span id="131"></span>
<span id="132"><span class="c1"># ### 练习：数据预处理</span></span>
<span id="133"><span class="c1"># </span></span>
<span id="134"><span class="c1"># 从上面的**数据探索**中的表中，我们可以看到有几个属性的每一条记录都是非数字的。通常情况下，学习算法期望输入是数字的，这要求非数字的特征（称为类别变量）被转换。转换类别变量的一种流行的方法是使用**独热编码**方案。独热编码为每一个非数字特征的每一个可能的类别创建一个_“虚拟”_变量。例如，假设`someFeature`有三个可能的取值`A`，`B`或者`C`，。我们将把这个特征编码成`someFeature_A`, `someFeature_B`和`someFeature_C`.</span></span>
<span id="135"><span class="c1"># </span></span>
<span id="136"><span class="c1"># |   | 一些特征 |                    | 特征_A | 特征_B | 特征_C |</span></span>
<span id="137"><span class="c1"># | :-: | :-: |                            | :-: | :-: | :-: |</span></span>
<span id="138"><span class="c1"># | 0 |  B  |  | 0 | 1 | 0 |</span></span>
<span id="139"><span class="c1"># | 1 |  C  | ----&gt; 独热编码 ----&gt; | 0 | 0 | 1 |</span></span>
<span id="140"><span class="c1"># | 2 |  A  |  | 1 | 0 | 0 |</span></span>
<span id="141"><span class="c1"># </span></span>
<span id="142"><span class="c1"># 此外，对于非数字的特征，我们需要将非数字的标签`&#39;income&#39;`转换成数值以保证学习算法能够正常工作。因为这个标签只有两种可能的类别（&quot;&lt;=50K&quot;和&quot;&gt;50K&quot;），我们不必要使用独热编码，可以直接将他们编码分别成两个类`0`和`1`，在下面的代码单元中你将实现以下功能：</span></span>
<span id="143"><span class="c1">#  - 使用[`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies)对`&#39;features_raw&#39;`数据来施加一个独热编码。</span></span>
<span id="144"><span class="c1">#  - 将目标标签`&#39;income_raw&#39;`转换成数字项。</span></span>
<span id="145"><span class="c1">#    - 将&quot;&lt;=50K&quot;转换成`0`；将&quot;&gt;50K&quot;转换成`1`。</span></span>
<span id="146"></span>
<span id="147"><span class="c1"># In[7]:</span></span>
<span id="148"></span>
<span id="149"></span>
<span id="150"><span class="c1"># TODO：使用pandas.get_dummies()对&#39;features_raw&#39;数据进行独热编码</span></span>
<span id="151"><span class="n">features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">features_raw</span><span class="p">)</span></span>
<span id="152"></span>
<span id="153"><span class="c1"># TODO：将&#39;income_raw&#39;编码成数字值</span></span>
<span id="154"><span class="n">income</span> <span class="o">=</span> <span class="p">(</span><span class="n">income_raw</span> <span class="o">==</span> <span class="s1">&#39;&gt;50K&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span></span>
<span id="155"></span>
<span id="156"><span class="c1"># 打印经过独热编码之后的特征数量</span></span>
<span id="157"><span class="n">encoded</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span></span>
<span id="158"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> total features after one-hot encoding.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">encoded</span><span class="p">))))</span></span>
<span id="159"></span>
<span id="160"><span class="c1"># 移除下面一行的注释以观察编码的特征名字</span></span>
<span id="161"><span class="c1">#print encoded</span></span>
<span id="162"></span>
<span id="163"></span>
<span id="164"><span class="c1"># ### 混洗和切分数据</span></span>
<span id="165"><span class="c1"># 现在所有的 _类别变量_ 已被转换成数值特征，而且所有的数值特征已被规一化。和我们一般情况下做的一样，我们现在将数据（包括特征和它们的标签）切分成训练和测试集。其中80%的数据将用于训练和20%的数据用于测试。</span></span>
<span id="166"><span class="c1"># </span></span>
<span id="167"><span class="c1"># 运行下面的代码单元来完成切分。</span></span>
<span id="168"></span>
<span id="169"><span class="c1"># In[8]:</span></span>
<span id="170"></span>
<span id="171"></span>
<span id="172"><span class="c1"># 导入 train_test_split</span></span>
<span id="173"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span></span>
<span id="174"></span>
<span id="175"><span class="c1"># 将&#39;features&#39;和&#39;income&#39;数据切分成训练集和测试集</span></span>
<span id="176"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">income</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span></span>
<span id="177"></span>
<span id="178"><span class="c1"># 显示切分的结果</span></span>
<span id="179"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Training set has </span><span class="si">{}</span><span class="s2"> samples.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span></span>
<span id="180"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Testing set has </span><span class="si">{}</span><span class="s2"> samples.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span></span>
<span id="181"></span>
<span id="182"></span>
<span id="183"><span class="c1"># ----</span></span>
<span id="184"><span class="c1"># ## 评价模型性能</span></span>
<span id="185"><span class="c1"># 在这一部分中，我们将尝试四种不同的算法，并确定哪一个能够最好地建模数据。这里面的三个将是你选择的监督学习器，而第四种算法被称为一个*朴素的预测器*。</span></span>
<span id="186"><span class="c1"># </span></span>
<span id="187"></span>
<span id="188"><span class="c1"># ### 评价方法和朴素的预测器</span></span>
<span id="189"><span class="c1"># *CharityML*通过他们的研究人员知道被调查者的年收入大于\$50,000最有可能向他们捐款。因为这个原因*CharityML*对于准确预测谁能够获得\$50,000以上收入尤其有兴趣。这样看起来使用**准确率**作为评价模型的标准是合适的。另外，把*没有*收入大于\$50,000的人识别成年收入大于\$50,000对于*CharityML*来说是有害的，因为他想要找到的是有意愿捐款的用户。这样，我们期望的模型具有准确预测那些能够年收入大于\$50,000的能力比模型去**查全**这些被调查者*更重要*。我们能够使用**F-beta score**作为评价指标，这样能够同时考虑查准率和查全率：</span></span>
<span id="190"><span class="c1"># </span></span>
<span id="191"><span class="c1"># $$ F_{\beta} = (1 + \beta^2) \cdot \frac{precision \cdot recall}{\left( \beta^2 \cdot precision \right) + recall} $$</span></span>
<span id="192"><span class="c1"># </span></span>
<span id="193"><span class="c1"># </span></span>
<span id="194"><span class="c1"># 尤其是，当$\beta = 0.5$的时候更多的强调查准率，这叫做**F$_{0.5}$ score** （或者为了简单叫做F-score）。</span></span>
<span id="195"><span class="c1"># </span></span>
<span id="196"><span class="c1"># 通过查看不同类别的数据分布（那些最多赚\$50,000和那些能够赚更多的），我们能发现：很明显的是很多的被调查者年收入没有超过\$50,000。这点会显著地影响**准确率**，因为我们可以简单地预测说*“这个人的收入没有超过\$50,000”*，这样我们甚至不用看数据就能做到我们的预测在一般情况下是正确的！做这样一个预测被称作是**朴素的**，因为我们没有任何信息去证实这种说法。通常考虑对你的数据使用一个*朴素的预测器*是十分重要的，这样能够帮助我们建立一个模型的表现是否好的基准。那有人说，使用这样一个预测是没有意义的：如果我们预测所有人的收入都低于\$50,000，那么*CharityML*就不会有人捐款了。</span></span>
<span id="197"></span>
<span id="198"><span class="c1"># ### 问题 1 - 朴素预测器的性能</span></span>
<span id="199"><span class="c1"># *如果我们选择一个无论什么情况都预测被调查者年收入大于\$50,000的模型，那么这个模型在这个数据集上的准确率和F-score是多少？*  </span></span>
<span id="200"><span class="c1"># **注意：** 你必须使用下面的代码单元将你的计算结果赋值给`&#39;accuracy&#39;` 和 `&#39;fscore&#39;`，这些值会在后面被使用，请注意这里不能使用scikit-learn，你需要根据公式自己实现相关计算。</span></span>
<span id="201"></span>
<span id="202"><span class="c1"># In[9]:</span></span>
<span id="203"></span>
<span id="204"></span>
<span id="205"><span class="c1"># TODO： 计算准确率</span></span>
<span id="206"><span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></span>
<span id="207"><span class="n">pred</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span></span>
<span id="208"></span>
<span id="209"><span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">income</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span></span>
<span id="210"></span>
<span id="211"><span class="c1"># TODO： 使用上面的公式，并设置beta=0.5计算F-score</span></span>
<span id="212"><span class="n">sumTP</span> <span class="o">=</span> <span class="mi">0</span></span>
<span id="213"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)):</span></span>
<span id="214">    <span class="k">if</span> <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="p">:</span></span>
<span id="215">        <span class="k">if</span> <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">income</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span></span>
<span id="216">            <span class="n">sumTP</span> <span class="o">+=</span> <span class="mi">1</span></span>
<span id="217"><span class="n">precision</span> <span class="o">=</span> <span class="n">sumTP</span><span class="o">/</span> <span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span></span>
<span id="218"><span class="n">recall</span> <span class="o">=</span> <span class="n">sumTP</span><span class="o">/</span><span class="p">(</span><span class="n">income</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span></span>
<span id="219"></span>
<span id="220"><span class="n">fscore</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span> <span class="mf">0.5</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span> <span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span><span class="o">/</span><span class="p">(</span><span class="mf">0.5</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">)</span></span>
<span id="221"></span>
<span id="222"><span class="c1"># 打印结果</span></span>
<span id="223"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Naive Predictor: [Accuracy score: </span><span class="si">{:.4f}</span><span class="s2">, F-score: </span><span class="si">{:.4f}</span><span class="s2">]&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">fscore</span><span class="p">)))</span></span>
<span id="224"></span>
<span id="225"></span>
<span id="226"><span class="c1"># ### 监督学习模型</span></span>
<span id="227"><span class="c1"># **下面的监督学习模型是现在在** [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html) **中你能够选择的模型**</span></span>
<span id="228"><span class="c1"># - 高斯朴素贝叶斯 (GaussianNB)</span></span>
<span id="229"><span class="c1"># - 决策树</span></span>
<span id="230"><span class="c1"># - 集成方法 (Bagging, AdaBoost, Random Forest, Gradient Boosting)</span></span>
<span id="231"><span class="c1"># - K近邻 (KNeighbors)</span></span>
<span id="232"><span class="c1"># - 随机梯度下降分类器 (SGDC)</span></span>
<span id="233"><span class="c1"># - 支撑向量机 (SVM)</span></span>
<span id="234"><span class="c1"># - Logistic回归</span></span>
<span id="235"><span class="c1"># </span></span>
<span id="236"></span>
<span id="237"><span class="c1"># ### 问题 2 - 模型应用</span></span>
<span id="238"><span class="c1"># </span></span>
<span id="239"><span class="c1"># 列出从上面的监督学习模型中选择的三个适合我们这个问题的模型，你将在人口普查数据上测试这每个算法。对于你选择的每一个算法：</span></span>
<span id="240"><span class="c1"># </span></span>
<span id="241"><span class="c1"># - *描述一个该模型在真实世界的一个应用场景。（你需要为此做点研究，并给出你的引用出处）*</span></span>
<span id="242"><span class="c1"># - *这个模型的优势是什么？他什么情况下表现最好？*</span></span>
<span id="243"><span class="c1"># - *这个模型的缺点是什么？什么条件下它表现很差？*</span></span>
<span id="244"><span class="c1"># - *根据我们当前数据集的特点，为什么这个模型适合这个问题。*</span></span>
<span id="245"></span>
<span id="246"><span class="c1"># **回答： **</span></span>
<span id="247"><span class="c1"># * 支撑向量机(SVM)</span></span>
<span id="248"><span class="c1">#     - 应用场景：用于医学中分类蛋白质，超过90%的化合物能够被正确分类。[Bilwaj Gaonkar, Christos Davatzikos Analytic estimation of statistical significance maps for support vector machine based multi-variate image analysis and classification]</span></span>
<span id="249"><span class="c1">#     - 优点：1）在高维空间中表现仍旧比较好；2）在变量维度大于样本数量时算法依旧有效；3）灵活多变：运用不同的kernals可以构造不同的决策函数。在复杂数据和有明显的分隔边界时表现较好。</span></span>
<span id="250"><span class="c1">#     - 缺点：1）解出的模型的参数较难理解；2）只能用于二分类问题（除非应用将多类任务减少到几个二元问题的算法）。当样本量大时运行时间长。</span></span>
<span id="251"><span class="c1">#     - 使用SVM可以拟合复杂边界</span></span>
<span id="252"><span class="c1"># * 集成方法（Adaboost）</span></span>
<span id="253"><span class="c1">#     - 应用场景：[Application of Random Forests Methods to Diabetic Retinopathy Classification Analyses](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0098587)</span></span>
<span id="254"><span class="c1">#     - 优点：1）可以拟合复杂度高的模型；2）可以得知哪些变量比较重要；3）模型泛化能力强；4）运行速度快。适用于复杂的大规模数据。</span></span>
<span id="255"><span class="c1">#     - 缺点：在某些噪音较大的数据集上容易过拟合。在噪音较大，数据规模小的条件下表现很差。</span></span>
<span id="256"><span class="c1">#     - 数据量较大，可用复杂模型得到更好的拟合效果。</span></span>
<span id="257"><span class="c1"># * Logistics回归</span></span>
<span id="258"><span class="c1">#     - 应用场景：[基于投票者的年龄、收入、性别、种族、居住州等变量来预测美国大选中该投票者会将票投给哪个党派](http://biostat.mc.vanderbilt.edu/tmp/course.pdf)</span></span>
<span id="259"><span class="c1">#     - 优点：1）线性模型，容易解释和使用；2）运行速度快。在数据简单的时候表现很好。</span></span>
<span id="260"><span class="c1">#     - 缺点：1）不能很好地处理大量多特征的数据；2）容易欠拟合。在分隔边界复杂时表现不好。</span></span>
<span id="261"><span class="c1">#     - 该问题特征不算很多，可以用线性模型，而且有助于我们比较其他模型的效果。</span></span>
<span id="262"></span>
<span id="263"><span class="c1"># ### 练习 - 创建一个训练和预测的流水线</span></span>
<span id="264"><span class="c1"># 为了正确评估你选择的每一个模型的性能，创建一个能够帮助你快速有效地使用不同大小的训练集并在测试集上做预测的训练和测试的流水线是十分重要的。</span></span>
<span id="265"><span class="c1"># 你在这里实现的功能将会在接下来的部分中被用到。在下面的代码单元中，你将实现以下功能：</span></span>
<span id="266"><span class="c1"># </span></span>
<span id="267"><span class="c1">#  - 从[`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)中导入`fbeta_score`和`accuracy_score`。</span></span>
<span id="268"><span class="c1">#  - 用样例训练集拟合学习器，并记录训练时间。</span></span>
<span id="269"><span class="c1">#  - 用学习器来对训练集进行预测并记录预测时间。</span></span>
<span id="270"><span class="c1">#  - 在最前面的300个*训练数据*上做预测。</span></span>
<span id="271"><span class="c1">#  - 计算训练数据和测试数据的准确率。</span></span>
<span id="272"><span class="c1">#  - 计算训练数据和测试数据的F-score。</span></span>
<span id="273"></span>
<span id="274"><span class="c1"># In[18]:</span></span>
<span id="275"></span>
<span id="276"></span>
<span id="277"><span class="c1"># TODO：从sklearn中导入两个评价指标 - fbeta_score和accuracy_score</span></span>
<span id="278"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">fbeta_score</span><span class="p">,</span> <span class="n">accuracy_score</span></span>
<span id="279"></span>
<span id="280"><span class="k">def</span> <span class="nf">train_predict</span><span class="p">(</span><span class="n">learner</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span> </span>
<span id="281">    <span class="sd">&#39;&#39;&#39;</span></span>
<span id="282"><span class="sd">    inputs:</span></span>
<span id="283"><span class="sd">       - learner: the learning algorithm to be trained and predicted on</span></span>
<span id="284"><span class="sd">       - sample_size: the size of samples (number) to be drawn from training set</span></span>
<span id="285"><span class="sd">       - X_train: features training set</span></span>
<span id="286"><span class="sd">       - y_train: income training set</span></span>
<span id="287"><span class="sd">       - X_test: features testing set</span></span>
<span id="288"><span class="sd">       - y_test: income testing set</span></span>
<span id="289"><span class="sd">    &#39;&#39;&#39;</span></span>
<span id="290">    </span>
<span id="291">    <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span></span>
<span id="292">    </span>
<span id="293">    <span class="c1"># TODO：使用sample_size大小的训练数据来拟合学习器</span></span>
<span id="294">    <span class="c1"># TODO: Fit the learner to the training data using slicing with &#39;sample_size&#39;</span></span>
<span id="295">    <span class="n">train_data</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:</span><span class="n">sample_size</span><span class="p">]</span></span>
<span id="296">    <span class="n">train_label</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[:</span><span class="n">sample_size</span><span class="p">]</span></span>
<span id="297">    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="c1"># 获得程序开始时间</span></span>
<span id="298">    <span class="n">learner</span> <span class="o">=</span> <span class="n">learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">train</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([298, 307, 308])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">no independent test data</button>
<span id="299">    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="c1"># 获得程序结束时间</span></span>
<span id="300">    </span>
<span id="301">    <span class="c1"># TODO：计算训练时间</span></span>
<span id="302">    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;train_time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span></span>
<span id="303">    </span>
<span id="304">    <span class="c1"># TODO: 得到在测试集上的预测值</span></span>
<span id="305">    <span class="c1">#       然后得到对前300个训练数据的预测结果</span></span>
<span id="306">    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="c1"># 获得程序开始时间</span></span>
<span id="307">    <span class="n">predictions_test</span> <span class="o">=</span> <span class="n">learner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([298, 307, 308])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">potential preprocessing leakage</button> <a href="#126"><button type="button" style="line-height: 85%; None" onclick="mark_leak_lines([126])">show and go to first leak src</button></a> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([307, 431, 432, 520])">highlight other usage</button>
<span id="308">    <span class="n">predictions_train</span> <span class="o">=</span> <span class="n">learner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:</span><span class="mi">300</span><span class="p">])</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([298, 307, 308])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">potential preprocessing leakage</button> <a href="#126"><button type="button" style="line-height: 85%; None" onclick="mark_leak_lines([126])">show and go to first leak src</button></a>
<span id="309">    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="c1"># 获得程序结束时间</span></span>
<span id="310">    </span>
<span id="311">    <span class="c1"># TODO：计算预测用时</span></span>
<span id="312">    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;pred_time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span></span>
<span id="313">            </span>
<span id="314">    <span class="c1"># TODO：计算在最前面的300个训练数据的准确率</span></span>
<span id="315">    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;acc_train&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">[:</span><span class="mi">300</span><span class="p">],</span> <span class="n">predictions_train</span><span class="p">)</span></span>
<span id="316">        </span>
<span id="317">    <span class="c1"># TODO：计算在测试集上的准确率</span></span>
<span id="318">    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;acc_test&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions_test</span><span class="p">)</span></span>
<span id="319">    </span>
<span id="320">    <span class="c1"># TODO：计算在最前面300个训练数据上的F-score</span></span>
<span id="321">    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;f_train&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">[:</span><span class="mi">300</span><span class="p">],</span> <span class="n">predictions_train</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span></span>
<span id="322">        </span>
<span id="323">    <span class="c1"># TODO：计算测试集上的F-score</span></span>
<span id="324">    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;f_test&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions_test</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span></span>
<span id="325">       </span>
<span id="326">    <span class="c1"># 成功</span></span>
<span id="327">    <span class="nb">print</span><span class="p">((</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> trained on </span><span class="si">{}</span><span class="s2"> samples.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">learner</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">)))</span></span>
<span id="328">        </span>
<span id="329">    <span class="c1"># 返回结果</span></span>
<span id="330">    <span class="k">return</span> <span class="n">results</span></span>
<span id="331"></span>
<span id="332"></span>
<span id="333"><span class="c1"># ### 练习：初始模型的评估</span></span>
<span id="334"><span class="c1"># 在下面的代码单元中，您将需要实现以下功能：             </span></span>
<span id="335"><span class="c1"># - 导入你在前面讨论的三个监督学习模型。             </span></span>
<span id="336"><span class="c1"># - 初始化三个模型并存储在`&#39;clf_A&#39;`，`&#39;clf_B&#39;`和`&#39;clf_C&#39;`中。         </span></span>
<span id="337"><span class="c1">#   - 如果可能对每一个模型都设置一个`random_state`。       </span></span>
<span id="338"><span class="c1">#   - **注意：**这里先使用每一个模型的默认参数，在接下来的部分中你将需要对某一个模型的参数进行调整。             </span></span>
<span id="339"><span class="c1"># - 计算记录的数目等于1%，10%，和100%的训练数据，并将这些值存储在`&#39;samples&#39;`中             </span></span>
<span id="340"><span class="c1"># </span></span>
<span id="341"><span class="c1"># **注意：**取决于你选择的算法，下面实现的代码可能需要一些时间来运行！</span></span>
<span id="342"></span>
<span id="343"><span class="c1"># In[20]:</span></span>
<span id="344"></span>
<span id="345"></span>
<span id="346"><span class="c1"># TODO：从sklearn中导入三个监督学习模型</span></span>
<span id="347"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span></span>
<span id="348"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span></span>
<span id="349"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span></span>
<span id="350"></span>
<span id="351"><span class="c1"># TODO：初始化三个模型</span></span>
<span id="352"><span class="n">clf_A</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></span>
<span id="353"><span class="n">clf_B</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></span>
<span id="354"><span class="n">clf_C</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span></span>
<span id="355"></span>
<span id="356"><span class="c1"># TODO：计算1%， 10%， 100%的训练数据分别对应多少点</span></span>
<span id="357"><span class="n">samples_1</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mf">0.01</span><span class="p">)</span></span>
<span id="358"><span class="n">samples_10</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mf">0.1</span><span class="p">)</span></span>
<span id="359"><span class="n">samples_100</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></span>
<span id="360"></span>
<span id="361"><span class="c1"># 收集学习器的结果</span></span>
<span id="362"><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span></span>
<span id="363"><span class="k">for</span> <span class="n">clf</span> <span class="ow">in</span> <span class="p">[</span><span class="n">clf_A</span><span class="p">,</span> <span class="n">clf_B</span><span class="p">,</span> <span class="n">clf_C</span><span class="p">]:</span></span>
<span id="364">    <span class="n">clf_name</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span></span>
<span id="365">    <span class="n">results</span><span class="p">[</span><span class="n">clf_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span></span>
<span id="366">    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">samples</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">samples_1</span><span class="p">,</span> <span class="n">samples_10</span><span class="p">,</span> <span class="n">samples_100</span><span class="p">]):</span></span>
<span id="367">        <span class="n">results</span><span class="p">[</span><span class="n">clf_name</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span>         <span class="n">train_predict</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span></span>
<span id="368"></span>
<span id="369"><span class="c1"># 对选择的三个模型得到的评价结果进行可视化</span></span>
<span id="370"><span class="n">vs</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">fscore</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([370])">highlight other usage</button>
<span id="371"></span>
<span id="372"></span>
<span id="373"><span class="c1"># ----</span></span>
<span id="374"><span class="c1"># ## 提高效果</span></span>
<span id="375"><span class="c1"># </span></span>
<span id="376"><span class="c1"># 在这最后一节中，您将从三个有监督的学习模型中选择*最好的*模型来使用学生数据。你将在整个训练集（`X_train`和`y_train`）上通过使用网格搜索优化至少调节一个参数以获得一个比没有调节之前更好的F-score。</span></span>
<span id="377"></span>
<span id="378"><span class="c1"># ### 问题 3 - 选择最佳的模型</span></span>
<span id="379"><span class="c1"># </span></span>
<span id="380"><span class="c1"># *基于你前面做的评价，用一到两段向*CharityML*解释这三个模型中哪一个对于判断被调查者的年收入大于\$50,000是最合适的。*             </span></span>
<span id="381"><span class="c1"># **提示：**你的答案应该包括关于评价指标，预测/训练时间，以及该算法是否适合这里的数据的讨论。</span></span>
<span id="382"></span>
<span id="383"><span class="c1"># **回答：**Adaboost模型是最适合用来判断被调查者的年收入大于\$50,000与否的。因为Adaboost在测试集上的准确率和F-score都是最高的，这说明该模型能够很好地预测出年收入大于$50,000的人，同时兼顾查准率和查全率。同时Adaboost的预测和训练速度都很快，适合用在大规模数据上。</span></span>
<span id="384"></span>
<span id="385"><span class="c1"># ### 问题 4 - 用通俗的话解释模型</span></span>
<span id="386"><span class="c1"># </span></span>
<span id="387"><span class="c1"># *用一到两段话，向*CharityML*用外行也听得懂的话来解释最终模型是如何工作的。你需要解释所选模型的主要特点。例如，这个模型是怎样被训练的，它又是如何做出预测的。避免使用高级的数学或技术术语，不要使用公式或特定的算法名词。*</span></span>
<span id="388"></span>
<span id="389"><span class="c1"># **回答： ** AdaBoost是一种集成方法，训练出一堆弱分类器，然后将这些弱分类器的预测通过加权平均得到最终预测结果。具体到训练弱分类器的过程：如果某个样本点已经被准确地分类，那么在构造下一个训练集中，它的权值就被降低；相反，如果某个样本点没有被准确地分类，那么它的权值就得到提高。然后，权值更新过的样本集被用于训练下一个弱分类器，整个训练过程如此迭代地进行下去。随着迭代的进行，困难的示例将会有越来越大的权重，因此后续的弱分类器被迫集中在学习数据中以前的错误的例子。</span></span>
<span id="390"></span>
<span id="391"><span class="c1"># ### 练习：模型调优</span></span>
<span id="392"><span class="c1"># 调节选择的模型的参数。使用网格搜索（GridSearchCV）来至少调整模型的重要参数（至少调整一个），这个参数至少需给出并尝试3个不同的值。你要使用整个训练集来完成这个过程。在接下来的代码单元中，你需要实现以下功能：</span></span>
<span id="393"><span class="c1"># </span></span>
<span id="394"><span class="c1"># - 导入[`sklearn.model_selection.GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)和[`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).</span></span>
<span id="395"><span class="c1"># - 初始化你选择的分类器，并将其存储在`clf`中。</span></span>
<span id="396"><span class="c1">#  - 如果能够设置的话，设置`random_state`。</span></span>
<span id="397"><span class="c1"># - 创建一个对于这个模型你希望调整参数的字典。</span></span>
<span id="398"><span class="c1">#  - 例如: parameters = {&#39;parameter&#39; : [list of values]}。</span></span>
<span id="399"><span class="c1">#  - **注意：** 如果你的学习器（learner）有 `max_features` 参数，请不要调节它！</span></span>
<span id="400"><span class="c1"># - 使用`make_scorer`来创建一个`fbeta_score`评分对象（设置$\beta = 0.5$）。</span></span>
<span id="401"><span class="c1"># - 在分类器clf上用&#39;scorer&#39;作为评价函数运行网格搜索，并将结果存储在grid_obj中。</span></span>
<span id="402"><span class="c1"># - 用训练集（X_train, y_train）训练grid search object,并将结果存储在`grid_fit`中。</span></span>
<span id="403"><span class="c1"># </span></span>
<span id="404"><span class="c1"># **注意：** 取决于你选择的参数列表，下面实现的代码可能需要花一些时间运行！</span></span>
<span id="405"></span>
<span id="406"><span class="c1"># In[22]:</span></span>
<span id="407"></span>
<span id="408"></span>
<span id="409"><span class="c1"># TODO：导入&#39;GridSearchCV&#39;, &#39;make_scorer&#39;和其他一些需要的库</span></span>
<span id="410"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span></span>
<span id="411"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span></span>
<span id="412"><span class="c1"># TODO：初始化分类器</span></span>
<span id="413"><span class="n">clf</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span></span>
<span id="414"></span>
<span id="415"><span class="c1"># TODO：创建你希望调节的参数列表</span></span>
<span id="416"><span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:[</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">500</span><span class="p">],</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">:[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]}</span></span>
<span id="417"></span>
<span id="418"><span class="c1"># TODO：创建一个fbeta_score打分对象</span></span>
<span id="419"><span class="n">scorer</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">fbeta_score</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span></span>
<span id="420"></span>
<span id="421"><span class="c1"># TODO：在分类器上使用网格搜索，使用&#39;scorer&#39;作为评价函数</span></span>
<span id="422"><span class="n">grid_obj</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span></span>
<span id="423"></span>
<span id="424"><span class="c1"># TODO：用训练数据拟合网格搜索对象并找到最佳参数</span></span>
<span id="425"><span class="n">grid_fit</span> <span class="o">=</span> <span class="n">grid_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">train</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">no independent test data</button>
<span id="426"></span>
<span id="427"><span class="c1"># 得到estimator</span></span>
<span id="428"><span class="n">best_clf</span> <span class="o">=</span> <span class="n">grid_obj</span><span class="o">.</span><span class="n">best_estimator_</span></span>
<span id="429"></span>
<span id="430"><span class="c1"># 使用没有调优的模型做预测</span></span>
<span id="431"><span class="n">predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">train</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([431, 431, 432])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">no independent test data</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([431, 431, 432])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">potential preprocessing leakage</button> <a href="#126"><button type="button" style="line-height: 85%; None" onclick="mark_leak_lines([126])">show and go to first leak src</button></a> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([307, 431])">highlight other usage</button>
<span id="432"><span class="n">best_predictions</span> <span class="o">=</span> <span class="n">best_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([431, 431, 432])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">potential preprocessing leakage</button> <a href="#126"><button type="button" style="line-height: 85%; None" onclick="mark_leak_lines([126])">show and go to first leak src</button></a> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([307, 432])">highlight other usage</button>
<span id="433"></span>
<span id="434"><span class="c1"># 汇报调参前和调参后的分数</span></span>
<span id="435"><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Unoptimized model</span><span class="se">\n</span><span class="s2">------&quot;</span><span class="p">)</span></span>
<span id="436"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Accuracy score on testing data: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">))))</span></span>
<span id="437"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;F-score on testing data: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">))))</span></span>
<span id="438"><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Optimized Model</span><span class="se">\n</span><span class="s2">------&quot;</span><span class="p">)</span></span>
<span id="439"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Final accuracy score on the testing data: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">best_predictions</span><span class="p">))))</span></span>
<span id="440"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Final F-score on the testing data: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">best_predictions</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">))))</span></span>
<span id="441"></span>
<span id="442"></span>
<span id="443"><span class="c1"># ### 问题 5 - 最终模型评估</span></span>
<span id="444"><span class="c1"># </span></span>
<span id="445"><span class="c1"># _你的最优模型在测试数据上的准确率和F-score是多少？这些分数比没有优化的模型好还是差？你优化的结果相比于你在**问题 1**中得到的朴素预测器怎么样？_  </span></span>
<span id="446"><span class="c1"># **注意：**请在下面的表格中填写你的结果，然后在答案框中提供讨论。</span></span>
<span id="447"></span>
<span id="448"><span class="c1"># #### 结果:</span></span>
<span id="449"><span class="c1"># </span></span>
<span id="450"><span class="c1"># |     评价指标     | 基准预测器 | 未优化的模型 | 优化的模型 |</span></span>
<span id="451"><span class="c1"># | :------------: | :-----------------: | :---------------: | :-------------: | </span></span>
<span id="452"><span class="c1"># | 准确率 |     0.2478                |0.8576 | 0.8664              |</span></span>
<span id="453"><span class="c1"># | F-score        |      0.2917      |   0.7246           |   0.7432       |</span></span>
<span id="454"><span class="c1"># </span></span>
<span id="455"></span>
<span id="456"><span class="c1"># **回答：**最优模型在测试数据上的准确率是0.8664，F-score是0.7432。相比未优化的模型两个分数均有提高。优化的结果比朴素预测期效果好很多。这说明选择合适的模型和参数，能够大幅提高预测效果。</span></span>
<span id="457"></span>
<span id="458"><span class="c1"># ----</span></span>
<span id="459"><span class="c1"># ## 特征的重要性</span></span>
<span id="460"><span class="c1"># </span></span>
<span id="461"><span class="c1"># 在数据上（比如我们这里使用的人口普查的数据）使用监督学习算法的一个重要的任务是决定哪些特征能够提供最强的预测能力。通过专注于一些少量的有效特征和标签之间的关系，我们能够更加简单地理解这些现象，这在很多情况下都是十分有用的。在这个项目的情境下这表示我们希望选择一小部分特征，这些特征能够在预测被调查者是否年收入大于\$50,000这个问题上有很强的预测能力。</span></span>
<span id="462"><span class="c1"># </span></span>
<span id="463"><span class="c1"># 选择一个有`feature_importance_`属性（这是一个根据这个选择的分类器来对特征的重要性进行排序的函数）的scikit学习分类器（例如，AdaBoost，随机森林）。在下一个Python代码单元中用这个分类器拟合训练集数据并使用这个属性来决定这个人口普查数据中最重要的5个特征。</span></span>
<span id="464"></span>
<span id="465"><span class="c1"># ### 问题 6 - 观察特征相关性</span></span>
<span id="466"><span class="c1"># </span></span>
<span id="467"><span class="c1"># 当**探索数据**的时候，它显示在这个人口普查数据集中每一条记录我们有十三个可用的特征。             </span></span>
<span id="468"><span class="c1"># _在这十三个记录中，你认为哪五个特征对于预测是最重要的，你会怎样对他们排序？理由是什么？_</span></span>
<span id="469"></span>
<span id="470"><span class="c1"># **回答：**我认为最重要的五个特征依次是：workclass, education_level, age, capital-gain, relationship。我认为一个人的工作类型紧密联系着收入；受教育程度高通常能找到薪水更丰厚的工作；年龄也是比较重要的变量，这关系到一个人是否进入事业成熟期，刚工作的年轻人大多收入较低；资本收入是一个人总收入的一部分，对预测也有作用；一个人家庭关系对预测也有一定影响，一般来说有稳定家庭关系的人收入也比较稳定。</span></span>
<span id="471"></span>
<span id="472"><span class="c1"># ### 练习 - 提取特征重要性</span></span>
<span id="473"><span class="c1"># </span></span>
<span id="474"><span class="c1"># 选择一个`scikit-learn`中有`feature_importance_`属性的监督学习分类器，这个属性是一个在做预测的时候根据所选择的算法来对特征重要性进行排序的功能。</span></span>
<span id="475"><span class="c1"># </span></span>
<span id="476"><span class="c1"># 在下面的代码单元中，你将要实现以下功能：</span></span>
<span id="477"><span class="c1">#  - 如果这个模型和你前面使用的三个模型不一样的话从sklearn中导入一个监督学习模型。</span></span>
<span id="478"><span class="c1">#  - 在整个训练集上训练一个监督学习模型。</span></span>
<span id="479"><span class="c1">#  - 使用模型中的`&#39;.feature_importances_&#39;`提取特征的重要性。</span></span>
<span id="480"></span>
<span id="481"><span class="c1"># In[24]:</span></span>
<span id="482"></span>
<span id="483"></span>
<span id="484"><span class="c1"># TODO：导入一个有&#39;feature_importances_&#39;的监督学习模型</span></span>
<span id="485"></span>
<span id="486"><span class="c1"># TODO：在训练集上训练一个监督学习模型</span></span>
<span id="487"><span class="n">model</span> <span class="o">=</span> <span class="n">best_clf</span></span>
<span id="488"></span>
<span id="489"><span class="c1"># TODO： 提取特征重要性</span></span>
<span id="490"><span class="n">importances</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span></span>
<span id="491"></span>
<span id="492"><span class="c1"># 绘图</span></span>
<span id="493"><span class="n">vs</span><span class="o">.</span><span class="n">feature_plot</span><span class="p">(</span><span class="n">importances</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></span>
<span id="494"></span>
<span id="495"></span>
<span id="496"><span class="c1"># ### 问题 7 - 提取特征重要性</span></span>
<span id="497"><span class="c1"># 观察上面创建的展示五个用于预测被调查者年收入是否大于\$50,000最相关的特征的可视化图像。</span></span>
<span id="498"><span class="c1"># _这五个特征和你在**问题 6**中讨论的特征比较怎么样？如果说你的答案和这里的相近，那么这个可视化怎样佐证了你的想法？如果你的选择不相近，那么为什么你觉得这些特征更加相关？_</span></span>
<span id="499"></span>
<span id="500"><span class="c1"># **回答：**这五个特征与我的选择大部分一致，但是没想到capital-gain和capital-loss重要性竟然排在最前面，但是认真思考后发现资本收入和损失衡量了一个人的投资能力和资金充裕度，一般来说只有实现了财务自由的人才会把资金用作投资，这些人很可能比较富裕。年龄因素和我猜测的一致。每周工作时间一开始我并没有考虑进去，但是思考后发现工作时间长的人应该薪资更高，尤其是在美国这样劳动力昂贵的国家。受教育时间可以更好的反映一个人的受教育程度，从而影响收入。</span></span>
<span id="501"></span>
<span id="502"><span class="c1"># ### 特征选择</span></span>
<span id="503"><span class="c1"># </span></span>
<span id="504"><span class="c1"># 如果我们只是用可用特征的一个子集的话模型表现会怎么样？通过使用更少的特征来训练，在评价指标的角度来看我们的期望是训练和预测的时间会更少。从上面的可视化来看，我们可以看到前五个最重要的特征贡献了数据中**所有**特征中超过一半的重要性。这提示我们可以尝试去*减小特征空间*，并简化模型需要学习的信息。下面代码单元将使用你前面发现的优化模型，并*只使用五个最重要的特征*在相同的训练集上训练模型。</span></span>
<span id="505"></span>
<span id="506"><span class="c1"># In[25]:</span></span>
<span id="507"></span>
<span id="508"></span>
<span id="509"><span class="c1"># 导入克隆模型的功能</span></span>
<span id="510"><span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">clone</span></span>
<span id="511"></span>
<span id="512"><span class="c1"># 减小特征空间</span></span>
<span id="513"><span class="n">X_train_reduced</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">importances</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])[:</span><span class="mi">5</span><span class="p">]]]</span></span>
<span id="514"><span class="n">X_test_reduced</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">X_test</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">importances</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])[:</span><span class="mi">5</span><span class="p">]]]</span></span>
<span id="515"></span>
<span id="516"><span class="c1"># 在前面的网格搜索的基础上训练一个“最好的”模型</span></span>
<span id="517"><span class="n">clf</span> <span class="o">=</span> <span class="p">(</span><span class="n">clone</span><span class="p">(</span><span class="n">best_clf</span><span class="p">))</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_reduced</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">train</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([517, 520])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">no independent test data</button>
<span id="518"></span>
<span id="519"><span class="c1"># 做一个新的预测</span></span>
<span id="520"><span class="n">reduced_predictions</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_reduced</span><span class="p">)</span></span> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">test</button> <button type="button" style="line-height: 85%; background-color: green; color: white; border:none;" onclick="None">validation</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([517, 520])">highlight train/test sites</button> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">potential preprocessing leakage</button> <a href="#126"><button type="button" style="line-height: 85%; None" onclick="mark_leak_lines([126])">show and go to first leak src</button></a> <button type="button" style="line-height: 85%; background-color: red; color: white; border:none;" onclick="None">used multiple times</button> <button type="button" style="line-height: 85%; None" onclick="highlight_lines([307, 520])">highlight other usage</button>
<span id="521"></span>
<span id="522"><span class="c1"># 对于每一个版本的数据汇报最终模型的分数</span></span>
<span id="523"><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final Model trained on full data</span><span class="se">\n</span><span class="s2">------&quot;</span><span class="p">)</span></span>
<span id="524"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Accuracy on testing data: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">best_predictions</span><span class="p">))))</span></span>
<span id="525"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;F-score on testing data: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">best_predictions</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">))))</span></span>
<span id="526"><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Final Model trained on reduced data</span><span class="se">\n</span><span class="s2">------&quot;</span><span class="p">)</span></span>
<span id="527"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;Accuracy on testing data: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">reduced_predictions</span><span class="p">))))</span></span>
<span id="528"><span class="nb">print</span><span class="p">((</span><span class="s2">&quot;F-score on testing data: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">reduced_predictions</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">))))</span></span>
<span id="529"></span>
<span id="530"></span>
<span id="531"><span class="c1"># ### 问题 8 - 特征选择的影响</span></span>
<span id="532"><span class="c1"># </span></span>
<span id="533"><span class="c1"># *最终模型在只是用五个特征的数据上和使用所有的特征数据上的F-score和准确率相比怎么样？*  </span></span>
<span id="534"><span class="c1"># *如果训练时间是一个要考虑的因素，你会考虑使用部分特征的数据作为你的训练集吗？*</span></span>
<span id="535"></span>
<span id="536"><span class="c1"># **回答：**在只用五个特征进行训练和预测时，测试准确率从0.8664降低到0.8426，测试F-score从0.7432降低到0.7044。如果训练时间是一个要考虑的因素，我认为这样小幅度的降低预测效果是完全可以接受的，我会考虑使用部分特征进行训练。</span></span>
<span id="537"></span>
<span id="538"><span class="c1"># &gt; **注意：** 当你写完了所有的代码，并且回答了所有的问题。你就可以把你的 iPython Notebook 导出成 HTML 文件。你可以在菜单栏，这样导出**File -&gt; Download as -&gt; HTML (.html)**把这个 HTML 和这个 iPython notebook 一起做为你的作业提交。</span></span>
</pre></div>
</td></tr></table></body>
</html>
